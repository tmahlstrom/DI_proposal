{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.uci\n",
    "import chess.pgn\n",
    "import os\n",
    "import csv\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perf_df(event = 'Rated Classical game'):\n",
    "    df = pd.read_csv(\"/Users/tylerahlstrom/Documents/GitHub/DI_proposal/stockfish_performances_DC.csv\")\n",
    "    df = df.drop(df[df.event != event].index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_perfs(joint_perf_df):\n",
    "    new_headers = ['elo', 'chosen_evals', 'option_evals', 'opp_elo', 'win', 'acc_name']\n",
    "    split_df = pd.DataFrame(columns = new_headers)\n",
    "    for index, row in joint_perf_df.iterrows():\n",
    "        if len(row['result']) is 3:\n",
    "            split_df = split_df.append({'elo': row['elo_w'], 'chosen_evals' : row['chosen_moves_eval_w'], 'option_evals' : row['available_moves_eval_w'], 'opp_elo': row['elo_b'], 'result': row['result'][0], 'acc_name': row['acc_name_w']}, ignore_index=True)\n",
    "            split_df = split_df.append({'elo': row['elo_b'], 'chosen_evals' : row['chosen_moves_eval_b'], 'option_evals' : row['available_moves_eval_b'], 'opp_elo': row['elo_w'], 'result': row['result'][2], 'acc_name': row['acc_name_b']}, ignore_index=True)\n",
    "    return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_list(df):\n",
    "    for index, row in df.iterrows():\n",
    "        row['chosen_evals'] = json.loads(row['chosen_evals'])\n",
    "        row['option_evals'] = json.loads(row['option_evals'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_chosen_moves(dict_of_move_dict): #e.g. {u'11': {u'move_rank': 2, u'cp_scor#\n",
    "    lol_of_moves = []\n",
    "    for key, d_move in dict_of_move_dict.items():\n",
    "        lol_of_moves.append([key, d_move])\n",
    "    lol_of_moves.sort(key=lambda x: int(x[0]))\n",
    "    return lol_of_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_list_of_available_moves(dict_of_options_dict): # e.g. {u'24': {u'd7e8': {u'cp_score': -674, u'mate_s...\n",
    "    lolol_of_options  = []\n",
    "    for key, d_options in dict_of_options_dict.items():\n",
    "        lol_of_options = []\n",
    "        for key2, d_option in d_options.items():\n",
    "            lol_of_options.append([key2, d_option])\n",
    "        lol_of_options.sort(key=lambda x: int(x[1]['rank']))\n",
    "    \n",
    "        lolol_of_options.append([key, lol_of_options])\n",
    "    lolol_of_options.sort(key=lambda x: int(x[0][0]))\n",
    "    return lolol_of_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_rank_percentiles(list_of_moves):\n",
    "    list_of_rank_percentiles = []\n",
    "    for move in list_of_moves:\n",
    "        rank = int(move[1]['move_rank'])\n",
    "        num_options = int(move[1]['num_move_options'])\n",
    "        chunk = float(1)/float(num_options)\n",
    "        percentile = 1.0 - (float(rank-1) * chunk)\n",
    "        list_of_rank_percentiles.append(percentile)\n",
    "    return list_of_rank_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_move_cps(list_of_moves):\n",
    "    list_of_cps = []\n",
    "    for move in list_of_moves:\n",
    "        cp = move[1]['cp_score']\n",
    "        list_of_cps.append(cp)\n",
    "    return list_of_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_move_mates(list_of_moves):\n",
    "    list_of_mates = []\n",
    "    for move in list_of_moves:\n",
    "        mate = move[1]['mate_score']\n",
    "        list_of_mates.append(mate)\n",
    "    return list_of_mates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_option_cps(list_of_av_moves):\n",
    "    #print(list_of_av_moves)\n",
    "    lol_of_option_cps = []\n",
    "    for move in list_of_av_moves:\n",
    "        options_cps = []\n",
    "        for option in move[1]:\n",
    "            options_cps.append(option[1]['cp_score'])\n",
    "        lol_of_option_cps.append(options_cps)\n",
    "    \n",
    "    #print(lol_of_option_cps)\n",
    "    return lol_of_option_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_dist_percentiles(move_cps, option_cps):\n",
    "    dist_scores = []\n",
    "    for i in range(len(move_cps)):\n",
    "        cp_temp = [x for x in option_cps[i] if x != None]\n",
    "        max_cp = None\n",
    "        min_cp = None\n",
    "        if (len(cp_temp) > 0):\n",
    "            max_cp = max(cp_temp)\n",
    "            min_cp = min(cp_temp)\n",
    "    \n",
    "        #avg_cp = sum([x for x in option_cps[i] if x is not None])/float((len([x for x in option_cps[i] if x is not None])+0.1))\n",
    "        if move_cps[i] is None:\n",
    "            move_cps[i] = -2000\n",
    "        if max_cp is None:\n",
    "            max_cp = -10\n",
    "        if min_cp is None:\n",
    "            min_cp = -200\n",
    "        \n",
    "        if max_cp == min_cp:\n",
    "            dist_scores.append(0.5)\n",
    "            continue\n",
    "        dist = max(0, 1- (abs(move_cps[i])/abs(max_cp-min_cp)))#move_cps[i] - avg_cp\n",
    "        dist_scores.append(dist)\n",
    "        #percentile = float(better_than_cp)/min(float(total_cp), -1)\n",
    "        #dist_percentiles.append(percentile)\n",
    "    \n",
    "    return dist_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data_df(event):\n",
    "    data_df = get_perf_df(event)\n",
    "    data_df = data_df.drop_duplicates()\n",
    "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "    data_df = split_perfs(data_df)\n",
    "    data_df = convert_json_to_list(data_df)\n",
    "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elo_system_prediction(result, opp_elo):\n",
    "    k_factor = 40\n",
    "    base_elo = 1560\n",
    "    Ea = 1./(1.+10.**((opp_elo - base_elo)/400.))\n",
    "    Rnew = base_elo + k_factor*(float(result) - Ea)\n",
    "    return Rnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_games(X, y):\n",
    "    i = 0\n",
    "    while i < (len(X)):\n",
    "        if len(X[i]['cps']) < 30:\n",
    "            X.pop(i)\n",
    "            y.pop(i)\n",
    "            i -= 1\n",
    "        i+=1\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desired_data(complete_data_df, to_select = ['rank_percentiles', 'dist_percentiles', 'cps', 'result', 'opp_elo', 'acc_name', 'mates']):\n",
    "    i=0\n",
    "    X_selected_ldl = [] #X_selected_ldl is a list of dictionaries of lists, easiest way (i think) to track all the relevant data\n",
    "    y = []#elo targets\n",
    "    for index, row in complete_data_df.iterrows():\n",
    "        if i == 0:\n",
    "            print(index, row)\n",
    "        i += 1\n",
    "        row_dict = {}\n",
    "        \n",
    "        ch_moves = get_list_of_chosen_moves(row['chosen_evals'])\n",
    "        av_moves = get_list_of_list_of_available_moves(row['option_evals'])\n",
    "        \n",
    "        if 'rank_percentiles' in to_select:\n",
    "            rank_percentiles = get_list_of_rank_percentiles(ch_moves)\n",
    "            row_dict['rank_percentiles'] = rank_percentiles\n",
    "        if 'cps' in to_select: #TO ADD: cp percentiles (e.g., just how much worse would the worst move have been?)\n",
    "            cps = get_list_of_move_cps(ch_moves)\n",
    "            row_dict['cps'] = cps\n",
    "        if 'dist_percentiles' in to_select:\n",
    "            option_cps = get_list_of_option_cps(av_moves)\n",
    "            dis_percentiles = get_list_of_dist_percentiles(cps, option_cps)\n",
    "            row_dict['dist_percentiles'] = dis_percentiles\n",
    "        if 'opp_elo' in to_select:\n",
    "            row_dict['opp_elo'] = row['opp_elo']\n",
    "        if 'result' in to_select:\n",
    "            row_dict['result'] = row['result']\n",
    "        if 'acc_name' in to_select:\n",
    "            row_dict['acc_name'] = row['acc_name']\n",
    "        if 'mates' in to_select:\n",
    "            mates = get_list_of_move_mates(ch_moves)\n",
    "            row_dict['mates'] = mates\n",
    "        \n",
    "        elo = row['elo']\n",
    "        X_selected_ldl.append(row_dict)\n",
    "        y_entry = []\n",
    "        y_entry.append(elo)\n",
    "        elo_system_prediction = get_elo_system_prediction(row_dict['result'],row_dict['opp_elo'])\n",
    "        y_entry.append(int(elo_system_prediction))\n",
    "        y.append(y_entry)\n",
    "\n",
    "    return X_selected_ldl, y #X_selected_ldl is a list of dictionaries of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TabularizeMates(X_raw):\n",
    "    for x in X_raw:\n",
    "        found_mate = []\n",
    "        continued_mate = []\n",
    "        lost_mate = []\n",
    "        moved_into_mate = []\n",
    "        continued_being_mated = []\n",
    "\n",
    "        for m in x['mates']:  \n",
    "            found = 0\n",
    "            continued = 0\n",
    "            lost = 0\n",
    "            found_bad = 0\n",
    "            continued_bad = 0\n",
    "\n",
    "            if m != None:\n",
    "                if (m[0:2] == 'AB'):\n",
    "                    found = 1\n",
    "                if (m[0:2] == 'AC'):\n",
    "                    continued = 1\n",
    "                if (m[0:2] == 'AL'):\n",
    "                    lost = 1\n",
    "                if (m[0:2] == 'DB'):\n",
    "                    found_bad = 1\n",
    "                if (m[0:2] == 'DC'):\n",
    "                    continued_bad = 1    \n",
    "            found_mate.append(found)\n",
    "            continued_mate.append(continued)\n",
    "            lost_mate.append(lost)\n",
    "            moved_into_mate.append(found_bad)\n",
    "            continued_being_mated.append(continued_bad)\n",
    "\n",
    "        x['found_mate'] = found_mate\n",
    "        x['continued_mate'] = continued_mate\n",
    "        x['lost_mate'] = lost_mate\n",
    "        x['moved_into_mate'] = moved_into_mate\n",
    "        x['continued_being_mated'] = continued_being_mated\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RefineX(X_):\n",
    "    refined_X = []\n",
    "    for x in X_:\n",
    "        g = []\n",
    "        for i in range(len(x['cps'])):\n",
    "            m = []\n",
    "            m.append(min(10, x['cps'][i]))\n",
    "            m.append(x['dist_percentiles'][i])\n",
    "            m.append(x['rank_percentiles'][i])\n",
    "            m.append(x['found_mate'][i])\n",
    "            m.append(x['continued_mate'][i])\n",
    "            m.append(x['lost_mate'][i])\n",
    "            m.append(x['moved_into_mate'][i])\n",
    "            m.append(x['continued_being_mated'][i])\n",
    "            g.append(m)\n",
    "        refined_X.append(g)\n",
    "    return refined_X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLables(X_, Y_):\n",
    "    lables = []\n",
    "    for i in range(len(X_)):\n",
    "        single_lable = []\n",
    "        for _ in range(len(X_[i]['cps'])):\n",
    "            single_lable.append(Y_[i][0]) #the second item in Y[i] is the standard system prediction\n",
    "        lables.append(single_lable)\n",
    "    return lables\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(event = 'Rated Classical game'):\n",
    "    data_df = get_raw_data_df(event)\n",
    "    X, y = get_desired_data(data_df)\n",
    "    X, y = remove_short_games(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw, y_raw = get_data(event = 'Rated Classical game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularizeMates(X_raw)\n",
    "X_ = RefineX(X_raw)\n",
    "X = np.array([np.array(xi) for xi in X_])\n",
    "Y_ = CreateLables(X_raw, y_raw)\n",
    "Y = np.array([np.array(yi) for yi in Y_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=800, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt[0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed = []\n",
    "for each in Xt:\n",
    "    X_trimmed.append(each[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed = np.array(X_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_trimmed = []\n",
    "for each in Y:\n",
    "    Y_trimmed.append(each[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_trimmed = np.array(Y_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=800, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=500, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=500, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=1000, batch_size=64, validation_data=(X_trimmed_test, Y_trimmed_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=1000, batch_size=64, validation_data=(X_trimmed_test, Y_trimmed_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
