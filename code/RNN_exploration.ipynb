{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.uci\n",
    "import chess.pgn\n",
    "import os\n",
    "import csv\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import ast\n",
    "import pandas as pd\n",
    "import json\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perf_df(event = 'Rated Classical game'):\n",
    "    df = pd.read_csv(\"/Users/tylerahlstrom/Documents/GitHub/DI_proposal/stockfish_performances_DC.csv\")\n",
    "    df = df.drop(df[df.event != event].index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_perfs(joint_perf_df):\n",
    "    new_headers = ['elo', 'chosen_evals', 'option_evals', 'opp_elo', 'win', 'acc_name']\n",
    "    split_df = pd.DataFrame(columns = new_headers)\n",
    "    for index, row in joint_perf_df.iterrows():\n",
    "        if len(row['result']) is 3:\n",
    "            split_df = split_df.append({'elo': row['elo_w'], 'chosen_evals' : row['chosen_moves_eval_w'], 'option_evals' : row['available_moves_eval_w'], 'opp_elo': row['elo_b'], 'result': row['result'][0], 'acc_name': row['acc_name_w']}, ignore_index=True)\n",
    "            split_df = split_df.append({'elo': row['elo_b'], 'chosen_evals' : row['chosen_moves_eval_b'], 'option_evals' : row['available_moves_eval_b'], 'opp_elo': row['elo_w'], 'result': row['result'][2], 'acc_name': row['acc_name_b']}, ignore_index=True)\n",
    "    return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_list(df):\n",
    "    for index, row in df.iterrows():\n",
    "        row['chosen_evals'] = json.loads(row['chosen_evals'])\n",
    "        row['option_evals'] = json.loads(row['option_evals'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_chosen_moves(dict_of_move_dict): #e.g. {u'11': {u'move_rank': 2, u'cp_scor#\n",
    "    lol_of_moves = []\n",
    "    for key, d_move in dict_of_move_dict.items():\n",
    "        lol_of_moves.append([key, d_move])\n",
    "    lol_of_moves.sort(key=lambda x: int(x[0]))\n",
    "    return lol_of_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_list_of_available_moves(dict_of_options_dict): # e.g. {u'24': {u'd7e8': {u'cp_score': -674, u'mate_s...\n",
    "    lolol_of_options  = []\n",
    "    for key, d_options in dict_of_options_dict.items():\n",
    "        lol_of_options = []\n",
    "        for key2, d_option in d_options.items():\n",
    "            lol_of_options.append([key2, d_option])\n",
    "        lol_of_options.sort(key=lambda x: int(x[1]['rank']))\n",
    "    \n",
    "        lolol_of_options.append([key, lol_of_options])\n",
    "    lolol_of_options.sort(key=lambda x: int(x[0][0]))\n",
    "    return lolol_of_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_rank_percentiles(list_of_moves):\n",
    "    list_of_rank_percentiles = []\n",
    "    for move in list_of_moves:\n",
    "        rank = int(move[1]['move_rank'])\n",
    "        num_options = int(move[1]['num_move_options'])\n",
    "        chunk = float(1)/float(num_options)\n",
    "        percentile = 1.0 - (float(rank-1) * chunk)\n",
    "        list_of_rank_percentiles.append(percentile)\n",
    "    return list_of_rank_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_move_cps(list_of_moves):\n",
    "    list_of_cps = []\n",
    "    for move in list_of_moves:\n",
    "        cp = move[1]['cp_score']\n",
    "        list_of_cps.append(cp)\n",
    "    return list_of_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_move_mates(list_of_moves):\n",
    "    list_of_mates = []\n",
    "    for move in list_of_moves:\n",
    "        mate = move[1]['mate_score']\n",
    "        list_of_mates.append(mate)\n",
    "    return list_of_mates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_option_cps(list_of_av_moves):\n",
    "    #print(list_of_av_moves)\n",
    "    lol_of_option_cps = []\n",
    "    for move in list_of_av_moves:\n",
    "        options_cps = []\n",
    "        for option in move[1]:\n",
    "            options_cps.append(option[1]['cp_score'])\n",
    "        lol_of_option_cps.append(options_cps)\n",
    "    \n",
    "    #print(lol_of_option_cps)\n",
    "    return lol_of_option_cps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_dist_percentiles(move_cps, option_cps):\n",
    "    dist_scores = []\n",
    "    for i in range(len(move_cps)):\n",
    "        cp_temp = [x for x in option_cps[i] if x != None]\n",
    "        max_cp = None\n",
    "        min_cp = None\n",
    "        if (len(cp_temp) > 0):\n",
    "            max_cp = max(cp_temp)\n",
    "            min_cp = min(cp_temp)\n",
    "    \n",
    "        #avg_cp = sum([x for x in option_cps[i] if x is not None])/float((len([x for x in option_cps[i] if x is not None])+0.1))\n",
    "        if move_cps[i] is None:\n",
    "            move_cps[i] = -2000\n",
    "        if max_cp is None:\n",
    "            max_cp = -10\n",
    "        if min_cp is None:\n",
    "            min_cp = -200\n",
    "        \n",
    "        if max_cp == min_cp:\n",
    "            dist_scores.append(0.5)\n",
    "            continue\n",
    "        dist = max(0, 1- (abs(move_cps[i])/abs(max_cp-min_cp)))#move_cps[i] - avg_cp\n",
    "        dist_scores.append(dist)\n",
    "        #percentile = float(better_than_cp)/min(float(total_cp), -1)\n",
    "        #dist_percentiles.append(percentile)\n",
    "    \n",
    "    return dist_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data_df(event):\n",
    "    data_df = get_perf_df(event)\n",
    "    data_df = data_df.drop_duplicates()\n",
    "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "    data_df = split_perfs(data_df)\n",
    "    data_df = convert_json_to_list(data_df)\n",
    "    data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elo_system_prediction(result, opp_elo):\n",
    "    k_factor = 40\n",
    "    base_elo = 1560\n",
    "    Ea = 1./(1.+10.**((opp_elo - base_elo)/400.))\n",
    "    Rnew = base_elo + k_factor*(float(result) - Ea)\n",
    "    return Rnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_short_games(X, y):\n",
    "    i = 0\n",
    "    while i < (len(X)):\n",
    "        if len(X[i]['cps']) < 30:\n",
    "            X.pop(i)\n",
    "            y.pop(i)\n",
    "            i -= 1\n",
    "        i+=1\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desired_data(complete_data_df, to_select = ['rank_percentiles', 'dist_percentiles', 'cps', 'result', 'opp_elo', 'acc_name', 'mates']):\n",
    "    i=0\n",
    "    X_selected_ldl = [] #X_selected_ldl is a list of dictionaries of lists, easiest way (i think) to track all the relevant data\n",
    "    y = []#elo targets\n",
    "    for index, row in complete_data_df.iterrows():\n",
    "        if i == 0:\n",
    "            print(index, row)\n",
    "        i += 1\n",
    "        row_dict = {}\n",
    "        \n",
    "        ch_moves = get_list_of_chosen_moves(row['chosen_evals'])\n",
    "        av_moves = get_list_of_list_of_available_moves(row['option_evals'])\n",
    "        \n",
    "        if 'rank_percentiles' in to_select:\n",
    "            rank_percentiles = get_list_of_rank_percentiles(ch_moves)\n",
    "            row_dict['rank_percentiles'] = rank_percentiles\n",
    "        if 'cps' in to_select: #TO ADD: cp percentiles (e.g., just how much worse would the worst move have been?)\n",
    "            cps = get_list_of_move_cps(ch_moves)\n",
    "            row_dict['cps'] = cps\n",
    "        if 'dist_percentiles' in to_select:\n",
    "            option_cps = get_list_of_option_cps(av_moves)\n",
    "            dis_percentiles = get_list_of_dist_percentiles(cps, option_cps)\n",
    "            row_dict['dist_percentiles'] = dis_percentiles\n",
    "        if 'opp_elo' in to_select:\n",
    "            row_dict['opp_elo'] = row['opp_elo']\n",
    "        if 'result' in to_select:\n",
    "            row_dict['result'] = row['result']\n",
    "        if 'acc_name' in to_select:\n",
    "            row_dict['acc_name'] = row['acc_name']\n",
    "        if 'mates' in to_select:\n",
    "            mates = get_list_of_move_mates(ch_moves)\n",
    "            row_dict['mates'] = mates\n",
    "        \n",
    "        elo = row['elo']\n",
    "        X_selected_ldl.append(row_dict)\n",
    "        y_entry = []\n",
    "        y_entry.append(elo)\n",
    "        elo_system_prediction = get_elo_system_prediction(row_dict['result'],row_dict['opp_elo'])\n",
    "        y_entry.append(int(elo_system_prediction))\n",
    "        y.append(y_entry)\n",
    "\n",
    "    return X_selected_ldl, y #X_selected_ldl is a list of dictionaries of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TabularizeMates(X_raw):\n",
    "    for x in X_raw:\n",
    "        found_mate = []\n",
    "        continued_mate = []\n",
    "        lost_mate = []\n",
    "        moved_into_mate = []\n",
    "        continued_being_mated = []\n",
    "\n",
    "        for m in x['mates']:  \n",
    "            found = 0\n",
    "            continued = 0\n",
    "            lost = 0\n",
    "            found_bad = 0\n",
    "            continued_bad = 0\n",
    "\n",
    "            if m != None:\n",
    "                if (m[0:2] == 'AB'):\n",
    "                    found = 1\n",
    "                if (m[0:2] == 'AC'):\n",
    "                    continued = 1\n",
    "                if (m[0:2] == 'AL'):\n",
    "                    lost = 1\n",
    "                if (m[0:2] == 'DB'):\n",
    "                    found_bad = 1\n",
    "                if (m[0:2] == 'DC'):\n",
    "                    continued_bad = 1    \n",
    "            found_mate.append(found)\n",
    "            continued_mate.append(continued)\n",
    "            lost_mate.append(lost)\n",
    "            moved_into_mate.append(found_bad)\n",
    "            continued_being_mated.append(continued_bad)\n",
    "\n",
    "        x['found_mate'] = found_mate\n",
    "        x['continued_mate'] = continued_mate\n",
    "        x['lost_mate'] = lost_mate\n",
    "        x['moved_into_mate'] = moved_into_mate\n",
    "        x['continued_being_mated'] = continued_being_mated\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RefineX(X_):\n",
    "    refined_X = []\n",
    "    for x in X_:\n",
    "        g = []\n",
    "        for i in range(len(x['cps'])):\n",
    "            m = []\n",
    "            m.append(min(10, x['cps'][i]))\n",
    "            m.append(x['dist_percentiles'][i])\n",
    "            m.append(x['rank_percentiles'][i])\n",
    "            m.append(x['found_mate'][i])\n",
    "            m.append(x['continued_mate'][i])\n",
    "            m.append(x['lost_mate'][i])\n",
    "            m.append(x['moved_into_mate'][i])\n",
    "            m.append(x['continued_being_mated'][i])\n",
    "            g.append(m)\n",
    "        refined_X.append(g)\n",
    "    return refined_X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLables(X_, Y_):\n",
    "    lables = []\n",
    "    for i in range(len(X_)):\n",
    "        single_lable = []\n",
    "        for _ in range(len(X_[i]['cps'])):\n",
    "            single_lable.append(Y_[i][0]) #the second item in Y[i] is the standard system prediction\n",
    "        lables.append(single_lable)\n",
    "    return lables\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(event = 'Rated Classical game'):\n",
    "    data_df = get_raw_data_df(event)\n",
    "    X, y = get_desired_data(data_df)\n",
    "    X, y = remove_short_games(X, y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 elo                                                          1305\n",
      "chosen_evals    {'0': {'move': 'e2e4', 'move_rank': 1, 'num_mo...\n",
      "option_evals    {'0': {'e2e4': {'rank': 1, 'cp_score': -22, 'm...\n",
      "opp_elo                                                      1320\n",
      "win                                                           NaN\n",
      "acc_name                                             goodplayer93\n",
      "result                                                          1\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_raw, y_raw = get_data(event = 'Rated Classical game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_name': 'corporaldonut',\n",
       " 'cps': [-22,\n",
       "  -37,\n",
       "  -57,\n",
       "  -60,\n",
       "  -58,\n",
       "  -324,\n",
       "  -5,\n",
       "  -42,\n",
       "  -141,\n",
       "  -44,\n",
       "  -17,\n",
       "  -198,\n",
       "  -46,\n",
       "  -83,\n",
       "  0,\n",
       "  -440,\n",
       "  -132,\n",
       "  -7,\n",
       "  0,\n",
       "  -15,\n",
       "  -70,\n",
       "  -364,\n",
       "  -8,\n",
       "  -18,\n",
       "  25,\n",
       "  -2000,\n",
       "  -4742,\n",
       "  -18,\n",
       "  -14,\n",
       "  -49,\n",
       "  -5,\n",
       "  -492,\n",
       "  230,\n",
       "  -917,\n",
       "  -2000,\n",
       "  -2000,\n",
       "  -2000],\n",
       " 'dist_percentiles': [0.875,\n",
       "  0.9175946547884187,\n",
       "  0.8926553672316384,\n",
       "  0.9112426035502958,\n",
       "  0.9307048984468339,\n",
       "  0.7631578947368421,\n",
       "  0.9963503649635036,\n",
       "  0.9778364116094986,\n",
       "  0.8109919571045576,\n",
       "  0.9305993690851735,\n",
       "  0.983284169124877,\n",
       "  0.8123222748815166,\n",
       "  0.9098039215686274,\n",
       "  0.9236430542778289,\n",
       "  1.0,\n",
       "  0.7109067017082786,\n",
       "  0.899390243902439,\n",
       "  0.9947565543071161,\n",
       "  1.0,\n",
       "  0.9888309754281459,\n",
       "  0.9581589958158996,\n",
       "  0.7659163987138263,\n",
       "  0.9938744257274119,\n",
       "  0.9781818181818182,\n",
       "  0.9773755656108597,\n",
       "  0,\n",
       "  0,\n",
       "  0.9918330308529946,\n",
       "  0.9943865276663993,\n",
       "  0.7421052631578947,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.7032258064516129,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'mates': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'AC:11',\n",
       "  'AL:38',\n",
       "  'AL:152',\n",
       "  'AL:608',\n",
       "  'AL:2432',\n",
       "  'AL:9728',\n",
       "  'AL:38912',\n",
       "  'AL:155648',\n",
       "  'AL:622592',\n",
       "  'AC:5',\n",
       "  'AC:4',\n",
       "  'AC:0'],\n",
       " 'opp_elo': 1118,\n",
       " 'rank_percentiles': [1.0,\n",
       "  1.0,\n",
       "  0.7631578947368421,\n",
       "  0.7142857142857143,\n",
       "  0.8571428571428572,\n",
       "  0.875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9473684210526316,\n",
       "  0.935483870967742,\n",
       "  1.0,\n",
       "  0.6551724137931034,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.9333333333333333,\n",
       "  0.8947368421052632,\n",
       "  0.8571428571428572,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  0.9743589743589743,\n",
       "  0.975609756097561,\n",
       "  0.17948717948717952,\n",
       "  1.0,\n",
       "  0.9782608695652174,\n",
       "  1.0,\n",
       "  0.9787234042553191,\n",
       "  0.85,\n",
       "  0.8181818181818181,\n",
       "  0.6086956521739131,\n",
       "  0.8809523809523809,\n",
       "  1.0,\n",
       "  0.6041666666666667,\n",
       "  1.0,\n",
       "  0.675,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'result': '1'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "TabularizeMates(X_raw)\n",
    "X_ = RefineX(X_raw)\n",
    "X = np.array([np.array(xi) for xi in X_])\n",
    "Y_ = CreateLables(X_raw, y_raw)\n",
    "Y = np.array([np.array(yi) for yi in Y_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 8)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581],\n",
       " [1535, 1581]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_name': 'Xoal',\n",
       " 'cps': [-17,\n",
       "  -19,\n",
       "  -81,\n",
       "  -25,\n",
       "  -327,\n",
       "  -295,\n",
       "  -85,\n",
       "  -127,\n",
       "  -196,\n",
       "  -14,\n",
       "  -26,\n",
       "  -69,\n",
       "  -439,\n",
       "  -4,\n",
       "  -36,\n",
       "  -27,\n",
       "  -156,\n",
       "  -34,\n",
       "  -223,\n",
       "  -40,\n",
       "  -2000,\n",
       "  -2000,\n",
       "  -26,\n",
       "  -30,\n",
       "  -9,\n",
       "  -14,\n",
       "  -28,\n",
       "  -67,\n",
       "  -203,\n",
       "  -63,\n",
       "  -1673,\n",
       "  48,\n",
       "  -548,\n",
       "  -2000,\n",
       "  -2,\n",
       "  -40],\n",
       " 'dist_percentiles': [0.891025641025641,\n",
       "  0.9828519855595668,\n",
       "  0.9662077596996246,\n",
       "  0.9794745484400657,\n",
       "  0.7394422310756972,\n",
       "  0.7675334909377463,\n",
       "  0.9348659003831418,\n",
       "  0.9361488185017597,\n",
       "  0.8460329929300864,\n",
       "  0.9883817427385893,\n",
       "  0.8452380952380952,\n",
       "  0.9307228915662651,\n",
       "  0.6189236111111112,\n",
       "  0.9983606557377049,\n",
       "  0.8105263157894737,\n",
       "  0.9786223277909739,\n",
       "  0.7891891891891891,\n",
       "  0.7462686567164178,\n",
       "  0.956983024691358,\n",
       "  0.9722222222222222,\n",
       "  0,\n",
       "  0.6239894717052077,\n",
       "  0.995077622112836,\n",
       "  0.972875226039783,\n",
       "  0.9945913461538461,\n",
       "  0.9891975308641975,\n",
       "  0.9933030375508252,\n",
       "  0.9854821235102925,\n",
       "  0.5,\n",
       "  0.21250000000000002,\n",
       "  0,\n",
       "  0.9402985074626866,\n",
       "  0.5791090629800307,\n",
       "  0,\n",
       "  0.9912663755458515,\n",
       "  0.9750312109862672],\n",
       " 'mates': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'DB:-2',\n",
       "  'DC:-1',\n",
       "  'DL:-8',\n",
       "  'DL:-32',\n",
       "  'DL:-128',\n",
       "  'DL:-512',\n",
       "  'DL:-2048',\n",
       "  'DL:-8192',\n",
       "  'DL:-32768',\n",
       "  'DL:-131072',\n",
       "  'DL:-524288',\n",
       "  'DL:-2097152',\n",
       "  'DL:-8388608',\n",
       "  'DC:-23',\n",
       "  'DL:-67108910',\n",
       "  'DL:-268435640'],\n",
       " 'opp_elo': 1505,\n",
       " 'rank_percentiles': [1.0,\n",
       "  1.0,\n",
       "  0.8709677419354839,\n",
       "  0.9696969696969697,\n",
       "  0.21212121212121215,\n",
       "  0.9285714285714286,\n",
       "  0.8064516129032258,\n",
       "  0.6666666666666667,\n",
       "  0.33333333333333337,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.75,\n",
       "  0.4545454545454546,\n",
       "  0.9655172413793104,\n",
       "  0.967741935483871,\n",
       "  1.0,\n",
       "  0.7575757575757576,\n",
       "  0.9142857142857143,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.21212121212121215,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.8,\n",
       "  1.0,\n",
       "  0.8571428571428572,\n",
       "  0.9090909090909091,\n",
       "  0.7428571428571429,\n",
       "  0.6388888888888888,\n",
       "  0.972972972972973,\n",
       "  0.3999999999999999,\n",
       "  1.0,\n",
       "  0.7777777777777778,\n",
       "  0.72,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'result': '1'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 8)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 30, 50)            11800     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 30, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 52,251\n",
      "Trainable params: 52,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3333 samples, validate on 700 samples\n",
      "Epoch 1/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 339824.1829 - val_loss: 340384.2305\n",
      "Epoch 2/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 334659.8549 - val_loss: 335216.4898\n",
      "Epoch 3/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 329556.0507 - val_loss: 330109.7271\n",
      "Epoch 4/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 324510.9020 - val_loss: 325080.9311\n",
      "Epoch 5/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 319514.7916 - val_loss: 320064.2132\n",
      "Epoch 6/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 314562.4425 - val_loss: 315114.6329\n",
      "Epoch 7/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 309658.6476 - val_loss: 310220.6270\n",
      "Epoch 8/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 304807.9936 - val_loss: 305359.8162\n",
      "Epoch 9/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 300025.6061 - val_loss: 300575.7580\n",
      "Epoch 10/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 295283.6202 - val_loss: 295838.6286\n",
      "Epoch 11/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 290591.9075 - val_loss: 291151.9701\n",
      "Epoch 12/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 285957.6323 - val_loss: 286510.5577\n",
      "Epoch 13/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 281367.7219 - val_loss: 281923.1847\n",
      "Epoch 14/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 276833.7323 - val_loss: 277374.3812\n",
      "Epoch 15/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 272359.5139 - val_loss: 272903.4091\n",
      "Epoch 16/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 267927.2578 - val_loss: 268465.0057\n",
      "Epoch 17/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 263557.5075 - val_loss: 264109.6184\n",
      "Epoch 18/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 259236.4483 - val_loss: 259780.3913\n",
      "Epoch 19/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 254943.1098 - val_loss: 255485.5272\n",
      "Epoch 20/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 250706.1456 - val_loss: 251241.1303\n",
      "Epoch 21/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 246524.4231 - val_loss: 247064.3870\n",
      "Epoch 22/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 242397.1776 - val_loss: 242927.3364\n",
      "Epoch 23/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 238313.4985 - val_loss: 238863.0384\n",
      "Epoch 24/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 234282.9583 - val_loss: 234819.3149\n",
      "Epoch 25/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 230308.6322 - val_loss: 230853.9779\n",
      "Epoch 26/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 226395.8788 - val_loss: 226937.6605\n",
      "Epoch 27/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 222528.1966 - val_loss: 223064.4233\n",
      "Epoch 28/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 218705.8019 - val_loss: 219236.2933\n",
      "Epoch 29/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 214934.1367 - val_loss: 215475.5329\n",
      "Epoch 30/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 211210.0495 - val_loss: 211757.9297\n",
      "Epoch 31/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 207529.0695 - val_loss: 208061.9367\n",
      "Epoch 32/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 203899.4712 - val_loss: 204432.3327\n",
      "Epoch 33/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 200332.2691 - val_loss: 200862.8236\n",
      "Epoch 34/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 196797.2547 - val_loss: 197325.8662\n",
      "Epoch 35/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 193326.5327 - val_loss: 193862.2299\n",
      "Epoch 36/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 189906.0367 - val_loss: 190433.8556\n",
      "Epoch 37/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 186541.4823 - val_loss: 187067.4663\n",
      "Epoch 38/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 183219.7219 - val_loss: 183743.1212\n",
      "Epoch 39/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 179933.1618 - val_loss: 180458.7718\n",
      "Epoch 40/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 176699.9553 - val_loss: 177230.8997\n",
      "Epoch 41/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 173529.1747 - val_loss: 174049.8341\n",
      "Epoch 42/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 170408.4570 - val_loss: 170943.7756\n",
      "Epoch 43/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 167329.6661 - val_loss: 167841.5833\n",
      "Epoch 44/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 164287.8042 - val_loss: 164815.3292\n",
      "Epoch 45/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 161305.5420 - val_loss: 161821.6841\n",
      "Epoch 46/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 158382.5625 - val_loss: 158911.1233\n",
      "Epoch 47/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 155497.7966 - val_loss: 156011.2392\n",
      "Epoch 48/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 152664.5843 - val_loss: 153187.0817\n",
      "Epoch 49/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 149871.9786 - val_loss: 150383.3000\n",
      "Epoch 50/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 147138.2587 - val_loss: 147659.5103\n",
      "Epoch 51/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 144443.3862 - val_loss: 144961.9612\n",
      "Epoch 52/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 141796.0790 - val_loss: 142307.9344\n",
      "Epoch 53/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 139209.7695 - val_loss: 139719.3750\n",
      "Epoch 54/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 136661.9195 - val_loss: 137181.2235\n",
      "Epoch 55/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 134161.3985 - val_loss: 134665.1779\n",
      "Epoch 56/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 131716.0375 - val_loss: 132232.0283\n",
      "Epoch 57/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 129313.8888 - val_loss: 129813.9842\n",
      "Epoch 58/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 126958.7991 - val_loss: 127462.9547\n",
      "Epoch 59/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 124650.8745 - val_loss: 125146.9400\n",
      "Epoch 60/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 122391.2830 - val_loss: 122894.7894\n",
      "Epoch 61/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 120167.2341 - val_loss: 120660.0046\n",
      "Epoch 62/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 117999.7187 - val_loss: 118499.0971\n",
      "Epoch 63/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 115866.4230 - val_loss: 116361.5446\n",
      "Epoch 64/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 113777.0238 - val_loss: 114278.6686\n",
      "Epoch 65/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 111748.4185 - val_loss: 112243.4008\n",
      "Epoch 66/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 109770.9549 - val_loss: 110280.1586\n",
      "Epoch 67/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 107824.3538 - val_loss: 108308.2942\n",
      "Epoch 68/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 105920.5174 - val_loss: 106414.3323\n",
      "Epoch 69/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 104068.3134 - val_loss: 104562.3513\n",
      "Epoch 70/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 102266.5030 - val_loss: 102751.4800\n",
      "Epoch 71/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 100504.8709 - val_loss: 100997.5528\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333/3333 [==============================] - 5s 2ms/step - loss: 98789.4176 - val_loss: 99277.9290\n",
      "Epoch 73/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 97114.6669 - val_loss: 97607.1917\n",
      "Epoch 74/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 95487.0546 - val_loss: 95976.1718\n",
      "Epoch 75/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 93900.2639 - val_loss: 94382.4938\n",
      "Epoch 76/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 92363.5391 - val_loss: 92840.1822\n",
      "Epoch 77/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 90867.2743 - val_loss: 91349.2008\n",
      "Epoch 78/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 89401.0257 - val_loss: 89888.3326\n",
      "Epoch 79/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 87989.6545 - val_loss: 88463.0533\n",
      "Epoch 80/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 86613.5537 - val_loss: 87085.7158\n",
      "Epoch 81/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 85273.3329 - val_loss: 85740.8039\n",
      "Epoch 82/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 83978.5189 - val_loss: 84448.0168\n",
      "Epoch 83/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 82718.7442 - val_loss: 83182.2240\n",
      "Epoch 84/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 81512.6576 - val_loss: 81983.1093\n",
      "Epoch 85/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 80333.9908 - val_loss: 80800.0790\n",
      "Epoch 86/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 79195.5655 - val_loss: 79647.7695\n",
      "Epoch 87/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 78105.1339 - val_loss: 78567.4370\n",
      "Epoch 88/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 77052.5962 - val_loss: 77512.3830\n",
      "Epoch 89/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 76042.5657 - val_loss: 76500.2398\n",
      "Epoch 90/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 75064.8163 - val_loss: 75520.2721\n",
      "Epoch 91/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 74127.2556 - val_loss: 74576.3606\n",
      "Epoch 92/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 73224.6938 - val_loss: 73671.1414\n",
      "Epoch 93/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 72355.1282 - val_loss: 72797.1544\n",
      "Epoch 94/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 71526.5425 - val_loss: 71972.3782\n",
      "Epoch 95/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 70729.3038 - val_loss: 71180.3913\n",
      "Epoch 96/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 69970.3072 - val_loss: 70406.4979\n",
      "Epoch 97/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 69234.6653 - val_loss: 69679.0173\n",
      "Epoch 98/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 68544.4946 - val_loss: 68987.7820\n",
      "Epoch 99/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 67887.1529 - val_loss: 68314.4554\n",
      "Epoch 100/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 67262.4105 - val_loss: 67698.6318\n",
      "Epoch 101/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 66672.5549 - val_loss: 67092.7404\n",
      "Epoch 102/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 66107.6341 - val_loss: 66539.5845\n",
      "Epoch 103/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 65582.9931 - val_loss: 66008.8899\n",
      "Epoch 104/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 65074.8885 - val_loss: 65486.6023\n",
      "Epoch 105/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 64600.9502 - val_loss: 65020.2596\n",
      "Epoch 106/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 64162.9746 - val_loss: 64565.4966\n",
      "Epoch 107/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 63749.4559 - val_loss: 64159.9805\n",
      "Epoch 108/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 63367.7859 - val_loss: 63778.2539\n",
      "Epoch 109/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 63003.3020 - val_loss: 63401.6341\n",
      "Epoch 110/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 62670.3649 - val_loss: 63067.2976\n",
      "Epoch 111/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 62362.9595 - val_loss: 62758.8339\n",
      "Epoch 112/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 62075.8448 - val_loss: 62472.7398\n",
      "Epoch 113/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 61802.0826 - val_loss: 62185.8982\n",
      "Epoch 114/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 61555.2490 - val_loss: 61939.9546\n",
      "Epoch 115/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 61335.8384 - val_loss: 61712.7823\n",
      "Epoch 116/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 61129.3141 - val_loss: 61505.7037\n",
      "Epoch 117/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60944.0571 - val_loss: 61316.9858\n",
      "Epoch 118/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60777.1949 - val_loss: 61145.0404\n",
      "Epoch 119/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60626.0216 - val_loss: 60988.6736\n",
      "Epoch 120/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60489.0915 - val_loss: 60847.8652\n",
      "Epoch 121/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60362.6887 - val_loss: 60711.3923\n",
      "Epoch 122/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60252.7980 - val_loss: 60600.7955\n",
      "Epoch 123/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60150.8477 - val_loss: 60493.7671\n",
      "Epoch 124/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 60060.8800 - val_loss: 60401.1439\n",
      "Epoch 125/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59982.9201 - val_loss: 60316.8155\n",
      "Epoch 126/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59914.8672 - val_loss: 60244.7466\n",
      "Epoch 127/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59854.9246 - val_loss: 60178.7885\n",
      "Epoch 128/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59802.6856 - val_loss: 60123.0645\n",
      "Epoch 129/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59759.1093 - val_loss: 60074.8468\n",
      "Epoch 130/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59722.2491 - val_loss: 60036.6868\n",
      "Epoch 131/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59690.4434 - val_loss: 59998.4595\n",
      "Epoch 132/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59663.5867 - val_loss: 59968.4598\n",
      "Epoch 133/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59641.9733 - val_loss: 59946.5206\n",
      "Epoch 134/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59620.0879 - val_loss: 59920.1156\n",
      "Epoch 135/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59600.7629 - val_loss: 59895.0650\n",
      "Epoch 136/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59587.6962 - val_loss: 59879.8775\n",
      "Epoch 137/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59577.4211 - val_loss: 59867.0866\n",
      "Epoch 138/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59568.6312 - val_loss: 59856.1965\n",
      "Epoch 139/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 59560.7321 - val_loss: 59843.7058\n",
      "Epoch 140/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 59554.1824 - val_loss: 59835.6735\n",
      "Epoch 141/200\n",
      "3333/3333 [==============================] - 6s 2ms/step - loss: 59548.6646 - val_loss: 59826.7901\n",
      "Epoch 142/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59542.7065 - val_loss: 59818.5233\n",
      "Epoch 143/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59539.2166 - val_loss: 59813.1215\n",
      "Epoch 144/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59537.2932 - val_loss: 59808.4540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59535.2985 - val_loss: 59806.1896\n",
      "Epoch 146/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59532.1631 - val_loss: 59802.3877\n",
      "Epoch 147/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59532.2126 - val_loss: 59797.8238\n",
      "Epoch 148/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59530.4294 - val_loss: 59796.5341\n",
      "Epoch 149/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59529.6497 - val_loss: 59795.3472\n",
      "Epoch 150/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59528.5794 - val_loss: 59795.3809\n",
      "Epoch 151/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59527.0939 - val_loss: 59793.3045\n",
      "Epoch 152/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59527.0841 - val_loss: 59791.7524\n",
      "Epoch 153/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59526.5133 - val_loss: 59788.2763\n",
      "Epoch 154/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59526.4541 - val_loss: 59789.5452\n",
      "Epoch 155/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59526.0761 - val_loss: 59786.5647\n",
      "Epoch 156/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.6960 - val_loss: 59785.6821\n",
      "Epoch 157/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.6127 - val_loss: 59785.7206\n",
      "Epoch 158/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.3141 - val_loss: 59785.0137\n",
      "Epoch 159/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59525.1714 - val_loss: 59785.9598\n",
      "Epoch 160/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.9487 - val_loss: 59783.5365\n",
      "Epoch 161/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.5413 - val_loss: 59785.4162\n",
      "Epoch 162/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59525.1693 - val_loss: 59785.0066\n",
      "Epoch 163/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.5928 - val_loss: 59784.3489\n",
      "Epoch 164/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.3136 - val_loss: 59782.5592\n",
      "Epoch 165/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.2503 - val_loss: 59782.5516\n",
      "Epoch 166/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.7586 - val_loss: 59781.7644\n",
      "Epoch 167/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.0446 - val_loss: 59779.6385\n",
      "Epoch 168/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.3492 - val_loss: 59779.9890\n",
      "Epoch 169/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.5422 - val_loss: 59780.2886\n",
      "Epoch 170/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.2293 - val_loss: 59780.8523\n",
      "Epoch 171/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.4213 - val_loss: 59781.6056\n",
      "Epoch 172/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.9360 - val_loss: 59780.7519\n",
      "Epoch 173/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.7404 - val_loss: 59781.7853\n",
      "Epoch 174/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.9836 - val_loss: 59781.7767\n",
      "Epoch 175/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59525.0704 - val_loss: 59781.7958\n",
      "Epoch 176/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59524.4713 - val_loss: 59781.7313\n",
      "Epoch 177/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59525.1113 - val_loss: 59780.3088\n",
      "Epoch 178/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59525.3308 - val_loss: 59780.4077\n",
      "Epoch 179/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59525.8309 - val_loss: 59779.4013\n",
      "Epoch 180/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.8613 - val_loss: 59779.5743\n",
      "Epoch 181/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.8124 - val_loss: 59779.6317\n",
      "Epoch 182/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.0008 - val_loss: 59779.7502\n",
      "Epoch 183/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.0948 - val_loss: 59780.0801\n",
      "Epoch 184/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.8556 - val_loss: 59780.8756\n",
      "Epoch 185/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.2494 - val_loss: 59781.0745\n",
      "Epoch 186/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.2808 - val_loss: 59780.2380\n",
      "Epoch 187/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.9886 - val_loss: 59781.0402\n",
      "Epoch 188/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.3259 - val_loss: 59780.3445\n",
      "Epoch 189/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.5225 - val_loss: 59780.6564\n",
      "Epoch 190/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.7719 - val_loss: 59780.2200\n",
      "Epoch 191/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59525.6852 - val_loss: 59781.0719\n",
      "Epoch 192/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.4678 - val_loss: 59781.2050\n",
      "Epoch 193/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59525.7651 - val_loss: 59779.9886\n",
      "Epoch 194/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59523.7476 - val_loss: 59780.7316\n",
      "Epoch 195/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.9046 - val_loss: 59781.0097\n",
      "Epoch 196/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59524.6910 - val_loss: 59780.4611\n",
      "Epoch 197/200\n",
      "3333/3333 [==============================] - 5s 2ms/step - loss: 59525.9867 - val_loss: 59779.8610\n",
      "Epoch 198/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.4485 - val_loss: 59779.2031\n",
      "Epoch 199/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59523.5370 - val_loss: 59778.4721\n",
      "Epoch 200/200\n",
      "3333/3333 [==============================] - 5s 1ms/step - loss: 59524.6664 - val_loss: 59777.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd4d96d8>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=800, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-22.        ,   0.875     ,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [-37.        ,   0.91759465,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt[0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed = []\n",
    "for each in Xt:\n",
    "    X_trimmed.append(each[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed = np.array(X_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4033, 30, 8)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_trimmed = []\n",
    "for each in Y:\n",
    "    Y_trimmed.append(each[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_trimmed = np.array(Y_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4033, 1)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 30, 50)            11800     \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 30, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 52,251\n",
      "Trainable params: 52,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3633 samples, validate on 400 samples\n",
      "Epoch 1/800\n",
      "3633/3633 [==============================] - 9s 2ms/step - loss: 2470330.6026 - val_loss: 2461056.0000\n",
      "Epoch 2/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2445193.6722 - val_loss: 2442371.1900\n",
      "Epoch 3/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2426982.2673 - val_loss: 2424485.3800\n",
      "Epoch 4/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2409291.4803 - val_loss: 2406951.5500\n",
      "Epoch 5/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2391893.1007 - val_loss: 2389648.2800\n",
      "Epoch 6/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2374690.5869 - val_loss: 2372520.2400\n",
      "Epoch 7/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2357649.8404 - val_loss: 2355544.0200\n",
      "Epoch 8/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2340738.8465 - val_loss: 2338679.5100\n",
      "Epoch 9/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2323953.5559 - val_loss: 2321917.1000\n",
      "Epoch 10/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2307273.1861 - val_loss: 2305302.6500\n",
      "Epoch 11/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2290699.5316 - val_loss: 2288758.6400\n",
      "Epoch 12/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2274221.3587 - val_loss: 2272329.5900\n",
      "Epoch 13/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2257838.6177 - val_loss: 2255971.8300\n",
      "Epoch 14/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2241540.5050 - val_loss: 2239704.4500\n",
      "Epoch 15/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2225326.2432 - val_loss: 2223522.6400\n",
      "Epoch 16/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2209196.8648 - val_loss: 2207420.5700\n",
      "Epoch 17/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2193147.9920 - val_loss: 2191402.1900\n",
      "Epoch 18/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2177176.3526 - val_loss: 2175461.5900\n",
      "Epoch 19/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2161285.7747 - val_loss: 2159593.9900\n",
      "Epoch 20/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2145471.3132 - val_loss: 2143812.3100\n",
      "Epoch 21/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2129734.9665 - val_loss: 2128090.1100\n",
      "Epoch 22/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2114068.6386 - val_loss: 2112457.7400\n",
      "Epoch 23/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2098480.3832 - val_loss: 2096875.6300\n",
      "Epoch 24/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2082963.5249 - val_loss: 2081404.6200\n",
      "Epoch 25/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2067513.4575 - val_loss: 2065972.3100\n",
      "Epoch 26/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2052137.3605 - val_loss: 2050625.7200\n",
      "Epoch 27/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2036823.3261 - val_loss: 2035338.8100\n",
      "Epoch 28/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2021578.9108 - val_loss: 2020116.6900\n",
      "Epoch 29/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 2006397.9158 - val_loss: 2004958.0000\n",
      "Epoch 30/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1991286.8514 - val_loss: 1989870.3300\n",
      "Epoch 31/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1976242.1029 - val_loss: 1974842.6300\n",
      "Epoch 32/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1961265.8356 - val_loss: 1959875.9700\n",
      "Epoch 33/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1946355.7470 - val_loss: 1944999.7000\n",
      "Epoch 34/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1931515.0363 - val_loss: 1930178.6100\n",
      "Epoch 35/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1916738.8717 - val_loss: 1915423.4000\n",
      "Epoch 36/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1902020.8658 - val_loss: 1900739.9500\n",
      "Epoch 37/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1887369.5171 - val_loss: 1886112.8600\n",
      "Epoch 38/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1872777.6475 - val_loss: 1871526.2600\n",
      "Epoch 39/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1858247.5132 - val_loss: 1857019.4700\n",
      "Epoch 40/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1843789.4072 - val_loss: 1842584.0600\n",
      "Epoch 41/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1829391.0872 - val_loss: 1828214.8000\n",
      "Epoch 42/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1815056.8078 - val_loss: 1813877.5400\n",
      "Epoch 43/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1800780.3977 - val_loss: 1799633.5100\n",
      "Epoch 44/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1786571.7427 - val_loss: 1785437.0100\n",
      "Epoch 45/800\n",
      "3633/3633 [==============================] - 5s 2ms/step - loss: 1772424.0785 - val_loss: 1771316.4000\n",
      "Epoch 46/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1758337.0722 - val_loss: 1757245.2850\n",
      "Epoch 47/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1744308.7549 - val_loss: 1743253.8300\n",
      "Epoch 48/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1730348.1606 - val_loss: 1729288.8700\n",
      "Epoch 49/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1716440.2196 - val_loss: 1715417.9950\n",
      "Epoch 50/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1702593.7572 - val_loss: 1701598.1650\n",
      "Epoch 51/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1688814.5554 - val_loss: 1687819.8500\n",
      "Epoch 52/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1675092.0985 - val_loss: 1674128.2100\n",
      "Epoch 53/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1661433.4432 - val_loss: 1660492.6700\n",
      "Epoch 54/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1647833.2986 - val_loss: 1646900.8450\n",
      "Epoch 55/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1634293.4029 - val_loss: 1633379.3800\n",
      "Epoch 56/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1620817.7090 - val_loss: 1619937.1800\n",
      "Epoch 57/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1607401.9068 - val_loss: 1606524.8200\n",
      "Epoch 58/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1594043.5833 - val_loss: 1593194.3100\n",
      "Epoch 59/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1580742.7222 - val_loss: 1579916.5450\n",
      "Epoch 60/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1567508.7941 - val_loss: 1566702.2400\n",
      "Epoch 61/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1554336.3995 - val_loss: 1553542.8100\n",
      "Epoch 62/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1541220.0598 - val_loss: 1540446.4700\n",
      "Epoch 63/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1528167.8891 - val_loss: 1527412.6850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1515175.5196 - val_loss: 1514441.8700\n",
      "Epoch 65/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1502237.6261 - val_loss: 1501524.4300\n",
      "Epoch 66/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1489363.3451 - val_loss: 1488661.7100\n",
      "Epoch 67/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1476545.5187 - val_loss: 1475886.3900\n",
      "Epoch 68/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1463793.3004 - val_loss: 1463137.9150\n",
      "Epoch 69/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1451098.6546 - val_loss: 1450447.1800\n",
      "Epoch 70/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1438468.7706 - val_loss: 1437854.8600\n",
      "Epoch 71/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1425898.8823 - val_loss: 1425297.4350\n",
      "Epoch 72/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1413387.3492 - val_loss: 1412802.4100\n",
      "Epoch 73/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1400929.7268 - val_loss: 1400374.8000\n",
      "Epoch 74/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1388533.1903 - val_loss: 1387996.5100\n",
      "Epoch 75/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1376198.0330 - val_loss: 1375673.5600\n",
      "Epoch 76/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1363927.8779 - val_loss: 1363435.3150\n",
      "Epoch 77/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1351717.1899 - val_loss: 1351229.0200\n",
      "Epoch 78/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1339559.9886 - val_loss: 1339098.4550\n",
      "Epoch 79/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1327464.6744 - val_loss: 1327016.0750\n",
      "Epoch 80/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1315433.3413 - val_loss: 1315002.4600\n",
      "Epoch 81/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1303457.1561 - val_loss: 1303046.1300\n",
      "Epoch 82/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1291544.8178 - val_loss: 1291151.2500\n",
      "Epoch 83/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1279688.9816 - val_loss: 1279311.4750\n",
      "Epoch 84/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1267898.5650 - val_loss: 1267541.1100\n",
      "Epoch 85/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1256163.8887 - val_loss: 1255831.1700\n",
      "Epoch 86/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1244490.4551 - val_loss: 1244173.3400\n",
      "Epoch 87/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1232873.7915 - val_loss: 1232573.2400\n",
      "Epoch 88/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1221313.8463 - val_loss: 1221055.0900\n",
      "Epoch 89/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1209814.5034 - val_loss: 1209555.4650\n",
      "Epoch 90/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1198374.7586 - val_loss: 1198136.9100\n",
      "Epoch 91/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1186992.0880 - val_loss: 1186784.4700\n",
      "Epoch 92/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1175676.3617 - val_loss: 1175461.5300\n",
      "Epoch 93/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1164415.6558 - val_loss: 1164237.5150\n",
      "Epoch 94/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1153220.4299 - val_loss: 1153059.2850\n",
      "Epoch 95/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1142079.8358 - val_loss: 1141924.3900\n",
      "Epoch 96/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1130998.6210 - val_loss: 1130883.8150\n",
      "Epoch 97/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1119976.4712 - val_loss: 1119878.7850\n",
      "Epoch 98/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1109014.4108 - val_loss: 1108923.2700\n",
      "Epoch 99/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1098111.4751 - val_loss: 1098047.1950\n",
      "Epoch 100/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1087272.4459 - val_loss: 1087222.5750\n",
      "Epoch 101/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1076489.3487 - val_loss: 1076453.7050\n",
      "Epoch 102/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1065764.0908 - val_loss: 1065757.2550\n",
      "Epoch 103/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1055098.3049 - val_loss: 1055108.2700\n",
      "Epoch 104/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1044492.2775 - val_loss: 1044519.1600\n",
      "Epoch 105/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1033950.1647 - val_loss: 1033984.5550\n",
      "Epoch 106/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1023460.3104 - val_loss: 1023534.4250\n",
      "Epoch 107/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1013036.0755 - val_loss: 1013120.2600\n",
      "Epoch 108/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 1002669.2186 - val_loss: 1002766.5550\n",
      "Epoch 109/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 992359.9217 - val_loss: 992493.4500\n",
      "Epoch 110/800\n",
      "3633/3633 [==============================] - 5s 2ms/step - loss: 982111.9032 - val_loss: 982252.2350\n",
      "Epoch 111/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 971918.9615 - val_loss: 972091.5350\n",
      "Epoch 112/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 961788.7960 - val_loss: 961968.2850\n",
      "Epoch 113/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 951714.4666 - val_loss: 951926.3650\n",
      "Epoch 114/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 941700.8776 - val_loss: 941934.6700\n",
      "Epoch 115/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 931746.7815 - val_loss: 931995.1450\n",
      "Epoch 116/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 921853.6135 - val_loss: 922119.6300\n",
      "Epoch 117/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 912016.9681 - val_loss: 912304.6300\n",
      "Epoch 118/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 902237.6895 - val_loss: 902517.3900\n",
      "Epoch 119/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 892524.5862 - val_loss: 892837.8050\n",
      "Epoch 120/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 882868.8303 - val_loss: 883198.1625\n",
      "Epoch 121/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 873274.2737 - val_loss: 873617.1225\n",
      "Epoch 122/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 863736.4846 - val_loss: 864115.9300\n",
      "Epoch 123/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 854262.0155 - val_loss: 854642.1550\n",
      "Epoch 124/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 844837.2019 - val_loss: 845248.9650\n",
      "Epoch 125/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 835475.1710 - val_loss: 835898.3025\n",
      "Epoch 126/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 826170.6844 - val_loss: 826627.7425\n",
      "Epoch 127/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 816927.5725 - val_loss: 817381.4100\n",
      "Epoch 128/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 807744.1288 - val_loss: 808220.8625\n",
      "Epoch 129/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 798621.6230 - val_loss: 799134.1350\n",
      "Epoch 130/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 789558.2401 - val_loss: 790074.1050\n",
      "Epoch 131/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 780550.2331 - val_loss: 781092.9600\n",
      "Epoch 132/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 771600.4427 - val_loss: 772172.3525\n",
      "Epoch 133/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 762711.4199 - val_loss: 763285.4300\n",
      "Epoch 134/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 753878.7710 - val_loss: 754471.0575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 745104.1514 - val_loss: 745731.0800\n",
      "Epoch 136/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 736391.5810 - val_loss: 737027.7375\n",
      "Epoch 137/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 727738.1167 - val_loss: 728385.7000\n",
      "Epoch 138/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 719142.7392 - val_loss: 719811.4250\n",
      "Epoch 139/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 710604.7989 - val_loss: 711307.2350\n",
      "Epoch 140/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 702124.0035 - val_loss: 702837.8625\n",
      "Epoch 141/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 693703.5964 - val_loss: 694428.9175\n",
      "Epoch 142/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 685341.3723 - val_loss: 686095.0875\n",
      "Epoch 143/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 677036.3230 - val_loss: 677804.9575\n",
      "Epoch 144/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 668793.2130 - val_loss: 669572.2950\n",
      "Epoch 145/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 660608.6159 - val_loss: 661411.5500\n",
      "Epoch 146/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 652479.4001 - val_loss: 653315.0375\n",
      "Epoch 147/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 644413.3036 - val_loss: 645243.3300\n",
      "Epoch 148/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 636406.7184 - val_loss: 637250.0000\n",
      "Epoch 149/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 628455.6005 - val_loss: 629347.5400\n",
      "Epoch 150/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 620560.9144 - val_loss: 621450.9775\n",
      "Epoch 151/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 612722.0584 - val_loss: 613644.2350\n",
      "Epoch 152/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 604943.5514 - val_loss: 605882.7725\n",
      "Epoch 153/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 597222.9453 - val_loss: 598169.3950\n",
      "Epoch 154/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 589565.1545 - val_loss: 590541.3550\n",
      "Epoch 155/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 581963.1027 - val_loss: 582951.7400\n",
      "Epoch 156/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 574422.0040 - val_loss: 575433.0200\n",
      "Epoch 157/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 566937.1721 - val_loss: 567963.6950\n",
      "Epoch 158/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 559511.7473 - val_loss: 560561.0100\n",
      "Epoch 159/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 552146.3212 - val_loss: 553209.2300\n",
      "Epoch 160/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 544836.1516 - val_loss: 545913.9925\n",
      "Epoch 161/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 537584.5944 - val_loss: 538673.9925\n",
      "Epoch 162/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 530396.9176 - val_loss: 531526.3925\n",
      "Epoch 163/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 523260.7840 - val_loss: 524398.3575\n",
      "Epoch 164/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 516180.2572 - val_loss: 517334.2225\n",
      "Epoch 165/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 509157.8200 - val_loss: 510334.2725\n",
      "Epoch 166/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 502192.1467 - val_loss: 503382.0925\n",
      "Epoch 167/800\n",
      "3633/3633 [==============================] - 5s 2ms/step - loss: 495283.6592 - val_loss: 496500.6375\n",
      "Epoch 168/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 488434.2303 - val_loss: 489657.8200\n",
      "Epoch 169/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 481647.6251 - val_loss: 482894.7250\n",
      "Epoch 170/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 474914.5371 - val_loss: 476179.5600\n",
      "Epoch 171/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 468243.8332 - val_loss: 469524.4375\n",
      "Epoch 172/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 461628.1890 - val_loss: 462933.9700\n",
      "Epoch 173/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 455070.0840 - val_loss: 456385.5875\n",
      "Epoch 174/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 448570.9334 - val_loss: 449919.1575\n",
      "Epoch 175/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 442128.2358 - val_loss: 443488.7575\n",
      "Epoch 176/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 435741.6468 - val_loss: 437111.8800\n",
      "Epoch 177/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 429416.0464 - val_loss: 430807.5725\n",
      "Epoch 178/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 423143.6881 - val_loss: 424559.0725\n",
      "Epoch 179/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 416930.1741 - val_loss: 418370.5725\n",
      "Epoch 180/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 410773.2475 - val_loss: 412228.2213\n",
      "Epoch 181/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 404674.5118 - val_loss: 406140.9813\n",
      "Epoch 182/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 398632.3162 - val_loss: 400122.0250\n",
      "Epoch 183/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 392648.3255 - val_loss: 394168.5600\n",
      "Epoch 184/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 386723.9387 - val_loss: 388231.1262\n",
      "Epoch 185/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 380854.3489 - val_loss: 382398.2750\n",
      "Epoch 186/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 375047.8941 - val_loss: 376606.5887\n",
      "Epoch 187/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 369298.5034 - val_loss: 370881.4338\n",
      "Epoch 188/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 363601.2434 - val_loss: 365204.0513\n",
      "Epoch 189/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 357957.9488 - val_loss: 359583.8575\n",
      "Epoch 190/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 352374.8790 - val_loss: 354004.4450\n",
      "Epoch 191/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 346841.2026 - val_loss: 348492.0775\n",
      "Epoch 192/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 341371.5544 - val_loss: 343047.5850\n",
      "Epoch 193/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 335957.0961 - val_loss: 337651.3475\n",
      "Epoch 194/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 330597.3525 - val_loss: 332306.3713\n",
      "Epoch 195/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 325295.0318 - val_loss: 327023.3850\n",
      "Epoch 196/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 320050.2392 - val_loss: 321796.6213\n",
      "Epoch 197/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 314862.2868 - val_loss: 316615.0062\n",
      "Epoch 198/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 309734.9294 - val_loss: 311507.5012\n",
      "Epoch 199/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 304662.3280 - val_loss: 306470.6725\n",
      "Epoch 200/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 299647.5794 - val_loss: 301441.6500\n",
      "Epoch 201/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 294686.7102 - val_loss: 296514.9525\n",
      "Epoch 202/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 289784.2471 - val_loss: 291630.3563\n",
      "Epoch 203/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 284937.7609 - val_loss: 286797.9975\n",
      "Epoch 204/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 280145.1715 - val_loss: 282027.2037\n",
      "Epoch 205/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 275414.2916 - val_loss: 277297.3025\n",
      "Epoch 206/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 270735.5517 - val_loss: 272669.0625\n",
      "Epoch 207/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 266113.3983 - val_loss: 268047.0812\n",
      "Epoch 208/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 261543.0858 - val_loss: 263498.9387\n",
      "Epoch 209/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 257032.1893 - val_loss: 259009.8050\n",
      "Epoch 210/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 252575.7393 - val_loss: 254565.1800\n",
      "Epoch 211/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 248172.4843 - val_loss: 250187.1788\n",
      "Epoch 212/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 243826.6637 - val_loss: 245852.8588\n",
      "Epoch 213/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 239535.0986 - val_loss: 241582.6250\n",
      "Epoch 214/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 235302.8091 - val_loss: 237361.9037\n",
      "Epoch 215/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 231120.9135 - val_loss: 233204.7462\n",
      "Epoch 216/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 226997.3502 - val_loss: 229101.5975\n",
      "Epoch 217/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 222931.3435 - val_loss: 225039.1288\n",
      "Epoch 218/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 218917.0081 - val_loss: 221052.4931\n",
      "Epoch 219/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 214958.0436 - val_loss: 217107.7775\n",
      "Epoch 220/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 211052.8613 - val_loss: 213212.3025\n",
      "Epoch 221/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 207200.9806 - val_loss: 209402.1950\n",
      "Epoch 222/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 203405.8224 - val_loss: 205608.0981\n",
      "Epoch 223/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 199665.8259 - val_loss: 201880.8881\n",
      "Epoch 224/800\n",
      "3633/3633 [==============================] - 6s 2ms/step - loss: 195981.3968 - val_loss: 198228.0506\n",
      "Epoch 225/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 192351.4977 - val_loss: 194607.3325\n",
      "Epoch 226/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 188774.7779 - val_loss: 191051.8569\n",
      "Epoch 227/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 185253.2161 - val_loss: 187543.0875\n",
      "Epoch 228/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 181784.1158 - val_loss: 184092.5131\n",
      "Epoch 229/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 178369.9344 - val_loss: 180701.2288\n",
      "Epoch 230/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 175012.6564 - val_loss: 177349.9106\n",
      "Epoch 231/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 171705.8229 - val_loss: 174055.7800\n",
      "Epoch 232/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 168453.9351 - val_loss: 170827.1125\n",
      "Epoch 233/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 165257.1102 - val_loss: 167660.2838\n",
      "Epoch 234/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 162110.4002 - val_loss: 164522.5344\n",
      "Epoch 235/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 159016.3418 - val_loss: 161447.3031\n",
      "Epoch 236/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 155978.8063 - val_loss: 158415.3788\n",
      "Epoch 237/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 152992.6893 - val_loss: 155447.7013\n",
      "Epoch 238/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 150059.5501 - val_loss: 152535.7662\n",
      "Epoch 239/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 147179.3703 - val_loss: 149665.7381\n",
      "Epoch 240/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 144355.3533 - val_loss: 146859.3775\n",
      "Epoch 241/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 141580.7497 - val_loss: 144112.2881\n",
      "Epoch 242/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 138862.6906 - val_loss: 141389.5875\n",
      "Epoch 243/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 136190.7073 - val_loss: 138753.1306\n",
      "Epoch 244/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 133572.1328 - val_loss: 136155.0275\n",
      "Epoch 245/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 131004.3219 - val_loss: 133582.9919\n",
      "Epoch 246/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 128491.0036 - val_loss: 131096.3888\n",
      "Epoch 247/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 126030.0490 - val_loss: 128647.6250\n",
      "Epoch 248/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 123620.8751 - val_loss: 126257.3306\n",
      "Epoch 249/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 121261.5508 - val_loss: 123918.6212\n",
      "Epoch 250/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 118949.9048 - val_loss: 121622.0525\n",
      "Epoch 251/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 116689.7789 - val_loss: 119373.8788\n",
      "Epoch 252/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 114484.2167 - val_loss: 117189.5859\n",
      "Epoch 253/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 112327.5877 - val_loss: 115038.5975\n",
      "Epoch 254/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 110217.4030 - val_loss: 112956.1247\n",
      "Epoch 255/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 108159.4616 - val_loss: 110909.1575\n",
      "Epoch 256/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 106149.2845 - val_loss: 108910.3019\n",
      "Epoch 257/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 104192.3366 - val_loss: 106968.8669\n",
      "Epoch 258/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 102279.4951 - val_loss: 105084.0681\n",
      "Epoch 259/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 100418.1925 - val_loss: 103230.6316\n",
      "Epoch 260/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 98604.7814 - val_loss: 101430.5231\n",
      "Epoch 261/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 96838.3906 - val_loss: 99691.1531\n",
      "Epoch 262/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 95122.8986 - val_loss: 97981.2956\n",
      "Epoch 263/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 93454.0989 - val_loss: 96322.4144\n",
      "Epoch 264/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 91829.2194 - val_loss: 94723.0153\n",
      "Epoch 265/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 90253.3668 - val_loss: 93161.9538\n",
      "Epoch 266/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 88728.4669 - val_loss: 91636.0556\n",
      "Epoch 267/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 87247.0292 - val_loss: 90185.1206\n",
      "Epoch 268/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 85809.3433 - val_loss: 88759.8972\n",
      "Epoch 269/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 84418.1623 - val_loss: 87375.4175\n",
      "Epoch 270/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 83075.7362 - val_loss: 86053.6131\n",
      "Epoch 271/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 81776.6982 - val_loss: 84765.6894\n",
      "Epoch 272/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 80521.8127 - val_loss: 83524.3909\n",
      "Epoch 273/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 79311.9162 - val_loss: 82321.8422\n",
      "Epoch 274/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 78148.1297 - val_loss: 81174.4206\n",
      "Epoch 275/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 77027.8393 - val_loss: 80068.9994\n",
      "Epoch 276/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 75950.6957 - val_loss: 78995.2203\n",
      "Epoch 277/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 74919.1150 - val_loss: 77982.2038\n",
      "Epoch 278/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 73924.2770 - val_loss: 77001.1138\n",
      "Epoch 279/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 72971.6519 - val_loss: 76059.8897\n",
      "Epoch 280/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 72059.5361 - val_loss: 75166.1034\n",
      "Epoch 281/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 71185.5993 - val_loss: 74300.2828\n",
      "Epoch 282/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 70351.9797 - val_loss: 73485.3584\n",
      "Epoch 283/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 69556.4526 - val_loss: 72687.1053\n",
      "Epoch 284/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 68799.2662 - val_loss: 71951.6094\n",
      "Epoch 285/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 68083.2483 - val_loss: 71237.0956\n",
      "Epoch 286/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 67403.8069 - val_loss: 70564.3409\n",
      "Epoch 287/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 66753.8464 - val_loss: 69943.5028\n",
      "Epoch 288/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 66143.1056 - val_loss: 69331.4528\n",
      "Epoch 289/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 65567.1368 - val_loss: 68766.1116\n",
      "Epoch 290/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 65025.1941 - val_loss: 68238.5359\n",
      "Epoch 291/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 64516.0512 - val_loss: 67741.3078\n",
      "Epoch 292/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 64039.9548 - val_loss: 67270.2322\n",
      "Epoch 293/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 63595.0866 - val_loss: 66840.0631\n",
      "Epoch 294/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 63176.3524 - val_loss: 66423.0838\n",
      "Epoch 295/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 62788.7609 - val_loss: 66042.2634\n",
      "Epoch 296/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 62430.6650 - val_loss: 65699.5269\n",
      "Epoch 297/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 62100.2254 - val_loss: 65372.8728\n",
      "Epoch 298/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 61793.1652 - val_loss: 65072.1481\n",
      "Epoch 299/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 61510.3535 - val_loss: 64805.0303\n",
      "Epoch 300/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 61252.7081 - val_loss: 64536.4625\n",
      "Epoch 301/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 61018.5767 - val_loss: 64310.2250\n",
      "Epoch 302/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 60805.9679 - val_loss: 64103.7056\n",
      "Epoch 303/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 60613.0562 - val_loss: 63913.0881\n",
      "Epoch 304/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 60436.8076 - val_loss: 63740.5900\n",
      "Epoch 305/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 60279.1858 - val_loss: 63588.0366\n",
      "Epoch 306/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 60140.5252 - val_loss: 63454.5412\n",
      "Epoch 307/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 60015.1634 - val_loss: 63337.6850\n",
      "Epoch 308/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59902.0461 - val_loss: 63223.6041\n",
      "Epoch 309/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59803.6113 - val_loss: 63126.9309\n",
      "Epoch 310/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59718.3101 - val_loss: 63045.6991\n",
      "Epoch 311/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59643.6098 - val_loss: 62965.8375\n",
      "Epoch 312/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59578.2402 - val_loss: 62909.1659\n",
      "Epoch 313/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59520.7254 - val_loss: 62849.2784\n",
      "Epoch 314/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59473.3694 - val_loss: 62804.3234\n",
      "Epoch 315/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59432.5308 - val_loss: 62762.7269\n",
      "Epoch 316/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59398.5040 - val_loss: 62726.6369\n",
      "Epoch 317/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59369.3552 - val_loss: 62702.2206\n",
      "Epoch 318/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59345.3597 - val_loss: 62674.8209\n",
      "Epoch 319/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59325.3569 - val_loss: 62655.7822\n",
      "Epoch 320/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59310.0650 - val_loss: 62640.1562\n",
      "Epoch 321/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59296.6557 - val_loss: 62624.2306\n",
      "Epoch 322/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59284.7166 - val_loss: 62613.0600\n",
      "Epoch 323/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59275.8075 - val_loss: 62604.6662\n",
      "Epoch 324/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59267.5172 - val_loss: 62595.5691\n",
      "Epoch 325/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59262.0237 - val_loss: 62588.6637\n",
      "Epoch 326/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59257.0657 - val_loss: 62583.6684\n",
      "Epoch 327/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59252.7725 - val_loss: 62580.2050\n",
      "Epoch 328/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59251.6428 - val_loss: 62575.8519\n",
      "Epoch 329/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59249.2025 - val_loss: 62571.5659\n",
      "Epoch 330/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59246.3715 - val_loss: 62570.7019\n",
      "Epoch 331/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59245.5988 - val_loss: 62569.9262\n",
      "Epoch 332/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59242.3055 - val_loss: 62566.9044\n",
      "Epoch 333/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59242.4443 - val_loss: 62565.3209\n",
      "Epoch 334/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.8177 - val_loss: 62564.7994\n",
      "Epoch 335/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6447 - val_loss: 62564.0447\n",
      "Epoch 336/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.0964 - val_loss: 62562.9841\n",
      "Epoch 337/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6482 - val_loss: 62562.5969\n",
      "Epoch 338/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7753 - val_loss: 62562.1653\n",
      "Epoch 339/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0202 - val_loss: 62561.6816\n",
      "Epoch 340/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6183 - val_loss: 62561.6287\n",
      "Epoch 341/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0512 - val_loss: 62560.8984\n",
      "Epoch 342/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3100 - val_loss: 62560.9634\n",
      "Epoch 343/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5338 - val_loss: 62561.0716\n",
      "Epoch 344/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2763 - val_loss: 62560.5831\n",
      "Epoch 345/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2949 - val_loss: 62560.3928\n",
      "Epoch 346/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.7124 - val_loss: 62559.7738\n",
      "Epoch 347/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9809 - val_loss: 62560.3784\n",
      "Epoch 348/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6819 - val_loss: 62560.1103\n",
      "Epoch 349/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5198 - val_loss: 62559.6053\n",
      "Epoch 350/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2718 - val_loss: 62560.3338\n",
      "Epoch 351/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3555 - val_loss: 62559.8509\n",
      "Epoch 352/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3315 - val_loss: 62559.5316\n",
      "Epoch 353/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4904 - val_loss: 62559.5781\n",
      "Epoch 354/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4569 - val_loss: 62559.5488\n",
      "Epoch 355/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9446 - val_loss: 62559.6481\n",
      "Epoch 356/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9333 - val_loss: 62559.8138\n",
      "Epoch 357/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6712 - val_loss: 62559.5594\n",
      "Epoch 358/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2176 - val_loss: 62559.7800\n",
      "Epoch 359/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0509 - val_loss: 62559.3950\n",
      "Epoch 360/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9402 - val_loss: 62559.5891\n",
      "Epoch 361/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.9387 - val_loss: 62559.4334\n",
      "Epoch 362/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7794 - val_loss: 62559.6731\n",
      "Epoch 363/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2177 - val_loss: 62559.5984\n",
      "Epoch 364/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7454 - val_loss: 62559.3931\n",
      "Epoch 365/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9012 - val_loss: 62559.2966\n",
      "Epoch 366/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6127 - val_loss: 62559.2053\n",
      "Epoch 367/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2022 - val_loss: 62559.7216\n",
      "Epoch 368/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2195 - val_loss: 62559.2122\n",
      "Epoch 369/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8677 - val_loss: 62559.1822\n",
      "Epoch 370/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7568 - val_loss: 62559.6059\n",
      "Epoch 371/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7390 - val_loss: 62559.3384\n",
      "Epoch 372/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0440 - val_loss: 62559.6431\n",
      "Epoch 373/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1321 - val_loss: 62559.6406\n",
      "Epoch 374/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6367 - val_loss: 62560.1153\n",
      "Epoch 375/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3663 - val_loss: 62559.6997\n",
      "Epoch 376/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8769 - val_loss: 62559.6725\n",
      "Epoch 377/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4868 - val_loss: 62559.4106\n",
      "Epoch 378/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7547 - val_loss: 62559.7747\n",
      "Epoch 379/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.8627 - val_loss: 62559.3078\n",
      "Epoch 380/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6237 - val_loss: 62559.6234\n",
      "Epoch 381/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.2526 - val_loss: 62559.7262\n",
      "Epoch 382/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1302 - val_loss: 62559.9437\n",
      "Epoch 383/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4967 - val_loss: 62559.5150\n",
      "Epoch 384/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9929 - val_loss: 62559.4784\n",
      "Epoch 385/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9505 - val_loss: 62559.6316\n",
      "Epoch 386/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1778 - val_loss: 62559.8872\n",
      "Epoch 387/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4774 - val_loss: 62559.6022\n",
      "Epoch 388/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8112 - val_loss: 62559.8316\n",
      "Epoch 389/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8747 - val_loss: 62559.7525\n",
      "Epoch 390/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4046 - val_loss: 62559.5741\n",
      "Epoch 391/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0291 - val_loss: 62559.5091\n",
      "Epoch 392/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.1844 - val_loss: 62559.6113\n",
      "Epoch 393/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9040 - val_loss: 62559.7222\n",
      "Epoch 394/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6822 - val_loss: 62559.8438\n",
      "Epoch 395/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2558 - val_loss: 62559.5169\n",
      "Epoch 396/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8771 - val_loss: 62559.3812\n",
      "Epoch 397/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6430 - val_loss: 62559.4381\n",
      "Epoch 398/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.6988 - val_loss: 62559.6275\n",
      "Epoch 399/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9257 - val_loss: 62559.5987\n",
      "Epoch 400/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.5041 - val_loss: 62559.0766\n",
      "Epoch 401/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.8688 - val_loss: 62559.9178\n",
      "Epoch 402/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8466 - val_loss: 62559.5728\n",
      "Epoch 403/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6995 - val_loss: 62559.7275\n",
      "Epoch 404/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7004 - val_loss: 62559.5572\n",
      "Epoch 405/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2385 - val_loss: 62559.5634\n",
      "Epoch 406/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1891 - val_loss: 62559.5494\n",
      "Epoch 407/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8085 - val_loss: 62559.6556\n",
      "Epoch 408/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8226 - val_loss: 62559.5362\n",
      "Epoch 409/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3336 - val_loss: 62559.5241\n",
      "Epoch 410/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7618 - val_loss: 62559.4775\n",
      "Epoch 411/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4855 - val_loss: 62559.3800\n",
      "Epoch 412/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4219 - val_loss: 62559.5669\n",
      "Epoch 413/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0916 - val_loss: 62559.6678\n",
      "Epoch 414/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2742 - val_loss: 62559.5591\n",
      "Epoch 415/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0541 - val_loss: 62559.1275\n",
      "Epoch 416/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4300 - val_loss: 62560.2066\n",
      "Epoch 417/800\n",
      "3633/3633 [==============================] - 5s 2ms/step - loss: 59239.8982 - val_loss: 62559.5581\n",
      "Epoch 418/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5008 - val_loss: 62559.3625\n",
      "Epoch 419/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5926 - val_loss: 62559.7487\n",
      "Epoch 420/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8614 - val_loss: 62559.4797\n",
      "Epoch 421/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9694 - val_loss: 62559.4722\n",
      "Epoch 422/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7989 - val_loss: 62559.8313\n",
      "Epoch 423/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4839 - val_loss: 62559.5106\n",
      "Epoch 424/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.9141 - val_loss: 62559.8694\n",
      "Epoch 425/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9795 - val_loss: 62560.0031\n",
      "Epoch 426/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3700 - val_loss: 62559.6413\n",
      "Epoch 427/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7963 - val_loss: 62559.8259\n",
      "Epoch 428/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0237 - val_loss: 62559.8109\n",
      "Epoch 429/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4489 - val_loss: 62559.5509\n",
      "Epoch 430/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7163 - val_loss: 62559.4969\n",
      "Epoch 431/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2712 - val_loss: 62559.3125\n",
      "Epoch 432/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7227 - val_loss: 62559.3372\n",
      "Epoch 433/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7805 - val_loss: 62559.8384\n",
      "Epoch 434/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9733 - val_loss: 62559.7497\n",
      "Epoch 435/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9881 - val_loss: 62559.5194\n",
      "Epoch 436/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4084 - val_loss: 62559.5900\n",
      "Epoch 437/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1086 - val_loss: 62559.3750\n",
      "Epoch 438/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6557 - val_loss: 62559.4997\n",
      "Epoch 439/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3834 - val_loss: 62559.7866\n",
      "Epoch 440/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2514 - val_loss: 62559.4944\n",
      "Epoch 441/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9935 - val_loss: 62559.6228\n",
      "Epoch 442/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7203 - val_loss: 62559.7044\n",
      "Epoch 443/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7853 - val_loss: 62559.7284\n",
      "Epoch 444/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7388 - val_loss: 62559.4634\n",
      "Epoch 445/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0270 - val_loss: 62559.5891\n",
      "Epoch 446/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9439 - val_loss: 62559.8228\n",
      "Epoch 447/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0672 - val_loss: 62559.5572\n",
      "Epoch 448/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6652 - val_loss: 62559.4531\n",
      "Epoch 449/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2075 - val_loss: 62559.2559\n",
      "Epoch 450/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.8299 - val_loss: 62559.1522\n",
      "Epoch 451/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6128 - val_loss: 62559.4088\n",
      "Epoch 452/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.4436 - val_loss: 62560.2191\n",
      "Epoch 453/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8946 - val_loss: 62559.2897\n",
      "Epoch 454/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3385 - val_loss: 62559.5759\n",
      "Epoch 455/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6185 - val_loss: 62559.2784\n",
      "Epoch 456/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3412 - val_loss: 62559.5491\n",
      "Epoch 457/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1726 - val_loss: 62559.7716\n",
      "Epoch 458/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6758 - val_loss: 62559.4991\n",
      "Epoch 459/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3488 - val_loss: 62559.5481\n",
      "Epoch 460/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4035 - val_loss: 62559.6641\n",
      "Epoch 461/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2330 - val_loss: 62559.4653\n",
      "Epoch 462/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6098 - val_loss: 62559.5575\n",
      "Epoch 463/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4007 - val_loss: 62559.7119\n",
      "Epoch 464/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2173 - val_loss: 62559.9313\n",
      "Epoch 465/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2058 - val_loss: 62559.4091\n",
      "Epoch 466/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2757 - val_loss: 62560.0444\n",
      "Epoch 467/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0280 - val_loss: 62559.5631\n",
      "Epoch 468/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6409 - val_loss: 62560.1256\n",
      "Epoch 469/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1361 - val_loss: 62559.4384\n",
      "Epoch 470/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0261 - val_loss: 62559.6859\n",
      "Epoch 471/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1679 - val_loss: 62559.5675\n",
      "Epoch 472/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7867 - val_loss: 62559.6428\n",
      "Epoch 473/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0191 - val_loss: 62559.5878\n",
      "Epoch 474/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0942 - val_loss: 62559.3225\n",
      "Epoch 475/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6235 - val_loss: 62559.4731\n",
      "Epoch 476/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1561 - val_loss: 62559.6556\n",
      "Epoch 477/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9032 - val_loss: 62559.8066\n",
      "Epoch 478/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0374 - val_loss: 62559.6309\n",
      "Epoch 479/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.5467 - val_loss: 62559.9481\n",
      "Epoch 480/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.9450 - val_loss: 62559.6584\n",
      "Epoch 481/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3886 - val_loss: 62559.6788\n",
      "Epoch 482/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7924 - val_loss: 62559.2641\n",
      "Epoch 483/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6879 - val_loss: 62559.5353\n",
      "Epoch 484/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7778 - val_loss: 62559.2369\n",
      "Epoch 485/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7299 - val_loss: 62559.3425\n",
      "Epoch 486/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1703 - val_loss: 62559.4228\n",
      "Epoch 487/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3759 - val_loss: 62559.3419\n",
      "Epoch 488/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9815 - val_loss: 62559.8637\n",
      "Epoch 489/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9583 - val_loss: 62559.3338\n",
      "Epoch 490/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.5892 - val_loss: 62559.7684\n",
      "Epoch 491/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5471 - val_loss: 62559.5100\n",
      "Epoch 492/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8955 - val_loss: 62559.4022\n",
      "Epoch 493/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1182 - val_loss: 62559.3644\n",
      "Epoch 494/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0520 - val_loss: 62559.6866\n",
      "Epoch 495/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6842 - val_loss: 62559.4594\n",
      "Epoch 496/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8348 - val_loss: 62559.9150\n",
      "Epoch 497/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0498 - val_loss: 62559.5875\n",
      "Epoch 498/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3833 - val_loss: 62559.5178\n",
      "Epoch 499/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4978 - val_loss: 62559.8281\n",
      "Epoch 500/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5223 - val_loss: 62559.5891\n",
      "Epoch 501/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9981 - val_loss: 62559.4378\n",
      "Epoch 502/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8867 - val_loss: 62559.5003\n",
      "Epoch 503/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6128 - val_loss: 62559.3594\n",
      "Epoch 504/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8643 - val_loss: 62559.4822\n",
      "Epoch 505/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6390 - val_loss: 62559.6819\n",
      "Epoch 506/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4057 - val_loss: 62560.0628\n",
      "Epoch 507/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1698 - val_loss: 62559.8278\n",
      "Epoch 508/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3623 - val_loss: 62559.5200\n",
      "Epoch 509/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.7864 - val_loss: 62559.3853\n",
      "Epoch 510/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7347 - val_loss: 62559.6144\n",
      "Epoch 511/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0350 - val_loss: 62559.6266\n",
      "Epoch 512/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0891 - val_loss: 62559.3659\n",
      "Epoch 513/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9463 - val_loss: 62559.4353\n",
      "Epoch 514/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2965 - val_loss: 62559.4347\n",
      "Epoch 515/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9589 - val_loss: 62559.2253\n",
      "Epoch 516/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3383 - val_loss: 62559.2369\n",
      "Epoch 517/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4375 - val_loss: 62559.3203\n",
      "Epoch 518/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9680 - val_loss: 62559.4191\n",
      "Epoch 519/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9286 - val_loss: 62559.6128\n",
      "Epoch 520/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6509 - val_loss: 62559.2138\n",
      "Epoch 521/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3334 - val_loss: 62559.1072\n",
      "Epoch 522/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7797 - val_loss: 62559.2206\n",
      "Epoch 523/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6925 - val_loss: 62559.5097\n",
      "Epoch 524/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0650 - val_loss: 62559.6172\n",
      "Epoch 525/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9348 - val_loss: 62559.5200\n",
      "Epoch 526/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.9184 - val_loss: 62559.3922\n",
      "Epoch 527/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6427 - val_loss: 62559.6944\n",
      "Epoch 528/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.4088 - val_loss: 62559.5731\n",
      "Epoch 529/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.4374 - val_loss: 62559.3869\n",
      "Epoch 530/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2614 - val_loss: 62559.2038\n",
      "Epoch 531/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3298 - val_loss: 62559.6909\n",
      "Epoch 532/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1769 - val_loss: 62559.6912\n",
      "Epoch 533/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5123 - val_loss: 62559.6875\n",
      "Epoch 534/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8356 - val_loss: 62559.5019\n",
      "Epoch 535/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2340 - val_loss: 62559.7244\n",
      "Epoch 536/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5002 - val_loss: 62559.7091\n",
      "Epoch 537/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9241 - val_loss: 62559.8394\n",
      "Epoch 538/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4397 - val_loss: 62559.6478\n",
      "Epoch 539/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8010 - val_loss: 62559.6478\n",
      "Epoch 540/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6785 - val_loss: 62559.7081\n",
      "Epoch 541/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1129 - val_loss: 62559.4700\n",
      "Epoch 542/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9740 - val_loss: 62559.7053\n",
      "Epoch 543/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3936 - val_loss: 62559.6541\n",
      "Epoch 544/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.4495 - val_loss: 62559.1203\n",
      "Epoch 545/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7209 - val_loss: 62559.5019\n",
      "Epoch 546/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9870 - val_loss: 62559.7800\n",
      "Epoch 547/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8581 - val_loss: 62559.8616\n",
      "Epoch 548/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9518 - val_loss: 62559.7547\n",
      "Epoch 549/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6514 - val_loss: 62559.9334\n",
      "Epoch 550/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7165 - val_loss: 62559.9328\n",
      "Epoch 551/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6715 - val_loss: 62559.8347\n",
      "Epoch 552/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.1677 - val_loss: 62559.7866\n",
      "Epoch 553/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4391 - val_loss: 62559.7872\n",
      "Epoch 554/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8287 - val_loss: 62559.8816\n",
      "Epoch 555/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6147 - val_loss: 62559.5756\n",
      "Epoch 556/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8757 - val_loss: 62559.5631\n",
      "Epoch 557/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1333 - val_loss: 62559.9013\n",
      "Epoch 558/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7979 - val_loss: 62559.3897\n",
      "Epoch 559/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0176 - val_loss: 62559.2747\n",
      "Epoch 560/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0218 - val_loss: 62559.2506\n",
      "Epoch 561/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0656 - val_loss: 62559.2869\n",
      "Epoch 562/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8106 - val_loss: 62559.3313\n",
      "Epoch 563/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0269 - val_loss: 62559.6184\n",
      "Epoch 564/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59242.7868 - val_loss: 62559.7341\n",
      "Epoch 565/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.5674 - val_loss: 62559.1791\n",
      "Epoch 566/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.2659 - val_loss: 62559.7088\n",
      "Epoch 567/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5490 - val_loss: 62559.5312\n",
      "Epoch 568/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.5918 - val_loss: 62559.8725\n",
      "Epoch 569/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1731 - val_loss: 62559.4016\n",
      "Epoch 570/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9099 - val_loss: 62559.1691\n",
      "Epoch 571/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6877 - val_loss: 62559.3625\n",
      "Epoch 572/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9508 - val_loss: 62559.3628\n",
      "Epoch 573/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4584 - val_loss: 62559.3519\n",
      "Epoch 574/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3010 - val_loss: 62559.3616\n",
      "Epoch 575/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9511 - val_loss: 62559.4512\n",
      "Epoch 576/800\n",
      "3633/3633 [==============================] - 5s 2ms/step - loss: 59239.1846 - val_loss: 62559.9569\n",
      "Epoch 577/800\n",
      "3633/3633 [==============================] - 5s 2ms/step - loss: 59239.9112 - val_loss: 62559.7394\n",
      "Epoch 578/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8803 - val_loss: 62559.4216\n",
      "Epoch 579/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.3915 - val_loss: 62559.6997\n",
      "Epoch 580/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2889 - val_loss: 62559.7369\n",
      "Epoch 581/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6717 - val_loss: 62559.5741\n",
      "Epoch 582/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3312 - val_loss: 62559.8378\n",
      "Epoch 583/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2574 - val_loss: 62559.3666\n",
      "Epoch 584/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8950 - val_loss: 62559.4222\n",
      "Epoch 585/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7804 - val_loss: 62559.7594\n",
      "Epoch 586/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7420 - val_loss: 62559.6862\n",
      "Epoch 587/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1216 - val_loss: 62559.5081\n",
      "Epoch 588/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8697 - val_loss: 62559.4716\n",
      "Epoch 589/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4404 - val_loss: 62559.7634\n",
      "Epoch 590/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6646 - val_loss: 62559.4053\n",
      "Epoch 591/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.3177 - val_loss: 62559.7975\n",
      "Epoch 592/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0324 - val_loss: 62559.4059\n",
      "Epoch 593/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5775 - val_loss: 62559.6319\n",
      "Epoch 594/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8087 - val_loss: 62559.4531\n",
      "Epoch 595/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8748 - val_loss: 62559.5566\n",
      "Epoch 596/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3291 - val_loss: 62559.6997\n",
      "Epoch 597/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5982 - val_loss: 62559.4500\n",
      "Epoch 598/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7874 - val_loss: 62559.7328\n",
      "Epoch 599/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8770 - val_loss: 62559.4947\n",
      "Epoch 600/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3594 - val_loss: 62559.3528\n",
      "Epoch 601/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9899 - val_loss: 62559.4053\n",
      "Epoch 602/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.2391 - val_loss: 62559.8681\n",
      "Epoch 603/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9928 - val_loss: 62559.3784\n",
      "Epoch 604/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.8024 - val_loss: 62559.5638\n",
      "Epoch 605/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3522 - val_loss: 62559.6206\n",
      "Epoch 606/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4196 - val_loss: 62559.4944\n",
      "Epoch 607/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3384 - val_loss: 62559.5666\n",
      "Epoch 608/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0365 - val_loss: 62559.3956\n",
      "Epoch 609/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4383 - val_loss: 62559.5978\n",
      "Epoch 610/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6308 - val_loss: 62559.5362\n",
      "Epoch 611/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7227 - val_loss: 62559.6653\n",
      "Epoch 612/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9250 - val_loss: 62559.9231\n",
      "Epoch 613/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3189 - val_loss: 62559.3863\n",
      "Epoch 614/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6960 - val_loss: 62559.8209\n",
      "Epoch 615/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0308 - val_loss: 62559.3666\n",
      "Epoch 616/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4650 - val_loss: 62559.3909\n",
      "Epoch 617/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5500 - val_loss: 62559.3028\n",
      "Epoch 618/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2623 - val_loss: 62559.3778\n",
      "Epoch 619/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5422 - val_loss: 62559.1878\n",
      "Epoch 620/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5518 - val_loss: 62559.4434\n",
      "Epoch 621/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0079 - val_loss: 62559.8297\n",
      "Epoch 622/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2999 - val_loss: 62559.8431\n",
      "Epoch 623/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.3020 - val_loss: 62559.5925\n",
      "Epoch 624/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2904 - val_loss: 62559.3200\n",
      "Epoch 625/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8655 - val_loss: 62559.3628\n",
      "Epoch 626/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4051 - val_loss: 62559.6541\n",
      "Epoch 627/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8298 - val_loss: 62559.3628\n",
      "Epoch 628/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2135 - val_loss: 62559.5563\n",
      "Epoch 629/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2435 - val_loss: 62559.5278\n",
      "Epoch 630/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1239 - val_loss: 62559.4722\n",
      "Epoch 631/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9414 - val_loss: 62559.5878\n",
      "Epoch 632/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0360 - val_loss: 62559.4500\n",
      "Epoch 633/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2467 - val_loss: 62559.8963\n",
      "Epoch 634/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0076 - val_loss: 62559.3947\n",
      "Epoch 635/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8170 - val_loss: 62559.5066\n",
      "Epoch 636/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6292 - val_loss: 62559.6725\n",
      "Epoch 637/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7521 - val_loss: 62559.3925\n",
      "Epoch 638/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8923 - val_loss: 62559.6778\n",
      "Epoch 639/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8409 - val_loss: 62559.9097\n",
      "Epoch 640/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3315 - val_loss: 62559.8425\n",
      "Epoch 641/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6080 - val_loss: 62559.2831\n",
      "Epoch 642/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5275 - val_loss: 62559.7069\n",
      "Epoch 643/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6848 - val_loss: 62559.2862\n",
      "Epoch 644/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.1319 - val_loss: 62559.6394\n",
      "Epoch 645/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4522 - val_loss: 62559.9000\n",
      "Epoch 646/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2689 - val_loss: 62559.4969\n",
      "Epoch 647/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6809 - val_loss: 62559.6881\n",
      "Epoch 648/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7215 - val_loss: 62559.5253\n",
      "Epoch 649/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3867 - val_loss: 62559.4131\n",
      "Epoch 650/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3044 - val_loss: 62559.5122\n",
      "Epoch 651/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9312 - val_loss: 62559.4247\n",
      "Epoch 652/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9657 - val_loss: 62559.1028\n",
      "Epoch 653/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5425 - val_loss: 62559.3700\n",
      "Epoch 654/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.6336 - val_loss: 62559.9169\n",
      "Epoch 655/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0024 - val_loss: 62559.4197\n",
      "Epoch 656/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1790 - val_loss: 62559.4594\n",
      "Epoch 657/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9377 - val_loss: 62559.5203\n",
      "Epoch 658/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6099 - val_loss: 62559.2947\n",
      "Epoch 659/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5948 - val_loss: 62559.1934\n",
      "Epoch 660/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8910 - val_loss: 62559.5881\n",
      "Epoch 661/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0827 - val_loss: 62559.0428\n",
      "Epoch 662/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4964 - val_loss: 62559.2038\n",
      "Epoch 663/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7432 - val_loss: 62559.3294\n",
      "Epoch 664/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6743 - val_loss: 62559.1616\n",
      "Epoch 665/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8875 - val_loss: 62559.1403\n",
      "Epoch 666/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2300 - val_loss: 62559.4334\n",
      "Epoch 667/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7457 - val_loss: 62559.4766\n",
      "Epoch 668/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6429 - val_loss: 62559.0453\n",
      "Epoch 669/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3693 - val_loss: 62559.0991\n",
      "Epoch 670/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1682 - val_loss: 62559.4500\n",
      "Epoch 671/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6273 - val_loss: 62559.1156\n",
      "Epoch 672/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6024 - val_loss: 62559.5719\n",
      "Epoch 673/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8278 - val_loss: 62559.2253\n",
      "Epoch 674/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.4442 - val_loss: 62559.1153\n",
      "Epoch 675/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1991 - val_loss: 62559.3194\n",
      "Epoch 676/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.4293 - val_loss: 62559.4997\n",
      "Epoch 677/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0601 - val_loss: 62559.4653\n",
      "Epoch 678/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.4702 - val_loss: 62559.5900\n",
      "Epoch 679/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8652 - val_loss: 62559.5100\n",
      "Epoch 680/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3970 - val_loss: 62559.6953\n",
      "Epoch 681/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4188 - val_loss: 62559.5884\n",
      "Epoch 682/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0691 - val_loss: 62559.6400\n",
      "Epoch 683/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4633 - val_loss: 62559.4997\n",
      "Epoch 684/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9394 - val_loss: 62559.4397\n",
      "Epoch 685/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3399 - val_loss: 62559.2291\n",
      "Epoch 686/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9367 - val_loss: 62559.6803\n",
      "Epoch 687/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6534 - val_loss: 62559.4512\n",
      "Epoch 688/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1535 - val_loss: 62559.5931\n",
      "Epoch 689/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9719 - val_loss: 62559.5975\n",
      "Epoch 690/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1392 - val_loss: 62559.5728\n",
      "Epoch 691/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6704 - val_loss: 62559.4981\n",
      "Epoch 692/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8310 - val_loss: 62559.7625\n",
      "Epoch 693/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0636 - val_loss: 62559.5028\n",
      "Epoch 694/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6189 - val_loss: 62560.0091\n",
      "Epoch 695/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9099 - val_loss: 62559.7675\n",
      "Epoch 696/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6862 - val_loss: 62559.5553\n",
      "Epoch 697/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6012 - val_loss: 62559.8569\n",
      "Epoch 698/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0537 - val_loss: 62559.3963\n",
      "Epoch 699/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.2461 - val_loss: 62559.7453\n",
      "Epoch 700/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9623 - val_loss: 62559.5475\n",
      "Epoch 701/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1267 - val_loss: 62559.7625\n",
      "Epoch 702/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4624 - val_loss: 62559.4644\n",
      "Epoch 703/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4851 - val_loss: 62559.2797\n",
      "Epoch 704/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6641 - val_loss: 62559.7203\n",
      "Epoch 705/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7207 - val_loss: 62559.5984\n",
      "Epoch 706/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4642 - val_loss: 62559.6541\n",
      "Epoch 707/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8548 - val_loss: 62559.5041\n",
      "Epoch 708/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.5894 - val_loss: 62559.2950\n",
      "Epoch 709/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.5464 - val_loss: 62559.5881\n",
      "Epoch 710/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9203 - val_loss: 62559.2950\n",
      "Epoch 711/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2781 - val_loss: 62559.6475\n",
      "Epoch 712/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2185 - val_loss: 62559.8500\n",
      "Epoch 713/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.2310 - val_loss: 62559.6994\n",
      "Epoch 714/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3168 - val_loss: 62559.4050\n",
      "Epoch 715/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59242.8802 - val_loss: 62559.7228\n",
      "Epoch 716/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2973 - val_loss: 62559.2972\n",
      "Epoch 717/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8227 - val_loss: 62559.3891\n",
      "Epoch 718/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1078 - val_loss: 62559.7981\n",
      "Epoch 719/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8592 - val_loss: 62559.6172\n",
      "Epoch 720/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8993 - val_loss: 62559.7125\n",
      "Epoch 721/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6309 - val_loss: 62559.6637\n",
      "Epoch 722/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4443 - val_loss: 62559.4894\n",
      "Epoch 723/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1928 - val_loss: 62559.4578\n",
      "Epoch 724/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.8385 - val_loss: 62559.4991\n",
      "Epoch 725/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7656 - val_loss: 62559.4500\n",
      "Epoch 726/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7398 - val_loss: 62559.6522\n",
      "Epoch 727/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6075 - val_loss: 62559.8978\n",
      "Epoch 728/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.5981 - val_loss: 62559.4681\n",
      "Epoch 729/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.5053 - val_loss: 62559.5909\n",
      "Epoch 730/800\n",
      "3633/3633 [==============================] - 5s 2ms/step - loss: 59239.4211 - val_loss: 62559.3812\n",
      "Epoch 731/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.2854 - val_loss: 62559.4506\n",
      "Epoch 732/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3725 - val_loss: 62559.4222\n",
      "Epoch 733/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3003 - val_loss: 62559.6091\n",
      "Epoch 734/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.3407 - val_loss: 62559.4584\n",
      "Epoch 735/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.6308 - val_loss: 62559.3787\n",
      "Epoch 736/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1574 - val_loss: 62559.4116\n",
      "Epoch 737/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9994 - val_loss: 62559.4850\n",
      "Epoch 738/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7521 - val_loss: 62559.8600\n",
      "Epoch 739/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8954 - val_loss: 62559.2531\n",
      "Epoch 740/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7850 - val_loss: 62559.7559\n",
      "Epoch 741/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.3417 - val_loss: 62559.4047\n",
      "Epoch 742/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7315 - val_loss: 62559.6381\n",
      "Epoch 743/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.7125 - val_loss: 62559.5166\n",
      "Epoch 744/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1041 - val_loss: 62559.5106\n",
      "Epoch 745/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6837 - val_loss: 62559.8616\n",
      "Epoch 746/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0543 - val_loss: 62559.2047\n",
      "Epoch 747/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3094 - val_loss: 62559.3200\n",
      "Epoch 748/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3428 - val_loss: 62559.5525\n",
      "Epoch 749/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6796 - val_loss: 62559.4747\n",
      "Epoch 750/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6632 - val_loss: 62559.3828\n",
      "Epoch 751/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4895 - val_loss: 62559.2916\n",
      "Epoch 752/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0755 - val_loss: 62559.6628\n",
      "Epoch 753/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4511 - val_loss: 62559.4506\n",
      "Epoch 754/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9011 - val_loss: 62559.6509\n",
      "Epoch 755/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.6065 - val_loss: 62559.3419\n",
      "Epoch 756/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4143 - val_loss: 62559.4075\n",
      "Epoch 757/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.8617 - val_loss: 62559.7144\n",
      "Epoch 758/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.9863 - val_loss: 62559.7125\n",
      "Epoch 759/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59241.6431 - val_loss: 62559.5553\n",
      "Epoch 760/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.0520 - val_loss: 62559.2178\n",
      "Epoch 761/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6750 - val_loss: 62559.2147\n",
      "Epoch 762/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.4833 - val_loss: 62559.3637\n",
      "Epoch 763/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6957 - val_loss: 62559.2819\n",
      "Epoch 764/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.1193 - val_loss: 62559.5453\n",
      "Epoch 765/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.0059 - val_loss: 62559.7341\n",
      "Epoch 766/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.7124 - val_loss: 62559.9334\n",
      "Epoch 767/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.6600 - val_loss: 62559.3747\n",
      "Epoch 768/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.3116 - val_loss: 62559.8066\n",
      "Epoch 769/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.6759 - val_loss: 62559.6147\n",
      "Epoch 770/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59238.3487 - val_loss: 62559.4737\n",
      "Epoch 771/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59239.9580 - val_loss: 62559.8244\n",
      "Epoch 772/800\n",
      "3633/3633 [==============================] - 5s 1ms/step - loss: 59240.1362 - val_loss: 62559.8175\n",
      "Epoch 773/800\n",
      "3633/3633 [==============================] - 6s 2ms/step - loss: 59238.6804 - val_loss: 62559.4247\n",
      "Epoch 774/800\n",
      "3633/3633 [==============================] - 6s 2ms/step - loss: 59239.3330 - val_loss: 62559.3700\n",
      "Epoch 775/800\n",
      "3633/3633 [==============================] - 6s 2ms/step - loss: 59239.8256 - val_loss: 62559.6694\n",
      "Epoch 776/800\n",
      "3633/3633 [==============================] - 6s 2ms/step - loss: 59238.9486 - val_loss: 62559.5100\n",
      "Epoch 777/800\n",
      "3633/3633 [==============================] - 6s 2ms/step - loss: 59238.6825 - val_loss: 62559.3734\n",
      "Epoch 778/800\n",
      "3633/3633 [==============================] - 6s 2ms/step - loss: 59239.5759 - val_loss: 62559.1741\n",
      "Epoch 779/800\n",
      " 352/3633 [=>............................] - ETA: 5s - loss: 61076.5369"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-931a9aefa09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trimmed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trimmed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trimmed_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trimmed_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=800, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_61 (LSTM)               (None, 30, 50)            11800     \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 30, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 52,251\n",
      "Trainable params: 52,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3733 samples, validate on 300 samples\n",
      "Epoch 1/500\n",
      "3733/3733 [==============================] - 10s 3ms/step - loss: 2471544.6542 - val_loss: 2440976.7433\n",
      "Epoch 2/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2445354.5615 - val_loss: 2421091.1100\n",
      "Epoch 3/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2425897.2513 - val_loss: 2402050.4500\n",
      "Epoch 4/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2407027.0394 - val_loss: 2383441.1067\n",
      "Epoch 5/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2388468.1207 - val_loss: 2365057.1633\n",
      "Epoch 6/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2370127.9125 - val_loss: 2346890.9100\n",
      "Epoch 7/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2351956.6900 - val_loss: 2328858.0300\n",
      "Epoch 8/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2333934.4951 - val_loss: 2310957.4233\n",
      "Epoch 9/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2316046.2163 - val_loss: 2293195.4233\n",
      "Epoch 10/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2298280.8174 - val_loss: 2275563.5500\n",
      "Epoch 11/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2280634.4473 - val_loss: 2258033.4433\n",
      "Epoch 12/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2263093.8900 - val_loss: 2240607.9833\n",
      "Epoch 13/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 2245656.1312 - val_loss: 2223288.1133\n",
      "Epoch 14/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2228321.3622 - val_loss: 2206047.7167\n",
      "Epoch 15/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2211077.5844 - val_loss: 2188929.1300\n",
      "Epoch 16/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2193930.4815 - val_loss: 2171882.9467\n",
      "Epoch 17/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2176877.1463 - val_loss: 2154935.7567\n",
      "Epoch 18/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2159911.8492 - val_loss: 2138092.0667\n",
      "Epoch 19/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2143039.2748 - val_loss: 2121315.4567\n",
      "Epoch 20/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2126245.3344 - val_loss: 2104637.8767\n",
      "Epoch 21/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2109540.1974 - val_loss: 2088026.7167\n",
      "Epoch 22/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2092915.6539 - val_loss: 2071510.3767\n",
      "Epoch 23/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2076375.7509 - val_loss: 2055076.7167\n",
      "Epoch 24/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2059914.3580 - val_loss: 2038713.0300\n",
      "Epoch 25/500\n",
      "3733/3733 [==============================] - 6s 1ms/step - loss: 2043532.6474 - val_loss: 2022434.1717\n",
      "Epoch 26/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2027227.3121 - val_loss: 2006245.0800\n",
      "Epoch 27/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 2011003.1190 - val_loss: 1990110.5483\n",
      "Epoch 28/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1994856.0706 - val_loss: 1974064.8417\n",
      "Epoch 29/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1978787.5325 - val_loss: 1958108.0517\n",
      "Epoch 30/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1962793.0938 - val_loss: 1942209.6683\n",
      "Epoch 31/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1946876.1921 - val_loss: 1926398.9467\n",
      "Epoch 32/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1931033.8838 - val_loss: 1910651.2783\n",
      "Epoch 33/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1915265.7113 - val_loss: 1894975.3883\n",
      "Epoch 34/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1899570.7345 - val_loss: 1879380.6783\n",
      "Epoch 35/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1883949.5451 - val_loss: 1863858.8667\n",
      "Epoch 36/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1868400.1830 - val_loss: 1848410.0950\n",
      "Epoch 37/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1852919.7470 - val_loss: 1833047.6117\n",
      "Epoch 38/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1837518.2822 - val_loss: 1817718.8133\n",
      "Epoch 39/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1822182.6457 - val_loss: 1802495.3083\n",
      "Epoch 40/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1806924.2464 - val_loss: 1787338.3933\n",
      "Epoch 41/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1791732.2928 - val_loss: 1772241.7183\n",
      "Epoch 42/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1776610.6159 - val_loss: 1757221.8133\n",
      "Epoch 43/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1761564.6010 - val_loss: 1742255.7583\n",
      "Epoch 44/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1746584.4773 - val_loss: 1727389.8117\n",
      "Epoch 45/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1731679.5973 - val_loss: 1712572.3750\n",
      "Epoch 46/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1716840.9785 - val_loss: 1697833.5333\n",
      "Epoch 47/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1702073.7602 - val_loss: 1683166.7783\n",
      "Epoch 48/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1687372.3040 - val_loss: 1668564.7733\n",
      "Epoch 49/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1672744.9159 - val_loss: 1654020.7750\n",
      "Epoch 50/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1658183.7523 - val_loss: 1639570.2717\n",
      "Epoch 51/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1643694.4953 - val_loss: 1625178.3350\n",
      "Epoch 52/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1629274.0038 - val_loss: 1610855.5550\n",
      "Epoch 53/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1614922.8088 - val_loss: 1596590.0150\n",
      "Epoch 54/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1600640.8144 - val_loss: 1582421.3933\n",
      "Epoch 55/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1586431.9818 - val_loss: 1568303.2250\n",
      "Epoch 56/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1572290.6148 - val_loss: 1554249.4283\n",
      "Epoch 57/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1558216.0634 - val_loss: 1540287.5717\n",
      "Epoch 58/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1544207.6569 - val_loss: 1526371.8550\n",
      "Epoch 59/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1530267.0557 - val_loss: 1512515.7183\n",
      "Epoch 60/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1516400.3679 - val_loss: 1498753.8717\n",
      "Epoch 61/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1502605.8930 - val_loss: 1485046.8350\n",
      "Epoch 62/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1488874.2586 - val_loss: 1471412.9483\n",
      "Epoch 63/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1475212.9935 - val_loss: 1457854.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1461620.7793 - val_loss: 1444352.1200\n",
      "Epoch 65/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1448097.8204 - val_loss: 1430920.4650\n",
      "Epoch 66/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1434640.1339 - val_loss: 1417576.6400\n",
      "Epoch 67/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1421253.5136 - val_loss: 1404272.3317\n",
      "Epoch 68/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1407930.6129 - val_loss: 1391068.0117\n",
      "Epoch 69/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1394678.8709 - val_loss: 1377899.4783\n",
      "Epoch 70/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1381491.2150 - val_loss: 1364809.3350\n",
      "Epoch 71/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1368375.2817 - val_loss: 1351792.6067\n",
      "Epoch 72/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1355330.1781 - val_loss: 1338819.7333\n",
      "Epoch 73/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1342353.1164 - val_loss: 1325948.9817\n",
      "Epoch 74/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1329444.2216 - val_loss: 1313156.4767\n",
      "Epoch 75/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1316604.2167 - val_loss: 1300401.3117\n",
      "Epoch 76/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1303832.0712 - val_loss: 1287718.7550\n",
      "Epoch 77/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1291126.1458 - val_loss: 1275113.5750\n",
      "Epoch 78/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1278486.7219 - val_loss: 1262580.5300\n",
      "Epoch 79/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1265919.7219 - val_loss: 1250089.8483\n",
      "Epoch 80/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1253416.7929 - val_loss: 1237692.3550\n",
      "Epoch 81/500\n",
      "3733/3733 [==============================] - 6s 1ms/step - loss: 1240984.0276 - val_loss: 1225360.0183\n",
      "Epoch 82/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1228618.6260 - val_loss: 1213090.3983\n",
      "Epoch 83/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1216320.6639 - val_loss: 1200887.0417\n",
      "Epoch 84/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1204087.9727 - val_loss: 1188748.2917\n",
      "Epoch 85/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1191926.3977 - val_loss: 1176680.2150\n",
      "Epoch 86/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1179834.1768 - val_loss: 1164674.1867\n",
      "Epoch 87/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1167807.0435 - val_loss: 1152754.1417\n",
      "Epoch 88/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1155848.8240 - val_loss: 1140891.2067\n",
      "Epoch 89/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1143959.7155 - val_loss: 1129091.6650\n",
      "Epoch 90/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1132139.4556 - val_loss: 1117362.4917\n",
      "Epoch 91/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1120381.2267 - val_loss: 1105715.5317\n",
      "Epoch 92/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1108690.6517 - val_loss: 1094127.2717\n",
      "Epoch 93/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1097070.0753 - val_loss: 1082590.5267\n",
      "Epoch 94/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1085517.5970 - val_loss: 1071127.5183\n",
      "Epoch 95/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1074033.0368 - val_loss: 1059751.2983\n",
      "Epoch 96/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1062613.5876 - val_loss: 1048425.1417\n",
      "Epoch 97/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1051263.1809 - val_loss: 1037163.3533\n",
      "Epoch 98/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1039976.9847 - val_loss: 1025980.7900\n",
      "Epoch 99/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1028763.5758 - val_loss: 1014854.2950\n",
      "Epoch 100/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1017617.8408 - val_loss: 1003805.9533\n",
      "Epoch 101/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 1006539.1482 - val_loss: 992832.8908\n",
      "Epoch 102/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 995529.4038 - val_loss: 981901.5208\n",
      "Epoch 103/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 984583.0560 - val_loss: 971059.5392\n",
      "Epoch 104/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 973707.8854 - val_loss: 960276.3375\n",
      "Epoch 105/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 962898.2711 - val_loss: 949568.9125\n",
      "Epoch 106/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 952157.3296 - val_loss: 938908.8867\n",
      "Epoch 107/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 941482.3749 - val_loss: 928345.0733\n",
      "Epoch 108/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 930880.6900 - val_loss: 917827.3333\n",
      "Epoch 109/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 920339.1750 - val_loss: 907393.7508\n",
      "Epoch 110/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 909867.2006 - val_loss: 897015.6867\n",
      "Epoch 111/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 899462.5338 - val_loss: 886685.4858\n",
      "Epoch 112/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 889121.1992 - val_loss: 876454.0325\n",
      "Epoch 113/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 878853.3128 - val_loss: 866278.0325\n",
      "Epoch 114/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 868649.9652 - val_loss: 856177.0325\n",
      "Epoch 115/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 858515.1968 - val_loss: 846131.6675\n",
      "Epoch 116/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 848450.3717 - val_loss: 836159.2258\n",
      "Epoch 117/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 838450.6750 - val_loss: 826256.2158\n",
      "Epoch 118/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 828519.1872 - val_loss: 816416.9292\n",
      "Epoch 119/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 818653.7116 - val_loss: 806645.7325\n",
      "Epoch 120/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 808855.3341 - val_loss: 796947.9533\n",
      "Epoch 121/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 799123.7075 - val_loss: 787298.1842\n",
      "Epoch 122/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 789457.6683 - val_loss: 777737.6458\n",
      "Epoch 123/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 779857.6168 - val_loss: 768237.9100\n",
      "Epoch 124/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 770327.4247 - val_loss: 758794.6867\n",
      "Epoch 125/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 760861.7389 - val_loss: 749424.0275\n",
      "Epoch 126/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 751465.0857 - val_loss: 740111.9475\n",
      "Epoch 127/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 742131.0544 - val_loss: 730905.0367\n",
      "Epoch 128/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 732866.2252 - val_loss: 721715.4692\n",
      "Epoch 129/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 723665.8801 - val_loss: 712612.4200\n",
      "Epoch 130/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 714539.2917 - val_loss: 703580.4808\n",
      "Epoch 131/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 705477.9235 - val_loss: 694610.9533\n",
      "Epoch 132/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 696482.4178 - val_loss: 685716.3833\n",
      "Epoch 133/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 687550.0743 - val_loss: 676882.4725\n",
      "Epoch 134/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 678687.7504 - val_loss: 668093.7825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 669889.8328 - val_loss: 659401.1775\n",
      "Epoch 136/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 661164.9613 - val_loss: 650773.4525\n",
      "Epoch 137/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 652502.3136 - val_loss: 642210.2825\n",
      "Epoch 138/500\n",
      "3733/3733 [==============================] - 6s 1ms/step - loss: 643908.8314 - val_loss: 633696.3058\n",
      "Epoch 139/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 635376.7771 - val_loss: 625263.8850\n",
      "Epoch 140/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 626912.2666 - val_loss: 616890.0925\n",
      "Epoch 141/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 618513.7614 - val_loss: 608590.1908\n",
      "Epoch 142/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 610184.0012 - val_loss: 600345.6908\n",
      "Epoch 143/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 601920.8218 - val_loss: 592176.6175\n",
      "Epoch 144/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 593722.9808 - val_loss: 584082.9600\n",
      "Epoch 145/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 585594.2015 - val_loss: 576048.3500\n",
      "Epoch 146/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 577529.6611 - val_loss: 568071.3625\n",
      "Epoch 147/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 569531.5160 - val_loss: 560175.7125\n",
      "Epoch 148/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 561601.2953 - val_loss: 552333.0467\n",
      "Epoch 149/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 553735.6511 - val_loss: 544565.0425\n",
      "Epoch 150/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 545935.1353 - val_loss: 536855.8075\n",
      "Epoch 151/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 538200.0737 - val_loss: 529215.1575\n",
      "Epoch 152/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 530529.3573 - val_loss: 521630.6325\n",
      "Epoch 153/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 522928.7272 - val_loss: 514106.4700\n",
      "Epoch 154/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 515391.5518 - val_loss: 506682.3200\n",
      "Epoch 155/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 507922.0814 - val_loss: 499297.8229\n",
      "Epoch 156/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 500518.7052 - val_loss: 491986.0500\n",
      "Epoch 157/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 493177.5737 - val_loss: 484758.7404\n",
      "Epoch 158/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 485904.9243 - val_loss: 477570.9338\n",
      "Epoch 159/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 478698.5534 - val_loss: 470453.9100\n",
      "Epoch 160/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 471555.3110 - val_loss: 463414.8713\n",
      "Epoch 161/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 464480.8203 - val_loss: 456417.8812\n",
      "Epoch 162/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 457469.2167 - val_loss: 449519.8321\n",
      "Epoch 163/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 450527.8803 - val_loss: 442653.3600\n",
      "Epoch 164/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 443646.3723 - val_loss: 435869.0583\n",
      "Epoch 165/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 436833.3996 - val_loss: 429151.5588\n",
      "Epoch 166/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 430089.5069 - val_loss: 422489.6737\n",
      "Epoch 167/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 423404.6641 - val_loss: 415907.2013\n",
      "Epoch 168/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 416785.9306 - val_loss: 409379.8587\n",
      "Epoch 169/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 410235.9564 - val_loss: 402917.1537\n",
      "Epoch 170/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 403748.4611 - val_loss: 396530.4062\n",
      "Epoch 171/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 397327.3526 - val_loss: 390205.3850\n",
      "Epoch 172/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 390971.9646 - val_loss: 383940.6154\n",
      "Epoch 173/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 384678.4978 - val_loss: 377743.9721\n",
      "Epoch 174/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 378452.9074 - val_loss: 371597.0388\n",
      "Epoch 175/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 372289.8909 - val_loss: 365538.7263\n",
      "Epoch 176/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 366198.1781 - val_loss: 359509.7129\n",
      "Epoch 177/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 360166.1580 - val_loss: 353597.8867\n",
      "Epoch 178/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 354200.5460 - val_loss: 347717.0037\n",
      "Epoch 179/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 348299.9808 - val_loss: 341894.7379\n",
      "Epoch 180/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 342464.6695 - val_loss: 336159.1271\n",
      "Epoch 181/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 336694.8996 - val_loss: 330476.9096\n",
      "Epoch 182/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 330988.4047 - val_loss: 324868.3812\n",
      "Epoch 183/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 325342.1261 - val_loss: 319325.9392\n",
      "Epoch 184/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 319763.3793 - val_loss: 313818.3342\n",
      "Epoch 185/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 314247.6680 - val_loss: 308400.0733\n",
      "Epoch 186/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 308799.5899 - val_loss: 303046.6504\n",
      "Epoch 187/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 303414.1623 - val_loss: 297750.5396\n",
      "Epoch 188/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 298089.9896 - val_loss: 292519.4050\n",
      "Epoch 189/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 292833.7293 - val_loss: 287346.4100\n",
      "Epoch 190/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 287641.1117 - val_loss: 282229.8779\n",
      "Epoch 191/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 282511.5154 - val_loss: 277207.2533\n",
      "Epoch 192/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 277445.6379 - val_loss: 272241.2646\n",
      "Epoch 193/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 272443.4678 - val_loss: 267325.6312\n",
      "Epoch 194/500\n",
      "3733/3733 [==============================] - 6s 1ms/step - loss: 267502.2790 - val_loss: 262467.1987\n",
      "Epoch 195/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 262624.8028 - val_loss: 257677.5283\n",
      "Epoch 196/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 257808.9998 - val_loss: 252970.5833\n",
      "Epoch 197/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 253059.9011 - val_loss: 248307.3425\n",
      "Epoch 198/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 248374.1143 - val_loss: 243691.7685\n",
      "Epoch 199/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 243748.8831 - val_loss: 239174.0915\n",
      "Epoch 200/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 239189.1732 - val_loss: 234705.9902\n",
      "Epoch 201/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 234691.5529 - val_loss: 230280.6181\n",
      "Epoch 202/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 230257.5839 - val_loss: 225936.6281\n",
      "Epoch 203/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 225884.7920 - val_loss: 221672.1840\n",
      "Epoch 204/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 221579.2767 - val_loss: 217437.5298\n",
      "Epoch 205/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 217330.3923 - val_loss: 213291.1425\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733/3733 [==============================] - 5s 1ms/step - loss: 213147.8750 - val_loss: 209184.3944\n",
      "Epoch 207/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 209028.2664 - val_loss: 205146.2383\n",
      "Epoch 208/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 204969.8659 - val_loss: 201190.4952\n",
      "Epoch 209/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 200974.2460 - val_loss: 197285.6481\n",
      "Epoch 210/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 197035.6424 - val_loss: 193445.0106\n",
      "Epoch 211/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 193164.3808 - val_loss: 189640.9606\n",
      "Epoch 212/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 189350.8971 - val_loss: 185918.3575\n",
      "Epoch 213/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 185604.7003 - val_loss: 182263.0965\n",
      "Epoch 214/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 181918.2706 - val_loss: 178647.8942\n",
      "Epoch 215/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 178291.6295 - val_loss: 175122.8365\n",
      "Epoch 216/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 174727.2489 - val_loss: 171630.7465\n",
      "Epoch 217/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 171222.0486 - val_loss: 168229.7550\n",
      "Epoch 218/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 167779.0500 - val_loss: 164867.7760\n",
      "Epoch 219/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 164392.6526 - val_loss: 161573.8269\n",
      "Epoch 220/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 161071.2932 - val_loss: 158325.4242\n",
      "Epoch 221/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 157805.5043 - val_loss: 155151.4015\n",
      "Epoch 222/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 154602.4955 - val_loss: 152041.7594\n",
      "Epoch 223/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 151461.6853 - val_loss: 148972.4040\n",
      "Epoch 224/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 148376.8450 - val_loss: 145981.6027\n",
      "Epoch 225/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 145356.5937 - val_loss: 143047.1398\n",
      "Epoch 226/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 142393.2289 - val_loss: 140175.3294\n",
      "Epoch 227/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 139489.6843 - val_loss: 137339.9624\n",
      "Epoch 228/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 136642.8353 - val_loss: 134585.6954\n",
      "Epoch 229/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 133854.3503 - val_loss: 131896.9917\n",
      "Epoch 230/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 131125.2512 - val_loss: 129234.9100\n",
      "Epoch 231/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 128456.7088 - val_loss: 126648.8601\n",
      "Epoch 232/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 125846.7209 - val_loss: 124130.9801\n",
      "Epoch 233/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 123295.6134 - val_loss: 121659.7728\n",
      "Epoch 234/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 120795.6285 - val_loss: 119259.6117\n",
      "Epoch 235/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 118360.5378 - val_loss: 116896.4307\n",
      "Epoch 236/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 115982.1302 - val_loss: 114596.5509\n",
      "Epoch 237/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 113660.7053 - val_loss: 112356.9792\n",
      "Epoch 238/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 111398.4230 - val_loss: 110165.5874\n",
      "Epoch 239/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 109190.6824 - val_loss: 108049.4029\n",
      "Epoch 240/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 107041.2774 - val_loss: 105977.9407\n",
      "Epoch 241/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 104944.0121 - val_loss: 103958.8018\n",
      "Epoch 242/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 102904.7451 - val_loss: 102003.0593\n",
      "Epoch 243/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 100914.7318 - val_loss: 100102.6982\n",
      "Epoch 244/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 98985.2500 - val_loss: 98246.9695\n",
      "Epoch 245/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 97112.8229 - val_loss: 96449.1239\n",
      "Epoch 246/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 95291.0725 - val_loss: 94702.7878\n",
      "Epoch 247/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 93524.6450 - val_loss: 93027.3550\n",
      "Epoch 248/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 91811.3583 - val_loss: 91377.9478\n",
      "Epoch 249/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 90151.7622 - val_loss: 89798.9643\n",
      "Epoch 250/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 88544.8652 - val_loss: 88271.8610\n",
      "Epoch 251/500\n",
      "3733/3733 [==============================] - 6s 1ms/step - loss: 86990.9121 - val_loss: 86788.4749\n",
      "Epoch 252/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 85486.8834 - val_loss: 85357.5728\n",
      "Epoch 253/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 84033.8466 - val_loss: 83983.2219\n",
      "Epoch 254/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 82633.4072 - val_loss: 82662.7982\n",
      "Epoch 255/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 81285.6362 - val_loss: 81375.1400\n",
      "Epoch 256/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 79984.4259 - val_loss: 80161.8513\n",
      "Epoch 257/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 78731.9222 - val_loss: 78982.2738\n",
      "Epoch 258/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 77529.9094 - val_loss: 77840.3967\n",
      "Epoch 259/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 76374.8257 - val_loss: 76765.2549\n",
      "Epoch 260/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 75268.2412 - val_loss: 75720.1831\n",
      "Epoch 261/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 74205.8967 - val_loss: 74731.0968\n",
      "Epoch 262/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 73189.7165 - val_loss: 73784.8496\n",
      "Epoch 263/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 72221.1783 - val_loss: 72886.3295\n",
      "Epoch 264/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 71298.8463 - val_loss: 72030.4644\n",
      "Epoch 265/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 70419.8999 - val_loss: 71223.0296\n",
      "Epoch 266/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 69585.0532 - val_loss: 70448.3886\n",
      "Epoch 267/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 68790.2147 - val_loss: 69721.3484\n",
      "Epoch 268/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 68036.9917 - val_loss: 69024.3305\n",
      "Epoch 269/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 67328.1573 - val_loss: 68372.8979\n",
      "Epoch 270/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 66660.1611 - val_loss: 67771.5547\n",
      "Epoch 271/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 66029.8527 - val_loss: 67205.1946\n",
      "Epoch 272/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 65436.1077 - val_loss: 66670.2208\n",
      "Epoch 273/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 64880.9929 - val_loss: 66171.7773\n",
      "Epoch 274/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 64362.2949 - val_loss: 65713.2485\n",
      "Epoch 275/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 63878.1119 - val_loss: 65284.8388\n",
      "Epoch 276/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 63427.1835 - val_loss: 64888.7249\n",
      "Epoch 277/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 63009.9557 - val_loss: 64515.9545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 62625.0207 - val_loss: 64184.2435\n",
      "Epoch 279/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 62271.8471 - val_loss: 63878.8509\n",
      "Epoch 280/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 61946.2604 - val_loss: 63603.5790\n",
      "Epoch 281/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 61649.8113 - val_loss: 63352.0084\n",
      "Epoch 282/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 61379.9492 - val_loss: 63121.6133\n",
      "Epoch 283/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 61133.6551 - val_loss: 62919.8904\n",
      "Epoch 284/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 60911.6031 - val_loss: 62741.2310\n",
      "Epoch 285/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 60711.2638 - val_loss: 62577.5904\n",
      "Epoch 286/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 60531.0009 - val_loss: 62437.4649\n",
      "Epoch 287/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 60373.2053 - val_loss: 62315.2283\n",
      "Epoch 288/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 60232.0416 - val_loss: 62203.8498\n",
      "Epoch 289/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 60109.4454 - val_loss: 62112.5274\n",
      "Epoch 290/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59999.9194 - val_loss: 62035.1973\n",
      "Epoch 291/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59904.8334 - val_loss: 61967.2163\n",
      "Epoch 292/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59824.9285 - val_loss: 61910.7739\n",
      "Epoch 293/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59752.8633 - val_loss: 61865.7685\n",
      "Epoch 294/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59691.2499 - val_loss: 61824.5569\n",
      "Epoch 295/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59639.1614 - val_loss: 61796.1554\n",
      "Epoch 296/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59595.1075 - val_loss: 61767.4691\n",
      "Epoch 297/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59557.7791 - val_loss: 61749.7612\n",
      "Epoch 298/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59528.2000 - val_loss: 61734.9165\n",
      "Epoch 299/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59503.0632 - val_loss: 61723.9443\n",
      "Epoch 300/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59481.2088 - val_loss: 61715.9684\n",
      "Epoch 301/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59463.6402 - val_loss: 61710.3834\n",
      "Epoch 302/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59449.9184 - val_loss: 61706.6212\n",
      "Epoch 303/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59438.7631 - val_loss: 61704.6685\n",
      "Epoch 304/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59429.7188 - val_loss: 61704.1073\n",
      "Epoch 305/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59423.0148 - val_loss: 61704.3017\n",
      "Epoch 306/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59416.3981 - val_loss: 61705.0905\n",
      "Epoch 307/500\n",
      "3733/3733 [==============================] - 6s 1ms/step - loss: 59412.2474 - val_loss: 61706.1335\n",
      "Epoch 308/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59408.2591 - val_loss: 61707.8250\n",
      "Epoch 309/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59405.0097 - val_loss: 61709.5557\n",
      "Epoch 310/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59402.3440 - val_loss: 61712.0138\n",
      "Epoch 311/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59401.3233 - val_loss: 61713.4516\n",
      "Epoch 312/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59400.4666 - val_loss: 61714.7281\n",
      "Epoch 313/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59399.7115 - val_loss: 61716.1475\n",
      "Epoch 314/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59399.3842 - val_loss: 61718.9093\n",
      "Epoch 315/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.4279 - val_loss: 61719.9645\n",
      "Epoch 316/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.4090 - val_loss: 61721.6482\n",
      "Epoch 317/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59397.3406 - val_loss: 61723.8912\n",
      "Epoch 318/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.3879 - val_loss: 61722.8747\n",
      "Epoch 319/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.3767 - val_loss: 61725.2544\n",
      "Epoch 320/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8124 - val_loss: 61725.8458\n",
      "Epoch 321/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9838 - val_loss: 61727.2706\n",
      "Epoch 322/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6488 - val_loss: 61727.0883\n",
      "Epoch 323/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8223 - val_loss: 61727.3680\n",
      "Epoch 324/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8519 - val_loss: 61728.2347\n",
      "Epoch 325/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.8347 - val_loss: 61730.3114\n",
      "Epoch 326/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2539 - val_loss: 61730.6980\n",
      "Epoch 327/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4458 - val_loss: 61730.9005\n",
      "Epoch 328/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5214 - val_loss: 61730.8535\n",
      "Epoch 329/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8616 - val_loss: 61731.1200\n",
      "Epoch 330/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5038 - val_loss: 61731.6037\n",
      "Epoch 331/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5045 - val_loss: 61731.3245\n",
      "Epoch 332/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4665 - val_loss: 61732.5446\n",
      "Epoch 333/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.4241 - val_loss: 61731.4589\n",
      "Epoch 334/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0759 - val_loss: 61731.0860\n",
      "Epoch 335/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5131 - val_loss: 61730.7997\n",
      "Epoch 336/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1551 - val_loss: 61734.4949\n",
      "Epoch 337/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3051 - val_loss: 61733.7642\n",
      "Epoch 338/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.0329 - val_loss: 61732.8169\n",
      "Epoch 339/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.1956 - val_loss: 61734.8456\n",
      "Epoch 340/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9741 - val_loss: 61732.4219\n",
      "Epoch 341/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.2428 - val_loss: 61733.3381\n",
      "Epoch 342/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0079 - val_loss: 61733.0808\n",
      "Epoch 343/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 59395.0769 - val_loss: 61733.6957\n",
      "Epoch 344/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8730 - val_loss: 61733.8566\n",
      "Epoch 345/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.4698 - val_loss: 61734.5944\n",
      "Epoch 346/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.5776 - val_loss: 61732.3220\n",
      "Epoch 347/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9637 - val_loss: 61733.1106\n",
      "Epoch 348/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0296 - val_loss: 61733.7765\n",
      "Epoch 349/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6302 - val_loss: 61733.5643\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2613 - val_loss: 61733.8629\n",
      "Epoch 351/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.1738 - val_loss: 61733.7652\n",
      "Epoch 352/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8678 - val_loss: 61733.7967\n",
      "Epoch 353/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0705 - val_loss: 61732.1050\n",
      "Epoch 354/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.4255 - val_loss: 61732.4825\n",
      "Epoch 355/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4850 - val_loss: 61733.2000\n",
      "Epoch 356/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9051 - val_loss: 61733.8763\n",
      "Epoch 357/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2934 - val_loss: 61732.8842\n",
      "Epoch 358/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1714 - val_loss: 61732.5240\n",
      "Epoch 359/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4138 - val_loss: 61736.0078\n",
      "Epoch 360/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59393.6233 - val_loss: 61734.0353\n",
      "Epoch 361/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9139 - val_loss: 61730.8981\n",
      "Epoch 362/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9582 - val_loss: 61732.3052\n",
      "Epoch 363/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4560 - val_loss: 61732.8306\n",
      "Epoch 364/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.7805 - val_loss: 61733.7362\n",
      "Epoch 365/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3665 - val_loss: 61732.7978\n",
      "Epoch 366/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5308 - val_loss: 61734.8678\n",
      "Epoch 367/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.5442 - val_loss: 61734.2338\n",
      "Epoch 368/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6374 - val_loss: 61733.6502\n",
      "Epoch 369/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.0610 - val_loss: 61734.5785\n",
      "Epoch 370/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.9484 - val_loss: 61730.6704\n",
      "Epoch 371/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59393.8576 - val_loss: 61733.9187\n",
      "Epoch 372/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6384 - val_loss: 61734.7802\n",
      "Epoch 373/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8271 - val_loss: 61733.2183\n",
      "Epoch 374/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6649 - val_loss: 61733.5773\n",
      "Epoch 375/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.3153 - val_loss: 61731.7240\n",
      "Epoch 376/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4552 - val_loss: 61732.4060\n",
      "Epoch 377/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1790 - val_loss: 61735.0252\n",
      "Epoch 378/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.7099 - val_loss: 61732.5831\n",
      "Epoch 379/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6143 - val_loss: 61732.9182\n",
      "Epoch 380/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0687 - val_loss: 61733.1651\n",
      "Epoch 381/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4248 - val_loss: 61733.2903\n",
      "Epoch 382/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.7480 - val_loss: 61733.0750\n",
      "Epoch 383/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3371 - val_loss: 61733.9500\n",
      "Epoch 384/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.7498 - val_loss: 61731.9018\n",
      "Epoch 385/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1740 - val_loss: 61733.4629\n",
      "Epoch 386/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.1457 - val_loss: 61733.1525\n",
      "Epoch 387/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9966 - val_loss: 61734.1033\n",
      "Epoch 388/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8760 - val_loss: 61734.1933\n",
      "Epoch 389/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1705 - val_loss: 61734.9494\n",
      "Epoch 390/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1521 - val_loss: 61732.7375\n",
      "Epoch 391/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8035 - val_loss: 61733.3984\n",
      "Epoch 392/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4669 - val_loss: 61731.8196\n",
      "Epoch 393/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5922 - val_loss: 61732.2867\n",
      "Epoch 394/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.3654 - val_loss: 61732.5691\n",
      "Epoch 395/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.2411 - val_loss: 61733.3236\n",
      "Epoch 396/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.4333 - val_loss: 61732.8210\n",
      "Epoch 397/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3023 - val_loss: 61734.7673\n",
      "Epoch 398/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.1264 - val_loss: 61734.6014\n",
      "Epoch 399/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.2539 - val_loss: 61734.1364\n",
      "Epoch 400/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3609 - val_loss: 61733.3757\n",
      "Epoch 401/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.0422 - val_loss: 61733.6379\n",
      "Epoch 402/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3100 - val_loss: 61734.0607\n",
      "Epoch 403/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.6247 - val_loss: 61731.2015\n",
      "Epoch 404/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9124 - val_loss: 61734.8066\n",
      "Epoch 405/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9864 - val_loss: 61732.9268\n",
      "Epoch 406/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.2143 - val_loss: 61733.4085\n",
      "Epoch 407/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.7693 - val_loss: 61733.6571\n",
      "Epoch 408/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.8679 - val_loss: 61734.1985\n",
      "Epoch 409/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59393.9824 - val_loss: 61733.5059\n",
      "Epoch 410/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6294 - val_loss: 61735.4069\n",
      "Epoch 411/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6079 - val_loss: 61734.2567\n",
      "Epoch 412/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.3187 - val_loss: 61736.1223\n",
      "Epoch 413/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0208 - val_loss: 61734.9567\n",
      "Epoch 414/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.7725 - val_loss: 61733.7967\n",
      "Epoch 415/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4377 - val_loss: 61734.4643\n",
      "Epoch 416/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4293 - val_loss: 61734.8552\n",
      "Epoch 417/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.9644 - val_loss: 61734.5144\n",
      "Epoch 418/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0761 - val_loss: 61732.7602\n",
      "Epoch 419/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.5956 - val_loss: 61733.4447\n",
      "Epoch 420/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.5864 - val_loss: 61733.2589\n",
      "Epoch 421/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.1942 - val_loss: 61733.0307\n",
      "Epoch 422/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1684 - val_loss: 61735.1686\n",
      "Epoch 423/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0558 - val_loss: 61733.0984\n",
      "Epoch 424/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.2021 - val_loss: 61733.8043\n",
      "Epoch 425/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0100 - val_loss: 61732.1062\n",
      "Epoch 426/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4249 - val_loss: 61734.9033\n",
      "Epoch 427/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.4574 - val_loss: 61733.6152\n",
      "Epoch 428/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6383 - val_loss: 61733.4572\n",
      "Epoch 429/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9738 - val_loss: 61732.8597\n",
      "Epoch 430/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4409 - val_loss: 61731.5883\n",
      "Epoch 431/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4114 - val_loss: 61733.7652\n",
      "Epoch 432/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4001 - val_loss: 61733.2745\n",
      "Epoch 433/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.2621 - val_loss: 61731.5602\n",
      "Epoch 434/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.7038 - val_loss: 61734.4056\n",
      "Epoch 435/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1527 - val_loss: 61731.9018\n",
      "Epoch 436/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9166 - val_loss: 61733.2000\n",
      "Epoch 437/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4906 - val_loss: 61733.5233\n",
      "Epoch 438/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1570 - val_loss: 61733.5563\n",
      "Epoch 439/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.3113 - val_loss: 61734.6629\n",
      "Epoch 440/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.8560 - val_loss: 61734.3536\n",
      "Epoch 441/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5441 - val_loss: 61733.2827\n",
      "Epoch 442/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6942 - val_loss: 61734.6858\n",
      "Epoch 443/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.7601 - val_loss: 61733.7725\n",
      "Epoch 444/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6411 - val_loss: 61733.9837\n",
      "Epoch 445/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9568 - val_loss: 61734.6351\n",
      "Epoch 446/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9069 - val_loss: 61732.4587\n",
      "Epoch 447/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.1362 - val_loss: 61733.1089\n",
      "Epoch 448/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59396.0739 - val_loss: 61732.0679\n",
      "Epoch 449/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8363 - val_loss: 61732.8210\n",
      "Epoch 450/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.2636 - val_loss: 61731.7724\n",
      "Epoch 451/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1699 - val_loss: 61733.2859\n",
      "Epoch 452/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.9852 - val_loss: 61734.7888\n",
      "Epoch 453/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5950 - val_loss: 61733.7242\n",
      "Epoch 454/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2335 - val_loss: 61733.2372\n",
      "Epoch 455/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4041 - val_loss: 61732.2812\n",
      "Epoch 456/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.7861 - val_loss: 61731.9887\n",
      "Epoch 457/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.5096 - val_loss: 61733.4796\n",
      "Epoch 458/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2725 - val_loss: 61732.6858\n",
      "Epoch 459/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1331 - val_loss: 61734.6450\n",
      "Epoch 460/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2609 - val_loss: 61732.7348\n",
      "Epoch 461/500\n",
      "3733/3733 [==============================] - 6s 2ms/step - loss: 59394.5790 - val_loss: 61734.2000\n",
      "Epoch 462/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.0000 - val_loss: 61735.1475\n",
      "Epoch 463/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.3066 - val_loss: 61735.7724\n",
      "Epoch 464/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9531 - val_loss: 61733.1651\n",
      "Epoch 465/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0947 - val_loss: 61733.7302\n",
      "Epoch 466/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.3628 - val_loss: 61733.5144\n",
      "Epoch 467/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6586 - val_loss: 61734.6916\n",
      "Epoch 468/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6054 - val_loss: 61731.9840\n",
      "Epoch 469/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2423 - val_loss: 61732.8484\n",
      "Epoch 470/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9850 - val_loss: 61732.8530\n",
      "Epoch 471/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4576 - val_loss: 61733.5877\n",
      "Epoch 472/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3667 - val_loss: 61732.9127\n",
      "Epoch 473/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.8045 - val_loss: 61732.9058\n",
      "Epoch 474/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3933 - val_loss: 61734.0127\n",
      "Epoch 475/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.8551 - val_loss: 61733.0517\n",
      "Epoch 476/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6065 - val_loss: 61734.1604\n",
      "Epoch 477/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.9047 - val_loss: 61732.0219\n",
      "Epoch 478/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3237 - val_loss: 61733.7642\n",
      "Epoch 479/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6352 - val_loss: 61732.5870\n",
      "Epoch 480/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.7154 - val_loss: 61732.8292\n",
      "Epoch 481/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.7438 - val_loss: 61733.6258\n",
      "Epoch 482/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4227 - val_loss: 61732.5446\n",
      "Epoch 483/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2223 - val_loss: 61732.3270\n",
      "Epoch 484/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.0597 - val_loss: 61733.1810\n",
      "Epoch 485/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5606 - val_loss: 61730.8383\n",
      "Epoch 486/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.9207 - val_loss: 61731.6634\n",
      "Epoch 487/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.8757 - val_loss: 61733.4541\n",
      "Epoch 488/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.4421 - val_loss: 61731.7117\n",
      "Epoch 489/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.7183 - val_loss: 61733.4629\n",
      "Epoch 490/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2952 - val_loss: 61733.5186\n",
      "Epoch 491/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.6411 - val_loss: 61731.2248\n",
      "Epoch 492/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.3557 - val_loss: 61732.3006\n",
      "Epoch 493/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1708 - val_loss: 61732.4336\n",
      "Epoch 494/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.4441 - val_loss: 61734.7327\n",
      "Epoch 495/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.2188 - val_loss: 61732.9484\n",
      "Epoch 496/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.2642 - val_loss: 61732.9455\n",
      "Epoch 497/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.1394 - val_loss: 61733.4227\n",
      "Epoch 498/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59394.5460 - val_loss: 61732.8048\n",
      "Epoch 499/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59395.6440 - val_loss: 61734.0371\n",
      "Epoch 500/500\n",
      "3733/3733 [==============================] - 5s 1ms/step - loss: 59397.5242 - val_loss: 61731.5265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136211780>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=500, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 30, 50)            11800     \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 30, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 52,251\n",
      "Trainable params: 52,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3800 samples, validate on 233 samples\n",
      "Epoch 1/500\n",
      "3800/3800 [==============================] - 9s 2ms/step - loss: 2472527.2700 - val_loss: 2458688.0408\n",
      "Epoch 2/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2448322.6521 - val_loss: 2439940.6137\n",
      "Epoch 3/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 2430052.9474 - val_loss: 2422017.2736\n",
      "Epoch 4/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 2412334.9542 - val_loss: 2404506.2060\n",
      "Epoch 5/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2394904.9300 - val_loss: 2387190.9281\n",
      "Epoch 6/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2377675.2700 - val_loss: 2370067.4936\n",
      "Epoch 7/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 2360604.1589 - val_loss: 2353061.7189\n",
      "Epoch 8/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2343662.4563 - val_loss: 2336217.8820\n",
      "Epoch 9/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2326846.9411 - val_loss: 2319446.8734\n",
      "Epoch 10/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2310135.8811 - val_loss: 2302812.4206\n",
      "Epoch 11/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2293528.4247 - val_loss: 2286284.0644\n",
      "Epoch 12/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2277017.9558 - val_loss: 2269835.0483\n",
      "Epoch 13/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2260597.0826 - val_loss: 2253472.0215\n",
      "Epoch 14/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2244265.9416 - val_loss: 2237186.8788\n",
      "Epoch 15/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 2228019.5605 - val_loss: 2221007.2639\n",
      "Epoch 16/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2211859.6721 - val_loss: 2204886.7865\n",
      "Epoch 17/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2195779.2589 - val_loss: 2188869.7436\n",
      "Epoch 18/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2179775.5174 - val_loss: 2172924.7543\n",
      "Epoch 19/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2163851.7321 - val_loss: 2157044.5172\n",
      "Epoch 20/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2148001.2532 - val_loss: 2141258.5901\n",
      "Epoch 21/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 2132229.1163 - val_loss: 2125522.8498\n",
      "Epoch 22/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2116527.9663 - val_loss: 2109880.8433\n",
      "Epoch 23/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2100903.9974 - val_loss: 2094291.8766\n",
      "Epoch 24/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 2085346.4042 - val_loss: 2078799.9303\n",
      "Epoch 25/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2069860.5084 - val_loss: 2063359.7296\n",
      "Epoch 26/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2054445.3879 - val_loss: 2047986.0848\n",
      "Epoch 27/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2039096.1342 - val_loss: 2032687.5054\n",
      "Epoch 28/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2023814.7095 - val_loss: 2017464.2468\n",
      "Epoch 29/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 2008603.2382 - val_loss: 2002287.2264\n",
      "Epoch 30/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1993455.2366 - val_loss: 1987196.1019\n",
      "Epoch 31/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1978376.1253 - val_loss: 1972172.0139\n",
      "Epoch 32/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1963360.2632 - val_loss: 1957203.5021\n",
      "Epoch 33/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1948411.8463 - val_loss: 1942288.9732\n",
      "Epoch 34/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1933528.3045 - val_loss: 1927445.0418\n",
      "Epoch 35/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1918707.9274 - val_loss: 1912683.2275\n",
      "Epoch 36/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1903953.0239 - val_loss: 1897972.9034\n",
      "Epoch 37/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1889260.0821 - val_loss: 1883323.5697\n",
      "Epoch 38/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1874630.9450 - val_loss: 1868738.3433\n",
      "Epoch 39/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1860067.6989 - val_loss: 1854221.5113\n",
      "Epoch 40/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1845566.6329 - val_loss: 1839759.7505\n",
      "Epoch 41/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1831127.5282 - val_loss: 1825376.1556\n",
      "Epoch 42/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1816752.1939 - val_loss: 1811035.5440\n",
      "Epoch 43/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1802434.0842 - val_loss: 1796769.2725\n",
      "Epoch 44/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1788180.3955 - val_loss: 1782574.9174\n",
      "Epoch 45/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1773991.2989 - val_loss: 1768407.1223\n",
      "Epoch 46/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1759861.4692 - val_loss: 1754322.0858\n",
      "Epoch 47/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1745792.0776 - val_loss: 1740313.8476\n",
      "Epoch 48/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1731788.2018 - val_loss: 1726343.3653\n",
      "Epoch 49/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1717843.1989 - val_loss: 1712458.3525\n",
      "Epoch 50/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1703962.2182 - val_loss: 1698611.6738\n",
      "Epoch 51/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1690137.7097 - val_loss: 1684839.7591\n",
      "Epoch 52/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1676375.0634 - val_loss: 1671125.5773\n",
      "Epoch 53/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1662672.8376 - val_loss: 1657462.1947\n",
      "Epoch 54/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1649034.5095 - val_loss: 1643859.9764\n",
      "Epoch 55/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1635457.2771 - val_loss: 1630327.0370\n",
      "Epoch 56/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1621938.9371 - val_loss: 1616856.0215\n",
      "Epoch 57/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1608480.8476 - val_loss: 1603442.1872\n",
      "Epoch 58/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1595083.3597 - val_loss: 1590098.3696\n",
      "Epoch 59/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1581749.6176 - val_loss: 1576795.8519\n",
      "Epoch 60/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1568474.3876 - val_loss: 1563565.0027\n",
      "Epoch 61/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1555260.6134 - val_loss: 1550397.3101\n",
      "Epoch 62/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1542106.9126 - val_loss: 1537286.7892\n",
      "Epoch 63/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1529011.2276 - val_loss: 1524257.9142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1515980.5071 - val_loss: 1511252.0923\n",
      "Epoch 65/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1503008.6474 - val_loss: 1498318.1888\n",
      "Epoch 66/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1490095.8203 - val_loss: 1485463.7795\n",
      "Epoch 67/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1477246.5968 - val_loss: 1472650.5156\n",
      "Epoch 68/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1464453.2150 - val_loss: 1459908.4667\n",
      "Epoch 69/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1451722.3900 - val_loss: 1447213.1609\n",
      "Epoch 70/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1439050.8397 - val_loss: 1434589.5826\n",
      "Epoch 71/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1426440.4266 - val_loss: 1422016.2178\n",
      "Epoch 72/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1413892.3008 - val_loss: 1409511.5070\n",
      "Epoch 73/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1401401.7358 - val_loss: 1397076.2613\n",
      "Epoch 74/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1388972.4066 - val_loss: 1384686.9378\n",
      "Epoch 75/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1376599.0203 - val_loss: 1372364.9249\n",
      "Epoch 76/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1364289.5587 - val_loss: 1360097.7334\n",
      "Epoch 77/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1352039.9129 - val_loss: 1347886.5075\n",
      "Epoch 78/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1339851.5139 - val_loss: 1335742.3010\n",
      "Epoch 79/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1327721.9766 - val_loss: 1323654.0896\n",
      "Epoch 80/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1315653.8463 - val_loss: 1311625.8755\n",
      "Epoch 81/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1303643.3618 - val_loss: 1299679.6947\n",
      "Epoch 82/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1291694.6729 - val_loss: 1287751.1212\n",
      "Epoch 83/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1279801.8066 - val_loss: 1275916.8965\n",
      "Epoch 84/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1267970.1016 - val_loss: 1264140.4217\n",
      "Epoch 85/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1256198.4787 - val_loss: 1252400.2935\n",
      "Epoch 86/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1244486.5387 - val_loss: 1240738.6250\n",
      "Epoch 87/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1232837.5308 - val_loss: 1229120.8911\n",
      "Epoch 88/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1221243.8284 - val_loss: 1217584.3251\n",
      "Epoch 89/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1209710.8847 - val_loss: 1206099.7570\n",
      "Epoch 90/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1198237.6768 - val_loss: 1194662.2972\n",
      "Epoch 91/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1186827.2684 - val_loss: 1183287.6888\n",
      "Epoch 92/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1175477.6708 - val_loss: 1171991.4802\n",
      "Epoch 93/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1164186.9792 - val_loss: 1160739.3348\n",
      "Epoch 94/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1152955.1913 - val_loss: 1149548.8471\n",
      "Epoch 95/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1141782.6261 - val_loss: 1138428.7511\n",
      "Epoch 96/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1130673.2695 - val_loss: 1127346.7355\n",
      "Epoch 97/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1119623.3203 - val_loss: 1116346.5252\n",
      "Epoch 98/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1108628.5374 - val_loss: 1105419.1829\n",
      "Epoch 99/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1097699.0695 - val_loss: 1094508.9431\n",
      "Epoch 100/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1086825.4570 - val_loss: 1083681.3197\n",
      "Epoch 101/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1076013.3139 - val_loss: 1072923.9764\n",
      "Epoch 102/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1065260.6332 - val_loss: 1062207.1803\n",
      "Epoch 103/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1054566.4659 - val_loss: 1051558.9388\n",
      "Epoch 104/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1043932.9505 - val_loss: 1040966.3605\n",
      "Epoch 105/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1033357.7237 - val_loss: 1030430.5590\n",
      "Epoch 106/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1022843.0793 - val_loss: 1019967.8745\n",
      "Epoch 107/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 1012389.7347 - val_loss: 1009547.4871\n",
      "Epoch 108/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1001994.3062 - val_loss: 999193.8739\n",
      "Epoch 109/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 991658.3483 - val_loss: 988913.9533\n",
      "Epoch 110/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 981382.0243 - val_loss: 978680.1105\n",
      "Epoch 111/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 971164.9225 - val_loss: 968512.1068\n",
      "Epoch 112/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 961010.7737 - val_loss: 958387.4394\n",
      "Epoch 113/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 950909.3332 - val_loss: 948342.7623\n",
      "Epoch 114/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 940873.9301 - val_loss: 938335.6132\n",
      "Epoch 115/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 930893.1696 - val_loss: 928412.2935\n",
      "Epoch 116/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 920974.0333 - val_loss: 918535.2623\n",
      "Epoch 117/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 911114.3654 - val_loss: 908709.8712\n",
      "Epoch 118/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 901314.0288 - val_loss: 898968.7639\n",
      "Epoch 119/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 891573.1154 - val_loss: 889256.6964\n",
      "Epoch 120/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 881889.6153 - val_loss: 879626.4214\n",
      "Epoch 121/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 872268.2726 - val_loss: 870041.0638\n",
      "Epoch 122/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 862703.2512 - val_loss: 860533.9525\n",
      "Epoch 123/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 853202.1675 - val_loss: 851070.3860\n",
      "Epoch 124/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 843760.0626 - val_loss: 841668.3597\n",
      "Epoch 125/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 834373.1378 - val_loss: 832319.8839\n",
      "Epoch 126/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 825045.7516 - val_loss: 823056.0692\n",
      "Epoch 127/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 815782.9036 - val_loss: 813809.5671\n",
      "Epoch 128/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 806574.2821 - val_loss: 804653.3876\n",
      "Epoch 129/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 797425.7226 - val_loss: 795549.4804\n",
      "Epoch 130/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 788336.6414 - val_loss: 786514.2256\n",
      "Epoch 131/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 779308.2304 - val_loss: 777520.8970\n",
      "Epoch 132/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 770338.4062 - val_loss: 768586.1797\n",
      "Epoch 133/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 761426.9682 - val_loss: 759712.2747\n",
      "Epoch 134/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 752575.6495 - val_loss: 750914.8463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 743782.1536 - val_loss: 742174.2782\n",
      "Epoch 136/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 735047.8709 - val_loss: 733476.2991\n",
      "Epoch 137/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 726372.7320 - val_loss: 724838.4423\n",
      "Epoch 138/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 717756.7011 - val_loss: 716267.9611\n",
      "Epoch 139/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 709197.2270 - val_loss: 707763.3812\n",
      "Epoch 140/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 700699.3901 - val_loss: 699303.7516\n",
      "Epoch 141/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 692260.8641 - val_loss: 690902.9565\n",
      "Epoch 142/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 683878.6187 - val_loss: 682571.8149\n",
      "Epoch 143/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 675557.0242 - val_loss: 674298.4439\n",
      "Epoch 144/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 667295.2758 - val_loss: 666064.8278\n",
      "Epoch 145/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 659092.1154 - val_loss: 657910.3522\n",
      "Epoch 146/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 650946.2308 - val_loss: 649817.9252\n",
      "Epoch 147/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 642863.2291 - val_loss: 641749.4354\n",
      "Epoch 148/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 634834.8421 - val_loss: 633786.8061\n",
      "Epoch 149/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 626870.6163 - val_loss: 625858.5287\n",
      "Epoch 150/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 618960.1693 - val_loss: 617992.5046\n",
      "Epoch 151/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 611108.3559 - val_loss: 610191.7910\n",
      "Epoch 152/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 603315.4275 - val_loss: 602440.8683\n",
      "Epoch 153/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 595582.0084 - val_loss: 594738.4356\n",
      "Epoch 154/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 587906.5267 - val_loss: 587116.9815\n",
      "Epoch 155/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 580290.7747 - val_loss: 579538.2495\n",
      "Epoch 156/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 572734.1233 - val_loss: 572030.9539\n",
      "Epoch 157/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 565234.4635 - val_loss: 564578.5448\n",
      "Epoch 158/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 557795.9729 - val_loss: 557166.2116\n",
      "Epoch 159/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 550410.3607 - val_loss: 549844.3391\n",
      "Epoch 160/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 543087.7975 - val_loss: 542547.4480\n",
      "Epoch 161/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 535822.5299 - val_loss: 535322.0188\n",
      "Epoch 162/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 528617.2543 - val_loss: 528163.0030\n",
      "Epoch 163/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 521468.7186 - val_loss: 521058.3726\n",
      "Epoch 164/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 514377.5140 - val_loss: 514020.3222\n",
      "Epoch 165/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 507348.3024 - val_loss: 507025.6556\n",
      "Epoch 166/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 500372.9137 - val_loss: 500090.0408\n",
      "Epoch 167/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 493457.8189 - val_loss: 493210.5325\n",
      "Epoch 168/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 486599.6913 - val_loss: 486405.3412\n",
      "Epoch 169/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 479803.8735 - val_loss: 479651.4241\n",
      "Epoch 170/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 473062.8836 - val_loss: 472957.3337\n",
      "Epoch 171/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 466379.1387 - val_loss: 466306.9152\n",
      "Epoch 172/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 459752.4882 - val_loss: 459729.0252\n",
      "Epoch 173/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 453184.1581 - val_loss: 453205.2945\n",
      "Epoch 174/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 446673.3200 - val_loss: 446738.3780\n",
      "Epoch 175/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 440221.7424 - val_loss: 440329.8667\n",
      "Epoch 176/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 433827.3995 - val_loss: 433964.8024\n",
      "Epoch 177/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 427490.7576 - val_loss: 427679.3609\n",
      "Epoch 178/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 421213.4250 - val_loss: 421450.2893\n",
      "Epoch 179/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 414991.8288 - val_loss: 415270.8474\n",
      "Epoch 180/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 408830.6051 - val_loss: 409140.1632\n",
      "Epoch 181/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 402727.0657 - val_loss: 403081.6845\n",
      "Epoch 182/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 396684.4837 - val_loss: 397078.6175\n",
      "Epoch 183/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 390695.7949 - val_loss: 391144.5079\n",
      "Epoch 184/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 384766.8993 - val_loss: 385243.1969\n",
      "Epoch 185/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 378893.3550 - val_loss: 379418.3971\n",
      "Epoch 186/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 373077.6466 - val_loss: 373654.0490\n",
      "Epoch 187/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 367318.8782 - val_loss: 367924.6701\n",
      "Epoch 188/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 361616.8069 - val_loss: 362266.4910\n",
      "Epoch 189/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 355973.1909 - val_loss: 356671.8686\n",
      "Epoch 190/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 350384.9161 - val_loss: 351120.4376\n",
      "Epoch 191/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 344853.5141 - val_loss: 345639.9437\n",
      "Epoch 192/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 339381.8708 - val_loss: 340199.4675\n",
      "Epoch 193/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 333966.3114 - val_loss: 334828.4836\n",
      "Epoch 194/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 328608.6084 - val_loss: 329520.0673\n",
      "Epoch 195/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 323308.1416 - val_loss: 324249.4289\n",
      "Epoch 196/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 318062.9418 - val_loss: 319063.3332\n",
      "Epoch 197/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 312874.2826 - val_loss: 313910.6815\n",
      "Epoch 198/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 307744.1525 - val_loss: 308811.7570\n",
      "Epoch 199/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 302667.1565 - val_loss: 303797.9034\n",
      "Epoch 200/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 297651.6030 - val_loss: 298805.4748\n",
      "Epoch 201/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 292688.8197 - val_loss: 293901.5253\n",
      "Epoch 202/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 287786.5527 - val_loss: 289023.6722\n",
      "Epoch 203/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 282937.1158 - val_loss: 284229.6611\n",
      "Epoch 204/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 278147.8069 - val_loss: 279472.0093\n",
      "Epoch 205/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 273413.2178 - val_loss: 274787.4316\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 5s 1ms/step - loss: 268735.0643 - val_loss: 270145.1825\n",
      "Epoch 207/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 264112.4346 - val_loss: 265562.2417\n",
      "Epoch 208/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 259547.4782 - val_loss: 261040.2902\n",
      "Epoch 209/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 255038.2914 - val_loss: 256577.8169\n",
      "Epoch 210/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 250587.1492 - val_loss: 252154.4481\n",
      "Epoch 211/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 246193.0723 - val_loss: 247801.2509\n",
      "Epoch 212/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 241853.8554 - val_loss: 243513.4295\n",
      "Epoch 213/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 237569.7605 - val_loss: 239260.5327\n",
      "Epoch 214/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 233340.4905 - val_loss: 235086.7366\n",
      "Epoch 215/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 229170.5135 - val_loss: 230942.1656\n",
      "Epoch 216/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 225052.8712 - val_loss: 226869.0396\n",
      "Epoch 217/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 220991.8448 - val_loss: 222851.0480\n",
      "Epoch 218/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 216986.8497 - val_loss: 218886.0870\n",
      "Epoch 219/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 213034.7224 - val_loss: 214969.9763\n",
      "Epoch 220/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 209135.9502 - val_loss: 211124.2854\n",
      "Epoch 221/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 205296.6987 - val_loss: 207321.6220\n",
      "Epoch 222/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 201511.8383 - val_loss: 203566.8992\n",
      "Epoch 223/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 197780.1024 - val_loss: 199886.4606\n",
      "Epoch 224/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 194107.1088 - val_loss: 196251.8904\n",
      "Epoch 225/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 190487.3920 - val_loss: 192668.9350\n",
      "Epoch 226/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 186919.7843 - val_loss: 189156.7540\n",
      "Epoch 227/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 183408.3250 - val_loss: 185676.3091\n",
      "Epoch 228/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 179949.2351 - val_loss: 182254.1651\n",
      "Epoch 229/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 176546.9191 - val_loss: 178894.9745\n",
      "Epoch 230/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 173195.2022 - val_loss: 175587.1903\n",
      "Epoch 231/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 169902.0673 - val_loss: 172324.1999\n",
      "Epoch 232/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 166662.1785 - val_loss: 169123.0740\n",
      "Epoch 233/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 163475.8133 - val_loss: 165983.4508\n",
      "Epoch 234/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 160342.5955 - val_loss: 162887.6733\n",
      "Epoch 235/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 157262.7623 - val_loss: 159846.2797\n",
      "Epoch 236/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 154238.0249 - val_loss: 156861.4051\n",
      "Epoch 237/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 151264.5398 - val_loss: 153944.6825\n",
      "Epoch 238/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 148344.8538 - val_loss: 151051.5741\n",
      "Epoch 239/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 145478.7287 - val_loss: 148215.2768\n",
      "Epoch 240/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 142668.1702 - val_loss: 145436.5018\n",
      "Epoch 241/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 139910.9118 - val_loss: 142724.2229\n",
      "Epoch 242/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 137206.0033 - val_loss: 140059.3396\n",
      "Epoch 243/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 134550.4052 - val_loss: 137454.6612\n",
      "Epoch 244/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 131948.2301 - val_loss: 134893.2080\n",
      "Epoch 245/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 129401.2016 - val_loss: 132366.4456\n",
      "Epoch 246/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 126902.2108 - val_loss: 129920.7628\n",
      "Epoch 247/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 124458.3027 - val_loss: 127514.4152\n",
      "Epoch 248/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 122065.5890 - val_loss: 125159.4498\n",
      "Epoch 249/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 119725.7135 - val_loss: 122844.3246\n",
      "Epoch 250/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 117433.7815 - val_loss: 120601.4934\n",
      "Epoch 251/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 115192.7943 - val_loss: 118401.4231\n",
      "Epoch 252/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 113003.0409 - val_loss: 116239.8294\n",
      "Epoch 253/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 110863.0303 - val_loss: 114135.9684\n",
      "Epoch 254/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 108775.7758 - val_loss: 112096.6620\n",
      "Epoch 255/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 106737.3977 - val_loss: 110098.7714\n",
      "Epoch 256/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 104750.8827 - val_loss: 108136.1732\n",
      "Epoch 257/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 102813.3253 - val_loss: 106240.0254\n",
      "Epoch 258/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 100926.0439 - val_loss: 104395.8330\n",
      "Epoch 259/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 99089.3330 - val_loss: 102586.5872\n",
      "Epoch 260/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 97298.4124 - val_loss: 100841.0039\n",
      "Epoch 261/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 95559.9024 - val_loss: 99129.8354\n",
      "Epoch 262/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 93868.3596 - val_loss: 97475.4312\n",
      "Epoch 263/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 92225.9120 - val_loss: 95861.2908\n",
      "Epoch 264/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 90628.6551 - val_loss: 94313.8760\n",
      "Epoch 265/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 89078.9697 - val_loss: 92794.9016\n",
      "Epoch 266/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 87574.2328 - val_loss: 91337.3065\n",
      "Epoch 267/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 86119.4033 - val_loss: 89899.2404\n",
      "Epoch 268/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 84709.8160 - val_loss: 88531.4996\n",
      "Epoch 269/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 83348.0322 - val_loss: 87204.2248\n",
      "Epoch 270/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 82031.4362 - val_loss: 85913.0909\n",
      "Epoch 271/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 80761.2092 - val_loss: 84679.4266\n",
      "Epoch 272/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 79536.6773 - val_loss: 83482.2788\n",
      "Epoch 273/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 78355.3501 - val_loss: 82340.0448\n",
      "Epoch 274/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 77217.6972 - val_loss: 81242.1481\n",
      "Epoch 275/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 76126.8256 - val_loss: 80166.9060\n",
      "Epoch 276/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 75075.7596 - val_loss: 79160.5720\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 6s 2ms/step - loss: 74068.5177 - val_loss: 78182.7949\n",
      "Epoch 278/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 73102.4405 - val_loss: 77256.6571\n",
      "Epoch 279/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 72178.9119 - val_loss: 76353.2742\n",
      "Epoch 280/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 71294.0154 - val_loss: 75495.5267\n",
      "Epoch 281/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 70450.4143 - val_loss: 74691.6758\n",
      "Epoch 282/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 69646.9315 - val_loss: 73908.4625\n",
      "Epoch 283/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 68878.8125 - val_loss: 73175.4777\n",
      "Epoch 284/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 68151.0038 - val_loss: 72473.8721\n",
      "Epoch 285/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 67459.4074 - val_loss: 71812.4541\n",
      "Epoch 286/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 66806.1052 - val_loss: 71182.4088\n",
      "Epoch 287/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 66186.8830 - val_loss: 70596.5845\n",
      "Epoch 288/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 65602.9549 - val_loss: 70044.7707\n",
      "Epoch 289/500\n",
      "3800/3800 [==============================] - 7s 2ms/step - loss: 65052.5209 - val_loss: 69513.7206\n",
      "Epoch 290/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 64535.5663 - val_loss: 69022.1441\n",
      "Epoch 291/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 64052.3764 - val_loss: 68560.5951\n",
      "Epoch 292/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 63602.1480 - val_loss: 68131.9346\n",
      "Epoch 293/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 63182.6988 - val_loss: 67740.7599\n",
      "Epoch 294/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 62791.3286 - val_loss: 67380.0787\n",
      "Epoch 295/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 62430.5683 - val_loss: 67035.5898\n",
      "Epoch 296/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 62094.9894 - val_loss: 66718.0854\n",
      "Epoch 297/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 61786.4469 - val_loss: 66430.5012\n",
      "Epoch 298/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 61502.7204 - val_loss: 66176.4028\n",
      "Epoch 299/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 61244.2297 - val_loss: 65922.7416\n",
      "Epoch 300/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 61009.2136 - val_loss: 65710.2399\n",
      "Epoch 301/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 60798.8743 - val_loss: 65511.9034\n",
      "Epoch 302/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 60607.7506 - val_loss: 65338.9831\n",
      "Epoch 303/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 60436.6844 - val_loss: 65184.6340\n",
      "Epoch 304/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 60282.9419 - val_loss: 65050.1341\n",
      "Epoch 305/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 60146.3344 - val_loss: 64921.9331\n",
      "Epoch 306/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 60024.0838 - val_loss: 64817.9536\n",
      "Epoch 307/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59917.7742 - val_loss: 64721.3773\n",
      "Epoch 308/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59821.3849 - val_loss: 64632.0087\n",
      "Epoch 309/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59739.4009 - val_loss: 64567.8044\n",
      "Epoch 310/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59665.4823 - val_loss: 64497.6966\n",
      "Epoch 311/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59604.1365 - val_loss: 64446.1324\n",
      "Epoch 312/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59550.6775 - val_loss: 64402.9366\n",
      "Epoch 313/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59505.4633 - val_loss: 64361.2107\n",
      "Epoch 314/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59466.4573 - val_loss: 64330.5665\n",
      "Epoch 315/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59434.0473 - val_loss: 64304.0794\n",
      "Epoch 316/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59407.8622 - val_loss: 64283.0678\n",
      "Epoch 317/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59384.8973 - val_loss: 64266.1162\n",
      "Epoch 318/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59365.0996 - val_loss: 64249.7023\n",
      "Epoch 319/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59349.8483 - val_loss: 64237.6621\n",
      "Epoch 320/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59338.2174 - val_loss: 64228.0332\n",
      "Epoch 321/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59327.0909 - val_loss: 64220.9090\n",
      "Epoch 322/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59319.2911 - val_loss: 64212.9967\n",
      "Epoch 323/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59311.8024 - val_loss: 64209.9363\n",
      "Epoch 324/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59306.0806 - val_loss: 64206.9284\n",
      "Epoch 325/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59301.4521 - val_loss: 64203.5767\n",
      "Epoch 326/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59298.0850 - val_loss: 64201.7308\n",
      "Epoch 327/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59294.5112 - val_loss: 64199.9409\n",
      "Epoch 328/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59292.4744 - val_loss: 64199.2030\n",
      "Epoch 329/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59290.8804 - val_loss: 64198.1627\n",
      "Epoch 330/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59289.5658 - val_loss: 64197.4762\n",
      "Epoch 331/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59287.9142 - val_loss: 64197.1508\n",
      "Epoch 332/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59288.2395 - val_loss: 64196.8364\n",
      "Epoch 333/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59287.5259 - val_loss: 64196.7705\n",
      "Epoch 334/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59287.1231 - val_loss: 64196.7654\n",
      "Epoch 335/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59286.2538 - val_loss: 64196.7912\n",
      "Epoch 336/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59286.4064 - val_loss: 64196.9026\n",
      "Epoch 337/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59285.8477 - val_loss: 64196.9177\n",
      "Epoch 338/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.5671 - val_loss: 64196.9747\n",
      "Epoch 339/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.2668 - val_loss: 64197.0552\n",
      "Epoch 340/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59286.9459 - val_loss: 64197.2876\n",
      "Epoch 341/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.3758 - val_loss: 64197.3554\n",
      "Epoch 342/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59286.5434 - val_loss: 64197.4323\n",
      "Epoch 343/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.9729 - val_loss: 64197.8460\n",
      "Epoch 344/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.2392 - val_loss: 64197.3826\n",
      "Epoch 345/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4266 - val_loss: 64198.0918\n",
      "Epoch 346/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8064 - val_loss: 64198.0488\n",
      "Epoch 347/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6262 - val_loss: 64197.8877\n",
      "Epoch 348/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4744 - val_loss: 64197.8306\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6876 - val_loss: 64197.7888\n",
      "Epoch 350/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7495 - val_loss: 64198.0375\n",
      "Epoch 351/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.3399 - val_loss: 64197.8214\n",
      "Epoch 352/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.7621 - val_loss: 64198.0630\n",
      "Epoch 353/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.0404 - val_loss: 64198.2703\n",
      "Epoch 354/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.4799 - val_loss: 64198.2179\n",
      "Epoch 355/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.5643 - val_loss: 64197.9696\n",
      "Epoch 356/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.7790 - val_loss: 64197.9558\n",
      "Epoch 357/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.0143 - val_loss: 64198.7362\n",
      "Epoch 358/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.1156 - val_loss: 64198.4494\n",
      "Epoch 359/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5879 - val_loss: 64198.1924\n",
      "Epoch 360/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5381 - val_loss: 64198.2345\n",
      "Epoch 361/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59285.1243 - val_loss: 64198.3690\n",
      "Epoch 362/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8105 - val_loss: 64198.4911\n",
      "Epoch 363/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.9486 - val_loss: 64198.1924\n",
      "Epoch 364/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8300 - val_loss: 64198.7092\n",
      "Epoch 365/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59283.8762 - val_loss: 64198.3840\n",
      "Epoch 366/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1520 - val_loss: 64198.3849\n",
      "Epoch 367/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.1862 - val_loss: 64198.4187\n",
      "Epoch 368/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.8194 - val_loss: 64198.9934\n",
      "Epoch 369/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.3069 - val_loss: 64198.2560\n",
      "Epoch 370/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59285.2659 - val_loss: 64198.4106\n",
      "Epoch 371/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4883 - val_loss: 64198.3811\n",
      "Epoch 372/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.3395 - val_loss: 64198.5762\n",
      "Epoch 373/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59286.2408 - val_loss: 64198.2270\n",
      "Epoch 374/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.0839 - val_loss: 64198.1546\n",
      "Epoch 375/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.5129 - val_loss: 64198.9396\n",
      "Epoch 376/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.2105 - val_loss: 64198.4720\n",
      "Epoch 377/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6710 - val_loss: 64198.5572\n",
      "Epoch 378/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.1207 - val_loss: 64198.2108\n",
      "Epoch 379/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5807 - val_loss: 64198.4104\n",
      "Epoch 380/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1869 - val_loss: 64198.2541\n",
      "Epoch 381/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.7047 - val_loss: 64198.0931\n",
      "Epoch 382/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4605 - val_loss: 64198.4369\n",
      "Epoch 383/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.4661 - val_loss: 64198.4273\n",
      "Epoch 384/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.8962 - val_loss: 64198.1996\n",
      "Epoch 385/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59285.8405 - val_loss: 64197.7252\n",
      "Epoch 386/500\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 59284.4025 - val_loss: 64198.3621\n",
      "Epoch 387/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.1117 - val_loss: 64198.1877\n",
      "Epoch 388/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.7318 - val_loss: 64198.4604\n",
      "Epoch 389/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59286.6494 - val_loss: 64198.1127\n",
      "Epoch 390/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4314 - val_loss: 64198.6567\n",
      "Epoch 391/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.3237 - val_loss: 64198.4277\n",
      "Epoch 392/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1312 - val_loss: 64198.2877\n",
      "Epoch 393/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4934 - val_loss: 64198.7497\n",
      "Epoch 394/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.0927 - val_loss: 64198.3747\n",
      "Epoch 395/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.8700 - val_loss: 64198.2253\n",
      "Epoch 396/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.9011 - val_loss: 64198.5749\n",
      "Epoch 397/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.3200 - val_loss: 64198.3046\n",
      "Epoch 398/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.8898 - val_loss: 64198.3289\n",
      "Epoch 399/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.0658 - val_loss: 64198.1258\n",
      "Epoch 400/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.8987 - val_loss: 64198.1971\n",
      "Epoch 401/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.4387 - val_loss: 64198.2060\n",
      "Epoch 402/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6231 - val_loss: 64198.1104\n",
      "Epoch 403/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.2328 - val_loss: 64198.6916\n",
      "Epoch 404/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.3438 - val_loss: 64198.4541\n",
      "Epoch 405/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1163 - val_loss: 64198.3777\n",
      "Epoch 406/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.4135 - val_loss: 64198.0374\n",
      "Epoch 407/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.3338 - val_loss: 64198.7773\n",
      "Epoch 408/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.4051 - val_loss: 64198.7751\n",
      "Epoch 409/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59285.0857 - val_loss: 64198.1792\n",
      "Epoch 410/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.7588 - val_loss: 64198.6690\n",
      "Epoch 411/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.0873 - val_loss: 64198.1122\n",
      "Epoch 412/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.8628 - val_loss: 64198.5162\n",
      "Epoch 413/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7569 - val_loss: 64198.5254\n",
      "Epoch 414/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6814 - val_loss: 64198.8071\n",
      "Epoch 415/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1916 - val_loss: 64198.1601\n",
      "Epoch 416/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.0789 - val_loss: 64198.2949\n",
      "Epoch 417/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.0550 - val_loss: 64198.3444\n",
      "Epoch 418/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.8950 - val_loss: 64198.2840\n",
      "Epoch 419/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4125 - val_loss: 64198.5386\n",
      "Epoch 420/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8683 - val_loss: 64198.8041\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.2224 - val_loss: 64198.0387\n",
      "Epoch 422/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1473 - val_loss: 64198.2625\n",
      "Epoch 423/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.2172 - val_loss: 64198.4745\n",
      "Epoch 424/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.5765 - val_loss: 64198.4626\n",
      "Epoch 425/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7299 - val_loss: 64198.6375\n",
      "Epoch 426/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5213 - val_loss: 64198.6797\n",
      "Epoch 427/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5199 - val_loss: 64198.2625\n",
      "Epoch 428/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59286.2057 - val_loss: 64198.6432\n",
      "Epoch 429/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.3406 - val_loss: 64198.2848\n",
      "Epoch 430/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8664 - val_loss: 64198.2708\n",
      "Epoch 431/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4695 - val_loss: 64198.3289\n",
      "Epoch 432/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59286.3490 - val_loss: 64198.2498\n",
      "Epoch 433/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.4797 - val_loss: 64198.1315\n",
      "Epoch 434/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6126 - val_loss: 64198.5991\n",
      "Epoch 435/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7631 - val_loss: 64198.5844\n",
      "Epoch 436/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.8960 - val_loss: 64198.3093\n",
      "Epoch 437/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9129 - val_loss: 64198.2541\n",
      "Epoch 438/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.6207 - val_loss: 64199.0918\n",
      "Epoch 439/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.7247 - val_loss: 64198.3622\n",
      "Epoch 440/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9141 - val_loss: 64198.4604\n",
      "Epoch 441/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6567 - val_loss: 64198.1201\n",
      "Epoch 442/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4422 - val_loss: 64198.4288\n",
      "Epoch 443/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8254 - val_loss: 64198.0787\n",
      "Epoch 444/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.9538 - val_loss: 64198.1145\n",
      "Epoch 445/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7209 - val_loss: 64198.8641\n",
      "Epoch 446/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.0510 - val_loss: 64198.5101\n",
      "Epoch 447/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7308 - val_loss: 64198.8187\n",
      "Epoch 448/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.2365 - val_loss: 64198.2283\n",
      "Epoch 449/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.1585 - val_loss: 64198.2283\n",
      "Epoch 450/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5692 - val_loss: 64198.1177\n",
      "Epoch 451/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6278 - val_loss: 64198.4743\n",
      "Epoch 452/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4353 - val_loss: 64198.4110\n",
      "Epoch 453/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1102 - val_loss: 64198.2362\n",
      "Epoch 454/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.2208 - val_loss: 64198.5176\n",
      "Epoch 455/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4704 - val_loss: 64198.8499\n",
      "Epoch 456/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6553 - val_loss: 64198.4542\n",
      "Epoch 457/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.3989 - val_loss: 64198.5493\n",
      "Epoch 458/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.3684 - val_loss: 64198.0555\n",
      "Epoch 459/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.4920 - val_loss: 64198.8345\n",
      "Epoch 460/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9721 - val_loss: 64198.2545\n",
      "Epoch 461/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9238 - val_loss: 64198.8347\n",
      "Epoch 462/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6383 - val_loss: 64198.5572\n",
      "Epoch 463/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4369 - val_loss: 64198.3222\n",
      "Epoch 464/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.6527 - val_loss: 64198.4246\n",
      "Epoch 465/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.4066 - val_loss: 64198.6168\n",
      "Epoch 466/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1589 - val_loss: 64198.4426\n",
      "Epoch 467/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.9828 - val_loss: 64198.3342\n",
      "Epoch 468/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.1537 - val_loss: 64198.3981\n",
      "Epoch 469/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5594 - val_loss: 64198.2861\n",
      "Epoch 470/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.5647 - val_loss: 64198.3113\n",
      "Epoch 471/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.0460 - val_loss: 64198.0421\n",
      "Epoch 472/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9939 - val_loss: 64198.3312\n",
      "Epoch 473/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4136 - val_loss: 64198.3082\n",
      "Epoch 474/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9399 - val_loss: 64198.5719\n",
      "Epoch 475/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.3197 - val_loss: 64198.3045\n",
      "Epoch 476/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8394 - val_loss: 64198.5088\n",
      "Epoch 477/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59287.1961 - val_loss: 64198.6628\n",
      "Epoch 478/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7433 - val_loss: 64198.2588\n",
      "Epoch 479/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59283.9505 - val_loss: 64198.3868\n",
      "Epoch 480/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.2878 - val_loss: 64198.2155\n",
      "Epoch 481/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9964 - val_loss: 64198.3122\n",
      "Epoch 482/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.2380 - val_loss: 64198.4572\n",
      "Epoch 483/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7038 - val_loss: 64198.3950\n",
      "Epoch 484/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59287.9352 - val_loss: 64198.6213\n",
      "Epoch 485/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.8852 - val_loss: 64198.6112\n",
      "Epoch 486/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.3515 - val_loss: 64198.5174\n",
      "Epoch 487/500\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 59284.4964 - val_loss: 64198.6867\n",
      "Epoch 488/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.6661 - val_loss: 64198.3067\n",
      "Epoch 489/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.0822 - val_loss: 64198.1531\n",
      "Epoch 490/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.1034 - val_loss: 64198.1996\n",
      "Epoch 491/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.7286 - val_loss: 64198.4331\n",
      "Epoch 492/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.4119 - val_loss: 64198.5485\n",
      "Epoch 493/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.6110 - val_loss: 64198.4848\n",
      "Epoch 494/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.3656 - val_loss: 64198.2949\n",
      "Epoch 495/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.7002 - val_loss: 64198.3983\n",
      "Epoch 496/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.9447 - val_loss: 64198.4911\n",
      "Epoch 497/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.0530 - val_loss: 64198.2984\n",
      "Epoch 498/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.1511 - val_loss: 64198.7984\n",
      "Epoch 499/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59285.0970 - val_loss: 64198.3849\n",
      "Epoch 500/500\n",
      "3800/3800 [==============================] - 5s 1ms/step - loss: 59284.2493 - val_loss: 64198.5409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e017860>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=50, dropout = 0.3, return_sequences=True))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=500, batch_size=32, validation_data=(X_trimmed_test, Y_trimmed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_96 (LSTM)               (None, 30, 100)           43600     \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 30, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_98 (LSTM)               (None, 30, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 284,901\n",
      "Trainable params: 284,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3800 samples, validate on 233 samples\n",
      "Epoch 1/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 1550.9811 - val_loss: 1543.9834\n",
      "Epoch 2/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1542.1064 - val_loss: 1537.5791\n",
      "Epoch 3/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1535.8620 - val_loss: 1531.4481\n",
      "Epoch 4/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1529.7874 - val_loss: 1525.4205\n",
      "Epoch 5/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1523.7884 - val_loss: 1519.4463\n",
      "Epoch 6/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1517.8316 - val_loss: 1513.5061\n",
      "Epoch 7/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1511.8940 - val_loss: 1507.5220\n",
      "Epoch 8/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1505.8073 - val_loss: 1501.4057\n",
      "Epoch 9/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1499.7518 - val_loss: 1495.3877\n",
      "Epoch 10/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1493.7513 - val_loss: 1489.4019\n",
      "Epoch 11/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1487.7756 - val_loss: 1483.4357\n",
      "Epoch 12/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1481.8162 - val_loss: 1477.4826\n",
      "Epoch 13/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1475.8682 - val_loss: 1471.5397\n",
      "Epoch 14/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1469.9290 - val_loss: 1465.6041\n",
      "Epoch 15/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1463.9966 - val_loss: 1459.6749\n",
      "Epoch 16/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1458.0704 - val_loss: 1453.7514\n",
      "Epoch 17/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1452.1491 - val_loss: 1447.8322\n",
      "Epoch 18/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1446.2316 - val_loss: 1441.9167\n",
      "Epoch 19/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1440.3181 - val_loss: 1436.0049\n",
      "Epoch 20/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1434.4076 - val_loss: 1430.0958\n",
      "Epoch 21/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1428.4998 - val_loss: 1424.1890\n",
      "Epoch 22/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1422.5944 - val_loss: 1418.2848\n",
      "Epoch 23/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1416.6910 - val_loss: 1412.3825\n",
      "Epoch 24/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1410.7896 - val_loss: 1406.4820\n",
      "Epoch 25/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1404.8899 - val_loss: 1400.5831\n",
      "Epoch 26/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1398.9917 - val_loss: 1394.6861\n",
      "Epoch 27/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1393.0950 - val_loss: 1388.7898\n",
      "Epoch 28/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1387.1995 - val_loss: 1382.8951\n",
      "Epoch 29/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1381.3051 - val_loss: 1377.0010\n",
      "Epoch 30/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1375.4117 - val_loss: 1371.1081\n",
      "Epoch 31/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1369.5194 - val_loss: 1365.2163\n",
      "Epoch 32/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1363.6279 - val_loss: 1359.3252\n",
      "Epoch 33/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1357.7372 - val_loss: 1353.4347\n",
      "Epoch 34/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1351.8472 - val_loss: 1347.5455\n",
      "Epoch 35/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1345.9579 - val_loss: 1341.6563\n",
      "Epoch 36/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1340.0692 - val_loss: 1335.7681\n",
      "Epoch 37/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1334.1813 - val_loss: 1329.8800\n",
      "Epoch 38/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1328.2937 - val_loss: 1323.9929\n",
      "Epoch 39/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1322.4066 - val_loss: 1318.1062\n",
      "Epoch 40/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1316.5200 - val_loss: 1312.2197\n",
      "Epoch 41/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1310.6339 - val_loss: 1306.3340\n",
      "Epoch 42/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1304.7482 - val_loss: 1300.4482\n",
      "Epoch 43/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1298.8628 - val_loss: 1294.5632\n",
      "Epoch 44/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1292.9777 - val_loss: 1288.6783\n",
      "Epoch 45/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1287.0930 - val_loss: 1282.7937\n",
      "Epoch 46/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1281.2085 - val_loss: 1276.9092\n",
      "Epoch 47/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1275.1667 - val_loss: 1270.6788\n",
      "Epoch 48/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1268.9768 - val_loss: 1264.5699\n",
      "Epoch 49/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1262.9010 - val_loss: 1258.5193\n",
      "Epoch 50/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1256.8650 - val_loss: 1252.4958\n",
      "Epoch 51/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1250.8499 - val_loss: 1246.4888\n",
      "Epoch 52/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1244.8483 - val_loss: 1240.4923\n",
      "Epoch 53/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1238.8560 - val_loss: 1234.5040\n",
      "Epoch 54/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1232.8710 - val_loss: 1228.5222\n",
      "Epoch 55/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1226.8917 - val_loss: 1222.5454\n",
      "Epoch 56/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1220.9170 - val_loss: 1216.5728\n",
      "Epoch 57/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1214.9460 - val_loss: 1210.6036\n",
      "Epoch 58/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1208.9784 - val_loss: 1204.6373\n",
      "Epoch 59/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1203.0134 - val_loss: 1198.6735\n",
      "Epoch 60/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1197.0508 - val_loss: 1192.7119\n",
      "Epoch 61/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1191.0902 - val_loss: 1186.7525\n",
      "Epoch 62/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1185.1313 - val_loss: 1180.7941\n",
      "Epoch 63/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1179.1739 - val_loss: 1174.8376\n",
      "Epoch 64/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1173.2180 - val_loss: 1168.8825\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1167.2634 - val_loss: 1162.9286\n",
      "Epoch 66/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1161.3102 - val_loss: 1156.9761\n",
      "Epoch 67/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1155.3583 - val_loss: 1151.0246\n",
      "Epoch 68/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1149.4074 - val_loss: 1145.0743\n",
      "Epoch 69/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1143.4575 - val_loss: 1139.1249\n",
      "Epoch 70/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1137.5084 - val_loss: 1133.1763\n",
      "Epoch 71/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1131.5601 - val_loss: 1127.2282\n",
      "Epoch 72/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1125.6123 - val_loss: 1121.2804\n",
      "Epoch 73/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1119.6651 - val_loss: 1115.3336\n",
      "Epoch 74/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1113.7185 - val_loss: 1109.3874\n",
      "Epoch 75/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1107.7724 - val_loss: 1103.4414\n",
      "Epoch 76/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1101.8267 - val_loss: 1097.4961\n",
      "Epoch 77/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1095.8815 - val_loss: 1091.5509\n",
      "Epoch 78/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1089.9366 - val_loss: 1085.6063\n",
      "Epoch 79/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1083.9921 - val_loss: 1079.6620\n",
      "Epoch 80/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1078.0479 - val_loss: 1073.7179\n",
      "Epoch 81/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1072.1040 - val_loss: 1067.7743\n",
      "Epoch 82/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1066.1604 - val_loss: 1061.8308\n",
      "Epoch 83/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1060.2171 - val_loss: 1055.8875\n",
      "Epoch 84/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1054.2740 - val_loss: 1049.9445\n",
      "Epoch 85/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1048.3311 - val_loss: 1044.0018\n",
      "Epoch 86/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1042.3885 - val_loss: 1038.0593\n",
      "Epoch 87/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1036.4460 - val_loss: 1032.1170\n",
      "Epoch 88/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1030.5037 - val_loss: 1026.1748\n",
      "Epoch 89/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1024.5617 - val_loss: 1020.2325\n",
      "Epoch 90/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 1018.6196 - val_loss: 1014.2909\n",
      "Epoch 91/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1012.6778 - val_loss: 1008.3491\n",
      "Epoch 92/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1006.7361 - val_loss: 1002.4074\n",
      "Epoch 93/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 1000.7946 - val_loss: 996.4659\n",
      "Epoch 94/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 994.8532 - val_loss: 990.5245\n",
      "Epoch 95/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 988.9119 - val_loss: 984.5835\n",
      "Epoch 96/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 982.9707 - val_loss: 978.6423\n",
      "Epoch 97/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 977.0295 - val_loss: 972.7010\n",
      "Epoch 98/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 971.0885 - val_loss: 966.7603\n",
      "Epoch 99/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 965.1476 - val_loss: 960.8192\n",
      "Epoch 100/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 959.2067 - val_loss: 954.8786\n",
      "Epoch 101/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 953.2660 - val_loss: 948.9376\n",
      "Epoch 102/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 947.3253 - val_loss: 942.9970\n",
      "Epoch 103/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 941.3846 - val_loss: 937.0565\n",
      "Epoch 104/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 935.4508 - val_loss: 931.1161\n",
      "Epoch 105/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 929.5036 - val_loss: 925.1755\n",
      "Epoch 106/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 923.5632 - val_loss: 919.2352\n",
      "Epoch 107/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 917.6228 - val_loss: 913.2948\n",
      "Epoch 108/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 911.6824 - val_loss: 907.3543\n",
      "Epoch 109/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 905.7421 - val_loss: 901.4140\n",
      "Epoch 110/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 899.8019 - val_loss: 895.4737\n",
      "Epoch 111/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 893.8616 - val_loss: 889.5337\n",
      "Epoch 112/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 887.9215 - val_loss: 883.5935\n",
      "Epoch 113/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 881.9812 - val_loss: 877.6532\n",
      "Epoch 114/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 876.0412 - val_loss: 871.7131\n",
      "Epoch 115/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 870.1010 - val_loss: 865.7732\n",
      "Epoch 116/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 864.1610 - val_loss: 859.8330\n",
      "Epoch 117/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 858.2209 - val_loss: 853.8931\n",
      "Epoch 118/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 852.2809 - val_loss: 847.9530\n",
      "Epoch 119/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 846.3410 - val_loss: 842.0129\n",
      "Epoch 120/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 840.4010 - val_loss: 836.0731\n",
      "Epoch 121/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 834.4610 - val_loss: 830.1333\n",
      "Epoch 122/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 828.5211 - val_loss: 824.1932\n",
      "Epoch 123/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 822.5812 - val_loss: 818.2535\n",
      "Epoch 124/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 816.6413 - val_loss: 812.3134\n",
      "Epoch 125/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 810.7015 - val_loss: 806.3738\n",
      "Epoch 126/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 804.7617 - val_loss: 800.4338\n",
      "Epoch 127/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 798.8220 - val_loss: 794.4940\n",
      "Epoch 128/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 792.8821 - val_loss: 788.5543\n",
      "Epoch 129/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 786.9423 - val_loss: 782.6145\n",
      "Epoch 130/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 781.0024 - val_loss: 776.6744\n",
      "Epoch 131/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 775.0619 - val_loss: 770.7335\n",
      "Epoch 132/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 769.1207 - val_loss: 764.7919\n",
      "Epoch 133/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 763.1789 - val_loss: 758.8497\n",
      "Epoch 134/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 757.2365 - val_loss: 752.9072\n",
      "Epoch 135/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 751.2940 - val_loss: 746.9648\n",
      "Epoch 136/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 745.3514 - val_loss: 741.0223\n",
      "Epoch 137/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 739.4089 - val_loss: 735.0799\n",
      "Epoch 138/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 733.4664 - val_loss: 729.1373\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 6s 1ms/step - loss: 727.5241 - val_loss: 723.1949\n",
      "Epoch 140/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 721.5815 - val_loss: 717.2524\n",
      "Epoch 141/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 715.6390 - val_loss: 711.3098\n",
      "Epoch 142/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 709.6965 - val_loss: 705.3672\n",
      "Epoch 143/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 703.7540 - val_loss: 699.4248\n",
      "Epoch 144/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 697.8116 - val_loss: 693.4824\n",
      "Epoch 145/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 691.8691 - val_loss: 687.5399\n",
      "Epoch 146/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 685.9266 - val_loss: 681.5975\n",
      "Epoch 147/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 679.9890 - val_loss: 675.6616\n",
      "Epoch 148/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 674.0657 - val_loss: 669.7324\n",
      "Epoch 149/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 668.1548 - val_loss: 663.8054\n",
      "Epoch 150/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 662.2436 - val_loss: 657.8784\n",
      "Epoch 151/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 656.3402 - val_loss: 651.9588\n",
      "Epoch 152/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 650.4410 - val_loss: 646.0322\n",
      "Epoch 153/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 644.5438 - val_loss: 640.1173\n",
      "Epoch 154/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 638.6573 - val_loss: 634.1994\n",
      "Epoch 155/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 632.7726 - val_loss: 628.2773\n",
      "Epoch 156/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 626.8842 - val_loss: 622.3640\n",
      "Epoch 157/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 620.9993 - val_loss: 616.4418\n",
      "Epoch 158/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 615.1191 - val_loss: 610.5613\n",
      "Epoch 159/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 609.2497 - val_loss: 604.7087\n",
      "Epoch 160/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 603.3835 - val_loss: 598.8444\n",
      "Epoch 161/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 597.5210 - val_loss: 592.9889\n",
      "Epoch 162/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 591.6679 - val_loss: 587.1323\n",
      "Epoch 163/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 585.8174 - val_loss: 581.2847\n",
      "Epoch 164/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 579.9829 - val_loss: 575.4365\n",
      "Epoch 165/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 574.1500 - val_loss: 569.5850\n",
      "Epoch 166/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 568.3257 - val_loss: 563.7409\n",
      "Epoch 167/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 562.5128 - val_loss: 557.9030\n",
      "Epoch 168/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 556.7073 - val_loss: 552.0629\n",
      "Epoch 169/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 550.9277 - val_loss: 546.2451\n",
      "Epoch 170/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 545.1680 - val_loss: 540.4706\n",
      "Epoch 171/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 539.4305 - val_loss: 534.7012\n",
      "Epoch 172/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 533.7156 - val_loss: 528.9673\n",
      "Epoch 173/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 528.0274 - val_loss: 523.2986\n",
      "Epoch 174/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 522.3480 - val_loss: 517.7072\n",
      "Epoch 175/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 516.6881 - val_loss: 512.1364\n",
      "Epoch 176/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 511.0447 - val_loss: 506.5605\n",
      "Epoch 177/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 505.4241 - val_loss: 501.0030\n",
      "Epoch 178/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 499.8214 - val_loss: 495.5084\n",
      "Epoch 179/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 494.2313 - val_loss: 490.0587\n",
      "Epoch 180/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 488.6588 - val_loss: 484.6396\n",
      "Epoch 181/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 483.1232 - val_loss: 479.2531\n",
      "Epoch 182/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 477.6217 - val_loss: 473.9165\n",
      "Epoch 183/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 472.1391 - val_loss: 468.6703\n",
      "Epoch 184/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 466.6890 - val_loss: 463.4624\n",
      "Epoch 185/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 461.2820 - val_loss: 458.2564\n",
      "Epoch 186/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 455.9023 - val_loss: 453.0703\n",
      "Epoch 187/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 450.5545 - val_loss: 447.8944\n",
      "Epoch 188/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 445.2322 - val_loss: 442.7342\n",
      "Epoch 189/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 439.9213 - val_loss: 437.5785\n",
      "Epoch 190/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 434.6436 - val_loss: 432.4809\n",
      "Epoch 191/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 429.3890 - val_loss: 427.3714\n",
      "Epoch 192/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 424.1804 - val_loss: 422.2803\n",
      "Epoch 193/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 419.0233 - val_loss: 417.2118\n",
      "Epoch 194/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 413.9073 - val_loss: 412.1995\n",
      "Epoch 195/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 408.8653 - val_loss: 407.2502\n",
      "Epoch 196/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 403.8850 - val_loss: 402.3501\n",
      "Epoch 197/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 398.9635 - val_loss: 397.5102\n",
      "Epoch 198/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 394.0911 - val_loss: 392.7404\n",
      "Epoch 199/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 389.2153 - val_loss: 388.0251\n",
      "Epoch 200/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 384.4418 - val_loss: 383.3009\n",
      "Epoch 201/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 379.6992 - val_loss: 378.6808\n",
      "Epoch 202/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 375.0018 - val_loss: 374.1161\n",
      "Epoch 203/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 370.3834 - val_loss: 369.5786\n",
      "Epoch 204/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 365.8248 - val_loss: 365.1800\n",
      "Epoch 205/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 361.3171 - val_loss: 360.9055\n",
      "Epoch 206/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 356.8638 - val_loss: 356.6776\n",
      "Epoch 207/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 352.4554 - val_loss: 352.4996\n",
      "Epoch 208/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 348.1111 - val_loss: 348.3705\n",
      "Epoch 209/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 343.8575 - val_loss: 344.2376\n",
      "Epoch 210/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 339.6175 - val_loss: 340.1661\n",
      "Epoch 211/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 335.4151 - val_loss: 336.1369\n",
      "Epoch 212/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 331.2433 - val_loss: 332.2492\n",
      "Epoch 213/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 6s 1ms/step - loss: 327.1433 - val_loss: 328.3437\n",
      "Epoch 214/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 323.1182 - val_loss: 324.5309\n",
      "Epoch 215/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 319.1459 - val_loss: 320.8397\n",
      "Epoch 216/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 315.2054 - val_loss: 317.2091\n",
      "Epoch 217/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 311.2997 - val_loss: 313.6197\n",
      "Epoch 218/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 307.4293 - val_loss: 310.1096\n",
      "Epoch 219/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 303.6221 - val_loss: 306.6269\n",
      "Epoch 220/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 299.8787 - val_loss: 303.1278\n",
      "Epoch 221/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 296.2018 - val_loss: 299.6973\n",
      "Epoch 222/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 292.6191 - val_loss: 296.3077\n",
      "Epoch 223/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 289.0987 - val_loss: 293.0037\n",
      "Epoch 224/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 285.6497 - val_loss: 289.7995\n",
      "Epoch 225/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 282.2946 - val_loss: 286.7285\n",
      "Epoch 226/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 279.0211 - val_loss: 283.6831\n",
      "Epoch 227/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 275.8045 - val_loss: 280.6553\n",
      "Epoch 228/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 272.6449 - val_loss: 277.6799\n",
      "Epoch 229/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 269.6004 - val_loss: 274.7590\n",
      "Epoch 230/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 266.6383 - val_loss: 271.9092\n",
      "Epoch 231/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 263.7788 - val_loss: 269.1347\n",
      "Epoch 232/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 260.9884 - val_loss: 266.4344\n",
      "Epoch 233/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 258.2285 - val_loss: 263.8948\n",
      "Epoch 234/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 255.5266 - val_loss: 261.3735\n",
      "Epoch 235/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 252.8497 - val_loss: 258.9142\n",
      "Epoch 236/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 250.2525 - val_loss: 256.5516\n",
      "Epoch 237/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 247.7740 - val_loss: 254.2938\n",
      "Epoch 238/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 245.4255 - val_loss: 252.1005\n",
      "Epoch 239/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 243.1687 - val_loss: 250.0128\n",
      "Epoch 240/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 240.9756 - val_loss: 247.9156\n",
      "Epoch 241/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 238.8339 - val_loss: 245.8568\n",
      "Epoch 242/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 236.7509 - val_loss: 243.9825\n",
      "Epoch 243/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 234.7447 - val_loss: 242.1200\n",
      "Epoch 244/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 232.7937 - val_loss: 240.3593\n",
      "Epoch 245/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 230.9494 - val_loss: 238.6254\n",
      "Epoch 246/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 229.1614 - val_loss: 237.0526\n",
      "Epoch 247/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 227.4065 - val_loss: 235.6082\n",
      "Epoch 248/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 225.7407 - val_loss: 234.2202\n",
      "Epoch 249/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 224.1340 - val_loss: 232.8976\n",
      "Epoch 250/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 222.5857 - val_loss: 231.6022\n",
      "Epoch 251/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 221.0687 - val_loss: 230.3285\n",
      "Epoch 252/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 219.6141 - val_loss: 229.1782\n",
      "Epoch 253/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 218.1819 - val_loss: 228.0445\n",
      "Epoch 254/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 216.7979 - val_loss: 226.9048\n",
      "Epoch 255/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 215.4732 - val_loss: 225.7638\n",
      "Epoch 256/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 214.2004 - val_loss: 224.7401\n",
      "Epoch 257/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 212.9590 - val_loss: 223.7891\n",
      "Epoch 258/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 211.7695 - val_loss: 222.8223\n",
      "Epoch 259/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 210.6407 - val_loss: 221.9929\n",
      "Epoch 260/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 209.5763 - val_loss: 221.1444\n",
      "Epoch 261/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 208.5397 - val_loss: 220.3571\n",
      "Epoch 262/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 207.5721 - val_loss: 219.6259\n",
      "Epoch 263/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 206.6427 - val_loss: 218.9201\n",
      "Epoch 264/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 205.7856 - val_loss: 218.2639\n",
      "Epoch 265/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 204.9796 - val_loss: 217.6396\n",
      "Epoch 266/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 204.1965 - val_loss: 217.0788\n",
      "Epoch 267/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 203.4646 - val_loss: 216.5174\n",
      "Epoch 268/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 202.7983 - val_loss: 216.0122\n",
      "Epoch 269/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 202.2059 - val_loss: 215.5834\n",
      "Epoch 270/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 201.7140 - val_loss: 215.1995\n",
      "Epoch 271/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 201.2511 - val_loss: 214.8640\n",
      "Epoch 272/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 200.8230 - val_loss: 214.5293\n",
      "Epoch 273/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 200.4230 - val_loss: 214.2331\n",
      "Epoch 274/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 200.0402 - val_loss: 213.9499\n",
      "Epoch 275/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 199.6728 - val_loss: 213.6785\n",
      "Epoch 276/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 199.3258 - val_loss: 213.4166\n",
      "Epoch 277/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 198.9949 - val_loss: 213.1830\n",
      "Epoch 278/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 198.6777 - val_loss: 212.9744\n",
      "Epoch 279/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 198.3744 - val_loss: 212.7401\n",
      "Epoch 280/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 198.1064 - val_loss: 212.5192\n",
      "Epoch 281/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 197.8708 - val_loss: 212.3408\n",
      "Epoch 282/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 197.6653 - val_loss: 212.1685\n",
      "Epoch 283/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 197.4791 - val_loss: 212.0014\n",
      "Epoch 284/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 197.3071 - val_loss: 211.8509\n",
      "Epoch 285/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 197.1529 - val_loss: 211.7310\n",
      "Epoch 286/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 197.0146 - val_loss: 211.6193\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.9032 - val_loss: 211.5362\n",
      "Epoch 288/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.7971 - val_loss: 211.4984\n",
      "Epoch 289/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.7136 - val_loss: 211.4573\n",
      "Epoch 290/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.6395 - val_loss: 211.4163\n",
      "Epoch 291/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.5712 - val_loss: 211.3832\n",
      "Epoch 292/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.5142 - val_loss: 211.3497\n",
      "Epoch 293/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.4611 - val_loss: 211.3181\n",
      "Epoch 294/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.4098 - val_loss: 211.2782\n",
      "Epoch 295/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.3607 - val_loss: 211.2532\n",
      "Epoch 296/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.3225 - val_loss: 211.2280\n",
      "Epoch 297/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.2878 - val_loss: 211.2139\n",
      "Epoch 298/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.2600 - val_loss: 211.1909\n",
      "Epoch 299/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.2262 - val_loss: 211.1749\n",
      "Epoch 300/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 196.2026 - val_loss: 211.1639\n",
      "Epoch 301/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 196.1860 - val_loss: 211.1546\n",
      "Epoch 302/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 196.1730 - val_loss: 211.1483\n",
      "Epoch 303/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 196.1661 - val_loss: 211.1410\n",
      "Epoch 304/1000\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 196.1597 - val_loss: 211.1347\n",
      "Epoch 305/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1546 - val_loss: 211.1314\n",
      "Epoch 306/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1478 - val_loss: 211.1284\n",
      "Epoch 307/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1455 - val_loss: 211.1219\n",
      "Epoch 308/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1422 - val_loss: 211.1189\n",
      "Epoch 309/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1416 - val_loss: 211.1144\n",
      "Epoch 310/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1382 - val_loss: 211.1137\n",
      "Epoch 311/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1365 - val_loss: 211.1130\n",
      "Epoch 312/1000\n",
      "3800/3800 [==============================] - 6s 2ms/step - loss: 196.1411 - val_loss: 211.1068\n",
      "Epoch 313/1000\n",
      "1792/3800 [=============>................] - ETA: 3s - loss: 194.3997"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-336-11320f9de0e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trimmed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trimmed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trimmed_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trimmed_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=1000, batch_size=64, validation_data=(X_trimmed_test, Y_trimmed_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 233 samples\n",
      "Epoch 1/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 881.9229 - val_loss: 877.5643\n",
      "Epoch 2/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 875.9233 - val_loss: 871.5650\n",
      "Epoch 3/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 869.9237 - val_loss: 865.5653\n",
      "Epoch 4/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 863.9242 - val_loss: 859.5655\n",
      "Epoch 5/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 857.9246 - val_loss: 853.5661\n",
      "Epoch 6/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 851.9249 - val_loss: 847.5664\n",
      "Epoch 7/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 845.9253 - val_loss: 841.5670\n",
      "Epoch 8/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 839.9257 - val_loss: 835.5672\n",
      "Epoch 9/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 833.9261 - val_loss: 829.5675\n",
      "Epoch 10/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 827.9265 - val_loss: 823.5681\n",
      "Epoch 11/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 821.9270 - val_loss: 817.5685\n",
      "Epoch 12/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 815.9274 - val_loss: 811.5689\n",
      "Epoch 13/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 809.9280 - val_loss: 805.5692\n",
      "Epoch 14/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 803.9282 - val_loss: 799.5698\n",
      "Epoch 15/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 797.9286 - val_loss: 793.5702\n",
      "Epoch 16/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 791.9290 - val_loss: 787.5704\n",
      "Epoch 17/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 785.9294 - val_loss: 781.5709\n",
      "Epoch 18/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 779.9298 - val_loss: 775.5712\n",
      "Epoch 19/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 773.9302 - val_loss: 769.5714\n",
      "Epoch 20/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 767.9303 - val_loss: 763.5711\n",
      "Epoch 21/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 761.9296 - val_loss: 757.5702\n",
      "Epoch 22/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 755.9282 - val_loss: 751.5683\n",
      "Epoch 23/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 749.9259 - val_loss: 745.5661\n",
      "Epoch 24/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 743.9235 - val_loss: 739.5636\n",
      "Epoch 25/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 737.9211 - val_loss: 733.5612\n",
      "Epoch 26/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 731.9187 - val_loss: 727.5588\n",
      "Epoch 27/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 725.9162 - val_loss: 721.5564\n",
      "Epoch 28/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 719.9138 - val_loss: 715.5538\n",
      "Epoch 29/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 713.9114 - val_loss: 709.5515\n",
      "Epoch 30/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 707.9090 - val_loss: 703.5491\n",
      "Epoch 31/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 701.9066 - val_loss: 697.5467\n",
      "Epoch 32/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 695.9041 - val_loss: 691.5442\n",
      "Epoch 33/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 689.9017 - val_loss: 685.5418\n",
      "Epoch 34/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 683.8993 - val_loss: 679.5393\n",
      "Epoch 35/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 677.9045 - val_loss: 673.5442\n",
      "Epoch 36/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 671.9268 - val_loss: 667.5598\n",
      "Epoch 37/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 665.9572 - val_loss: 661.5737\n",
      "Epoch 38/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 659.9917 - val_loss: 655.5897\n",
      "Epoch 39/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 654.0318 - val_loss: 649.6085\n",
      "Epoch 40/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 648.0718 - val_loss: 643.6242\n",
      "Epoch 41/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 642.1200 - val_loss: 637.6483\n",
      "Epoch 42/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 636.1756 - val_loss: 631.6735\n",
      "Epoch 43/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 630.2301 - val_loss: 625.6981\n",
      "Epoch 44/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 624.2844 - val_loss: 619.7161\n",
      "Epoch 45/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 618.3365 - val_loss: 613.7439\n",
      "Epoch 46/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 612.4045 - val_loss: 607.8240\n",
      "Epoch 47/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 606.4817 - val_loss: 601.9111\n",
      "Epoch 48/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 600.5566 - val_loss: 595.9939\n",
      "Epoch 49/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 594.6405 - val_loss: 590.0780\n",
      "Epoch 50/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 588.7297 - val_loss: 584.1588\n",
      "Epoch 51/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 582.8273 - val_loss: 578.2585\n",
      "Epoch 52/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 576.9363 - val_loss: 572.3484\n",
      "Epoch 53/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 571.0469 - val_loss: 566.4409\n",
      "Epoch 54/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 565.1774 - val_loss: 560.5530\n",
      "Epoch 55/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 559.3118 - val_loss: 554.6524\n",
      "Epoch 56/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 553.4545 - val_loss: 548.7605\n",
      "Epoch 57/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 547.6290 - val_loss: 542.9030\n",
      "Epoch 58/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 541.8285 - val_loss: 537.0858\n",
      "Epoch 59/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 536.0529 - val_loss: 531.2827\n",
      "Epoch 60/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 530.3100 - val_loss: 525.5214\n",
      "Epoch 61/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 524.5687 - val_loss: 519.8651\n",
      "Epoch 62/1000\n",
      "3800/3800 [==============================] - 11s 3ms/step - loss: 518.8443 - val_loss: 514.2337\n",
      "Epoch 63/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 513.1361 - val_loss: 508.5875\n",
      "Epoch 64/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 507.4413 - val_loss: 502.9681\n",
      "Epoch 65/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 501.7744 - val_loss: 497.3875\n",
      "Epoch 66/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 496.1250 - val_loss: 491.8673\n",
      "Epoch 67/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 490.4890 - val_loss: 486.3923\n",
      "Epoch 68/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 484.8905 - val_loss: 480.9475\n",
      "Epoch 69/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 479.3176 - val_loss: 475.5225\n",
      "Epoch 70/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 473.7674 - val_loss: 470.1865\n",
      "Epoch 71/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 468.2636 - val_loss: 464.9281\n",
      "Epoch 72/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 462.7893 - val_loss: 459.6864\n",
      "Epoch 73/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 457.3458 - val_loss: 454.4499\n",
      "Epoch 74/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 451.9284 - val_loss: 449.2053\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 12s 3ms/step - loss: 446.5401 - val_loss: 443.9794\n",
      "Epoch 76/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 441.1737 - val_loss: 438.7720\n",
      "Epoch 77/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 435.8422 - val_loss: 433.6100\n",
      "Epoch 78/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 430.5321 - val_loss: 428.4544\n",
      "Epoch 79/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 425.2668 - val_loss: 423.3075\n",
      "Epoch 80/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 420.0549 - val_loss: 418.2064\n",
      "Epoch 81/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 414.8791 - val_loss: 413.1157\n",
      "Epoch 82/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 409.7672 - val_loss: 408.1271\n",
      "Epoch 83/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 404.7249 - val_loss: 403.1529\n",
      "Epoch 84/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 399.7133 - val_loss: 398.2473\n",
      "Epoch 85/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 394.7559 - val_loss: 393.4047\n",
      "Epoch 86/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 389.8633 - val_loss: 388.6318\n",
      "Epoch 87/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 385.0356 - val_loss: 383.8741\n",
      "Epoch 88/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 380.2435 - val_loss: 379.2187\n",
      "Epoch 89/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 380.7337 - val_loss: 374.5593\n",
      "Epoch 90/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 370.8239 - val_loss: 369.9896\n",
      "Epoch 91/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 366.2210 - val_loss: 365.5259\n",
      "Epoch 92/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 361.6708 - val_loss: 361.2106\n",
      "Epoch 93/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 357.1863 - val_loss: 356.9706\n",
      "Epoch 94/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 352.7338 - val_loss: 352.7416\n",
      "Epoch 95/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 348.3504 - val_loss: 348.5765\n",
      "Epoch 96/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 344.0387 - val_loss: 344.3996\n",
      "Epoch 97/1000\n",
      "3800/3800 [==============================] - 1815s 478ms/step - loss: 339.7650 - val_loss: 340.2900\n",
      "Epoch 98/1000\n",
      "3800/3800 [==============================] - 14s 4ms/step - loss: 335.5105 - val_loss: 336.2301\n",
      "Epoch 99/1000\n",
      "3800/3800 [==============================] - 17s 4ms/step - loss: 331.3022 - val_loss: 332.2599\n",
      "Epoch 100/1000\n",
      "3800/3800 [==============================] - 1808s 476ms/step - loss: 327.1667 - val_loss: 328.3566\n",
      "Epoch 101/1000\n",
      "3800/3800 [==============================] - 15s 4ms/step - loss: 323.1014 - val_loss: 324.4886\n",
      "Epoch 102/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 319.0609 - val_loss: 320.7676\n",
      "Epoch 103/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 315.0852 - val_loss: 317.0639\n",
      "Epoch 104/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 311.1336 - val_loss: 313.4626\n",
      "Epoch 105/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 307.2329 - val_loss: 309.9186\n",
      "Epoch 106/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 303.3960 - val_loss: 306.4007\n",
      "Epoch 107/1000\n",
      "3800/3800 [==============================] - 13s 4ms/step - loss: 299.6261 - val_loss: 302.9021\n",
      "Epoch 108/1000\n",
      "3800/3800 [==============================] - 14s 4ms/step - loss: 295.9300 - val_loss: 299.3956\n",
      "Epoch 109/1000\n",
      "3800/3800 [==============================] - 14s 4ms/step - loss: 292.2967 - val_loss: 295.9599\n",
      "Epoch 110/1000\n",
      "3800/3800 [==============================] - 13s 4ms/step - loss: 288.7379 - val_loss: 292.6909\n",
      "Epoch 111/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 285.2736 - val_loss: 289.4443\n",
      "Epoch 112/1000\n",
      "3800/3800 [==============================] - 14s 4ms/step - loss: 281.8939 - val_loss: 286.3491\n",
      "Epoch 113/1000\n",
      "3800/3800 [==============================] - 14s 4ms/step - loss: 278.6099 - val_loss: 283.2700\n",
      "Epoch 114/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 275.3612 - val_loss: 280.2433\n",
      "Epoch 115/1000\n",
      "3800/3800 [==============================] - 13s 4ms/step - loss: 272.2040 - val_loss: 277.2520\n",
      "Epoch 116/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 269.1321 - val_loss: 274.2960\n",
      "Epoch 117/1000\n",
      "3800/3800 [==============================] - 13s 4ms/step - loss: 266.1644 - val_loss: 271.4452\n",
      "Epoch 118/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 263.2942 - val_loss: 268.6134\n",
      "Epoch 119/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 260.4835 - val_loss: 265.9419\n",
      "Epoch 120/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 257.7098 - val_loss: 263.3863\n",
      "Epoch 121/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 254.9850 - val_loss: 260.8713\n",
      "Epoch 122/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 252.3019 - val_loss: 258.3958\n",
      "Epoch 123/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 249.7105 - val_loss: 256.0541\n",
      "Epoch 124/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 247.2510 - val_loss: 253.7843\n",
      "Epoch 125/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 244.8998 - val_loss: 251.6326\n",
      "Epoch 126/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 242.6501 - val_loss: 249.5089\n",
      "Epoch 127/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 240.4633 - val_loss: 247.4030\n",
      "Epoch 128/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 238.3007 - val_loss: 245.3752\n",
      "Epoch 129/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 236.2353 - val_loss: 243.4745\n",
      "Epoch 130/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 234.2292 - val_loss: 241.6600\n",
      "Epoch 131/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 232.3009 - val_loss: 239.8760\n",
      "Epoch 132/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 230.4444 - val_loss: 238.1567\n",
      "Epoch 133/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 228.6343 - val_loss: 236.6013\n",
      "Epoch 134/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 226.8942 - val_loss: 235.1764\n",
      "Epoch 135/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 225.2352 - val_loss: 233.7693\n",
      "Epoch 136/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 223.6455 - val_loss: 232.4879\n",
      "Epoch 137/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 222.0957 - val_loss: 231.2017\n",
      "Epoch 138/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 220.5892 - val_loss: 229.9458\n",
      "Epoch 139/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 219.1283 - val_loss: 228.7845\n",
      "Epoch 140/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 217.7062 - val_loss: 227.6301\n",
      "Epoch 141/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 216.3239 - val_loss: 226.5061\n",
      "Epoch 142/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 215.0101 - val_loss: 225.3996\n",
      "Epoch 143/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 213.7429 - val_loss: 224.3743\n",
      "Epoch 144/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 212.5050 - val_loss: 223.4010\n",
      "Epoch 145/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 211.3223 - val_loss: 222.5028\n",
      "Epoch 146/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 210.2184 - val_loss: 221.6538\n",
      "Epoch 147/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 209.1643 - val_loss: 220.8278\n",
      "Epoch 148/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 208.1512 - val_loss: 220.0602\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800/3800 [==============================] - 12s 3ms/step - loss: 207.1901 - val_loss: 219.3263\n",
      "Epoch 150/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 206.2829 - val_loss: 218.6191\n",
      "Epoch 151/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 205.4377 - val_loss: 218.0028\n",
      "Epoch 152/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 204.6391 - val_loss: 217.4085\n",
      "Epoch 153/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 203.8906 - val_loss: 216.8070\n",
      "Epoch 154/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 203.1676 - val_loss: 216.2848\n",
      "Epoch 155/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 202.5448 - val_loss: 215.8228\n",
      "Epoch 156/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 202.0071 - val_loss: 215.4185\n",
      "Epoch 157/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 201.5412 - val_loss: 215.0761\n",
      "Epoch 158/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 201.1015 - val_loss: 214.7463\n",
      "Epoch 159/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 200.6782 - val_loss: 214.4274\n",
      "Epoch 160/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 200.2753 - val_loss: 214.1319\n",
      "Epoch 161/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 199.8933 - val_loss: 213.8422\n",
      "Epoch 162/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 199.5342 - val_loss: 213.5767\n",
      "Epoch 163/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 199.1929 - val_loss: 213.3212\n",
      "Epoch 164/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 198.8613 - val_loss: 213.1018\n",
      "Epoch 165/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 198.5602 - val_loss: 212.8693\n",
      "Epoch 166/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 198.2731 - val_loss: 212.6558\n",
      "Epoch 167/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 198.0191 - val_loss: 212.4610\n",
      "Epoch 168/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.8035 - val_loss: 212.2762\n",
      "Epoch 169/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.6042 - val_loss: 212.0932\n",
      "Epoch 170/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.4127 - val_loss: 211.9383\n",
      "Epoch 171/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.2549 - val_loss: 211.8043\n",
      "Epoch 172/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.1125 - val_loss: 211.6807\n",
      "Epoch 173/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.9757 - val_loss: 211.5906\n",
      "Epoch 174/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.8685 - val_loss: 211.5266\n",
      "Epoch 175/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.7731 - val_loss: 211.4846\n",
      "Epoch 176/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.6941 - val_loss: 211.4484\n",
      "Epoch 177/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.6188 - val_loss: 211.4089\n",
      "Epoch 178/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.5528 - val_loss: 211.3675\n",
      "Epoch 179/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.4969 - val_loss: 211.3448\n",
      "Epoch 180/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.4415 - val_loss: 211.3047\n",
      "Epoch 181/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3941 - val_loss: 211.2751\n",
      "Epoch 182/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3526 - val_loss: 211.2432\n",
      "Epoch 183/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3147 - val_loss: 211.2320\n",
      "Epoch 184/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2767 - val_loss: 211.2036\n",
      "Epoch 185/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2432 - val_loss: 211.1878\n",
      "Epoch 186/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2174 - val_loss: 211.1657\n",
      "Epoch 187/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1965 - val_loss: 211.1610\n",
      "Epoch 188/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1795 - val_loss: 211.1510\n",
      "Epoch 189/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1715 - val_loss: 211.1451\n",
      "Epoch 190/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1633 - val_loss: 211.1406\n",
      "Epoch 191/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1594 - val_loss: 211.1364\n",
      "Epoch 192/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1516 - val_loss: 211.1284\n",
      "Epoch 193/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1463 - val_loss: 211.1239\n",
      "Epoch 194/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1454 - val_loss: 211.1240\n",
      "Epoch 195/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1412 - val_loss: 211.1175\n",
      "Epoch 196/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1385 - val_loss: 211.1144\n",
      "Epoch 197/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1386 - val_loss: 211.1112\n",
      "Epoch 198/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1394 - val_loss: 211.1090\n",
      "Epoch 199/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1332 - val_loss: 211.1026\n",
      "Epoch 200/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.1027\n",
      "Epoch 201/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1123 - val_loss: 211.1006\n",
      "Epoch 202/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.7264 - val_loss: 212.3771\n",
      "Epoch 203/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.6344 - val_loss: 212.0295\n",
      "Epoch 204/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.2609 - val_loss: 211.7747\n",
      "Epoch 205/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.6046 - val_loss: 211.1298\n",
      "Epoch 206/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2963 - val_loss: 211.0919\n",
      "Epoch 207/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.0910 - val_loss: 211.0957\n",
      "Epoch 208/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1467 - val_loss: 211.1115\n",
      "Epoch 209/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1796 - val_loss: 211.1004\n",
      "Epoch 210/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1244 - val_loss: 211.1253\n",
      "Epoch 211/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1221 - val_loss: 211.1245\n",
      "Epoch 212/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1534 - val_loss: 211.1091\n",
      "Epoch 213/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1026 - val_loss: 211.1166\n",
      "Epoch 214/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1451 - val_loss: 211.1215\n",
      "Epoch 215/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1848 - val_loss: 211.1020\n",
      "Epoch 216/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1499 - val_loss: 211.1008\n",
      "Epoch 217/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1191 - val_loss: 211.1056\n",
      "Epoch 218/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3859 - val_loss: 211.1311\n",
      "Epoch 219/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1856 - val_loss: 211.1067\n",
      "Epoch 220/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1133 - val_loss: 211.1042\n",
      "Epoch 221/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1072 - val_loss: 211.1159\n",
      "Epoch 222/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 198.0749 - val_loss: 211.1900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3680 - val_loss: 211.1167\n",
      "Epoch 224/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1613 - val_loss: 211.1047\n",
      "Epoch 225/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.0816 - val_loss: 211.1012\n",
      "Epoch 226/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1543 - val_loss: 211.0998\n",
      "Epoch 227/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.6882 - val_loss: 211.1005\n",
      "Epoch 228/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1495 - val_loss: 211.1060\n",
      "Epoch 229/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1241 - val_loss: 211.1011\n",
      "Epoch 230/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1853 - val_loss: 211.0967\n",
      "Epoch 231/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1356 - val_loss: 211.0936\n",
      "Epoch 232/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1622 - val_loss: 211.0951\n",
      "Epoch 233/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0965\n",
      "Epoch 234/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1354 - val_loss: 211.1030\n",
      "Epoch 235/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1356 - val_loss: 211.1006\n",
      "Epoch 236/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0965\n",
      "Epoch 237/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1256 - val_loss: 211.0916\n",
      "Epoch 238/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1430 - val_loss: 211.0974\n",
      "Epoch 239/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1340 - val_loss: 211.0911\n",
      "Epoch 240/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1186 - val_loss: 211.0868\n",
      "Epoch 241/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1549 - val_loss: 211.0887\n",
      "Epoch 242/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.0885 - val_loss: 211.0926\n",
      "Epoch 243/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1261 - val_loss: 211.1014\n",
      "Epoch 244/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1442 - val_loss: 211.0970\n",
      "Epoch 245/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1111 - val_loss: 211.0935\n",
      "Epoch 246/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1693 - val_loss: 211.0870\n",
      "Epoch 247/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0835\n",
      "Epoch 248/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0919\n",
      "Epoch 249/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1645 - val_loss: 211.0949\n",
      "Epoch 250/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1551 - val_loss: 211.0953\n",
      "Epoch 251/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1332 - val_loss: 211.0940\n",
      "Epoch 252/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0958\n",
      "Epoch 253/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1346 - val_loss: 211.1038\n",
      "Epoch 254/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1459 - val_loss: 211.1038\n",
      "Epoch 255/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1200 - val_loss: 211.0998\n",
      "Epoch 256/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.0988 - val_loss: 211.0936\n",
      "Epoch 257/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1004 - val_loss: 211.0964\n",
      "Epoch 258/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1546 - val_loss: 211.1004\n",
      "Epoch 259/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1420 - val_loss: 211.1001\n",
      "Epoch 260/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1599 - val_loss: 211.0993\n",
      "Epoch 261/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1587 - val_loss: 211.0975\n",
      "Epoch 262/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1352 - val_loss: 211.0972\n",
      "Epoch 263/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1180 - val_loss: 211.0894\n",
      "Epoch 264/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1819 - val_loss: 211.0941\n",
      "Epoch 265/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1470 - val_loss: 211.0979\n",
      "Epoch 266/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1273 - val_loss: 211.0990\n",
      "Epoch 267/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1112 - val_loss: 211.0916\n",
      "Epoch 268/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1998 - val_loss: 211.0990\n",
      "Epoch 269/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1469 - val_loss: 211.0972\n",
      "Epoch 270/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1475 - val_loss: 211.0924\n",
      "Epoch 271/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1430 - val_loss: 211.0915\n",
      "Epoch 272/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1055 - val_loss: 211.0883\n",
      "Epoch 273/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1108 - val_loss: 211.0839\n",
      "Epoch 274/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1099 - val_loss: 211.0629\n",
      "Epoch 275/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1948 - val_loss: 211.0529\n",
      "Epoch 276/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1739 - val_loss: 211.0516\n",
      "Epoch 277/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1454 - val_loss: 211.0535\n",
      "Epoch 278/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1589 - val_loss: 211.0629\n",
      "Epoch 279/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.0957 - val_loss: 211.0688\n",
      "Epoch 280/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1338 - val_loss: 211.0696\n",
      "Epoch 281/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1690 - val_loss: 211.0737\n",
      "Epoch 282/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1088 - val_loss: 211.0716\n",
      "Epoch 283/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1355 - val_loss: 211.0783\n",
      "Epoch 284/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1207 - val_loss: 211.0836\n",
      "Epoch 285/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1102 - val_loss: 211.0754\n",
      "Epoch 286/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1843 - val_loss: 211.0774\n",
      "Epoch 287/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0810\n",
      "Epoch 288/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2041 - val_loss: 211.0837\n",
      "Epoch 289/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1438 - val_loss: 211.0794\n",
      "Epoch 290/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1608 - val_loss: 211.0844\n",
      "Epoch 291/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1470 - val_loss: 211.1027\n",
      "Epoch 292/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2808 - val_loss: 211.0979\n",
      "Epoch 293/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0981\n",
      "Epoch 294/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0987\n",
      "Epoch 295/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0965\n",
      "Epoch 296/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.0043 - val_loss: 211.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1345 - val_loss: 211.0976\n",
      "Epoch 298/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2024 - val_loss: 211.0980\n",
      "Epoch 299/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1153 - val_loss: 212.4144\n",
      "Epoch 300/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.6618 - val_loss: 212.0407\n",
      "Epoch 301/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 197.2376 - val_loss: 211.6987\n",
      "Epoch 302/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.9215 - val_loss: 211.5264\n",
      "Epoch 303/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.7157 - val_loss: 211.4369\n",
      "Epoch 304/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.5686 - val_loss: 211.3614\n",
      "Epoch 305/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.4679 - val_loss: 211.3032\n",
      "Epoch 306/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3786 - val_loss: 211.2464\n",
      "Epoch 307/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3103 - val_loss: 211.2079\n",
      "Epoch 308/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2513 - val_loss: 211.1873\n",
      "Epoch 309/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2093 - val_loss: 211.1598\n",
      "Epoch 310/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1785 - val_loss: 211.1489\n",
      "Epoch 311/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1672 - val_loss: 211.1378\n",
      "Epoch 312/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1553 - val_loss: 211.1287\n",
      "Epoch 313/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1466 - val_loss: 211.1222\n",
      "Epoch 314/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1521 - val_loss: 211.1122\n",
      "Epoch 315/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1395 - val_loss: 211.1143\n",
      "Epoch 316/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1382 - val_loss: 211.1040\n",
      "Epoch 317/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1363 - val_loss: 211.1029\n",
      "Epoch 318/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1361 - val_loss: 211.1010\n",
      "Epoch 319/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1349 - val_loss: 211.1013\n",
      "Epoch 320/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1321 - val_loss: 211.1003\n",
      "Epoch 321/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1320 - val_loss: 211.0991\n",
      "Epoch 322/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1349 - val_loss: 211.0989\n",
      "Epoch 323/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1313 - val_loss: 211.0991\n",
      "Epoch 324/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1301 - val_loss: 211.0980\n",
      "Epoch 325/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1330 - val_loss: 211.0988\n",
      "Epoch 326/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0975\n",
      "Epoch 327/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0980\n",
      "Epoch 328/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1277 - val_loss: 211.0963\n",
      "Epoch 329/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0967\n",
      "Epoch 330/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0966\n",
      "Epoch 331/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0978\n",
      "Epoch 332/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0970\n",
      "Epoch 333/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1325 - val_loss: 211.0983\n",
      "Epoch 334/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0961\n",
      "Epoch 335/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0951\n",
      "Epoch 336/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1319 - val_loss: 211.0957\n",
      "Epoch 337/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0959\n",
      "Epoch 338/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0960\n",
      "Epoch 339/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0968\n",
      "Epoch 340/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1309 - val_loss: 211.0968\n",
      "Epoch 341/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1352 - val_loss: 211.0965\n",
      "Epoch 342/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1389 - val_loss: 211.0943\n",
      "Epoch 343/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0944\n",
      "Epoch 344/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0953\n",
      "Epoch 345/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0961\n",
      "Epoch 346/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1369 - val_loss: 211.0945\n",
      "Epoch 347/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1337 - val_loss: 211.0955\n",
      "Epoch 348/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1316 - val_loss: 211.0971\n",
      "Epoch 349/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1304 - val_loss: 211.0958\n",
      "Epoch 350/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0958\n",
      "Epoch 351/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1320 - val_loss: 211.0972\n",
      "Epoch 352/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1331 - val_loss: 211.0958\n",
      "Epoch 353/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0962\n",
      "Epoch 354/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1290 - val_loss: 211.0959\n",
      "Epoch 355/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1355 - val_loss: 211.0930\n",
      "Epoch 356/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 196.1305 - val_loss: 211.0950\n",
      "Epoch 357/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0949\n",
      "Epoch 358/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0954\n",
      "Epoch 359/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1327 - val_loss: 211.0944\n",
      "Epoch 360/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0955\n",
      "Epoch 361/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1283 - val_loss: 211.0946\n",
      "Epoch 362/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0954\n",
      "Epoch 363/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1277 - val_loss: 211.0950\n",
      "Epoch 364/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1324 - val_loss: 211.0929\n",
      "Epoch 365/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1257 - val_loss: 211.0951\n",
      "Epoch 366/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0948\n",
      "Epoch 367/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0943\n",
      "Epoch 368/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0945\n",
      "Epoch 369/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0953\n",
      "Epoch 370/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1274 - val_loss: 211.0949\n",
      "Epoch 372/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1352 - val_loss: 211.0956\n",
      "Epoch 373/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1367 - val_loss: 211.0965\n",
      "Epoch 374/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0956\n",
      "Epoch 375/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1325 - val_loss: 211.0942\n",
      "Epoch 376/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1343 - val_loss: 211.0951\n",
      "Epoch 377/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1297 - val_loss: 211.0959\n",
      "Epoch 378/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1261 - val_loss: 211.0943\n",
      "Epoch 379/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0935\n",
      "Epoch 380/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0940\n",
      "Epoch 381/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0940\n",
      "Epoch 382/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1333 - val_loss: 211.0951\n",
      "Epoch 383/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0945\n",
      "Epoch 384/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0933\n",
      "Epoch 385/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1360 - val_loss: 211.0931\n",
      "Epoch 386/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0949\n",
      "Epoch 387/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1323 - val_loss: 211.0954\n",
      "Epoch 388/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1337 - val_loss: 211.0949\n",
      "Epoch 389/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0946\n",
      "Epoch 390/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1304 - val_loss: 211.0945\n",
      "Epoch 391/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0963\n",
      "Epoch 392/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1377 - val_loss: 211.0942\n",
      "Epoch 393/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1337 - val_loss: 211.0964\n",
      "Epoch 394/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0965\n",
      "Epoch 395/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1312 - val_loss: 211.0971\n",
      "Epoch 396/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0950\n",
      "Epoch 397/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1321 - val_loss: 211.0965\n",
      "Epoch 398/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0965\n",
      "Epoch 399/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0962\n",
      "Epoch 400/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1323 - val_loss: 211.0981\n",
      "Epoch 401/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1304 - val_loss: 211.0965\n",
      "Epoch 402/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0972\n",
      "Epoch 403/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1360 - val_loss: 211.0984\n",
      "Epoch 404/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0976\n",
      "Epoch 405/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0977\n",
      "Epoch 406/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0977\n",
      "Epoch 407/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0968\n",
      "Epoch 408/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1343 - val_loss: 211.0955\n",
      "Epoch 409/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0967\n",
      "Epoch 410/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0964\n",
      "Epoch 411/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0964\n",
      "Epoch 412/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0955\n",
      "Epoch 413/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1331 - val_loss: 211.0946\n",
      "Epoch 414/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1347 - val_loss: 211.0954\n",
      "Epoch 415/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0968\n",
      "Epoch 416/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0956\n",
      "Epoch 417/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1348 - val_loss: 211.0978\n",
      "Epoch 418/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1283 - val_loss: 211.0960\n",
      "Epoch 419/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0951\n",
      "Epoch 420/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1327 - val_loss: 211.0957\n",
      "Epoch 421/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0949\n",
      "Epoch 422/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0955\n",
      "Epoch 423/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0958\n",
      "Epoch 424/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0951\n",
      "Epoch 425/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0946\n",
      "Epoch 426/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1364 - val_loss: 211.0947\n",
      "Epoch 427/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0962\n",
      "Epoch 428/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0954\n",
      "Epoch 429/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1340 - val_loss: 211.0969\n",
      "Epoch 430/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0959\n",
      "Epoch 431/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1327 - val_loss: 211.0969\n",
      "Epoch 432/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1309 - val_loss: 211.0962\n",
      "Epoch 433/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1308 - val_loss: 211.0959\n",
      "Epoch 434/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0954\n",
      "Epoch 435/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0945\n",
      "Epoch 436/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0944\n",
      "Epoch 437/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1330 - val_loss: 211.0941\n",
      "Epoch 438/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1353 - val_loss: 211.0930\n",
      "Epoch 439/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0938\n",
      "Epoch 440/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0940\n",
      "Epoch 441/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0934\n",
      "Epoch 442/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0941\n",
      "Epoch 443/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1290 - val_loss: 211.0934\n",
      "Epoch 444/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1348 - val_loss: 211.0957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1316 - val_loss: 211.0952\n",
      "Epoch 446/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0967\n",
      "Epoch 447/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0971\n",
      "Epoch 448/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1327 - val_loss: 211.0955\n",
      "Epoch 449/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0977\n",
      "Epoch 450/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0953\n",
      "Epoch 451/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0971\n",
      "Epoch 452/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0963\n",
      "Epoch 453/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0965\n",
      "Epoch 454/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1319 - val_loss: 211.0968\n",
      "Epoch 455/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1324 - val_loss: 211.0964\n",
      "Epoch 456/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1326 - val_loss: 211.0956\n",
      "Epoch 457/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0971\n",
      "Epoch 458/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1278 - val_loss: 211.0961\n",
      "Epoch 459/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1350 - val_loss: 211.0954\n",
      "Epoch 460/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0950\n",
      "Epoch 461/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0958\n",
      "Epoch 462/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0937\n",
      "Epoch 463/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1316 - val_loss: 211.0948\n",
      "Epoch 464/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0948\n",
      "Epoch 465/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0951\n",
      "Epoch 466/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0952\n",
      "Epoch 467/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1320 - val_loss: 211.0940\n",
      "Epoch 468/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1286 - val_loss: 211.0953\n",
      "Epoch 469/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0944\n",
      "Epoch 470/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0950\n",
      "Epoch 471/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0950\n",
      "Epoch 472/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0955\n",
      "Epoch 473/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1315 - val_loss: 211.0962\n",
      "Epoch 474/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1272 - val_loss: 211.0958\n",
      "Epoch 475/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0962\n",
      "Epoch 476/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0968\n",
      "Epoch 477/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0952\n",
      "Epoch 478/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1272 - val_loss: 211.0966\n",
      "Epoch 479/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0975\n",
      "Epoch 480/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1325 - val_loss: 211.0953\n",
      "Epoch 481/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0970\n",
      "Epoch 482/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0971\n",
      "Epoch 483/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0964\n",
      "Epoch 484/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0965\n",
      "Epoch 485/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0969\n",
      "Epoch 486/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0956\n",
      "Epoch 487/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1353 - val_loss: 211.0964\n",
      "Epoch 488/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1312 - val_loss: 211.0968\n",
      "Epoch 489/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0968\n",
      "Epoch 490/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1419 - val_loss: 211.0975\n",
      "Epoch 491/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1340 - val_loss: 211.0970\n",
      "Epoch 492/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1315 - val_loss: 211.0958\n",
      "Epoch 493/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0957\n",
      "Epoch 494/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.4666 - val_loss: 211.1306\n",
      "Epoch 495/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1563 - val_loss: 211.1310\n",
      "Epoch 496/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1413 - val_loss: 211.0720\n",
      "Epoch 497/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1633 - val_loss: 211.1187\n",
      "Epoch 498/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1490 - val_loss: 211.1148\n",
      "Epoch 499/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1371 - val_loss: 211.1103\n",
      "Epoch 500/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1359 - val_loss: 211.1054\n",
      "Epoch 501/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1328 - val_loss: 211.1029\n",
      "Epoch 502/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1320 - val_loss: 211.1014\n",
      "Epoch 503/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1308 - val_loss: 211.1003\n",
      "Epoch 504/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0997\n",
      "Epoch 505/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1308 - val_loss: 211.1006\n",
      "Epoch 506/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0976\n",
      "Epoch 507/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1344 - val_loss: 211.0964\n",
      "Epoch 508/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0990\n",
      "Epoch 509/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0972\n",
      "Epoch 510/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1278 - val_loss: 211.0978\n",
      "Epoch 511/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1312 - val_loss: 211.0966\n",
      "Epoch 512/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0966\n",
      "Epoch 513/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1304 - val_loss: 211.0965\n",
      "Epoch 514/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0966\n",
      "Epoch 515/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1298 - val_loss: 211.0962\n",
      "Epoch 516/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0967\n",
      "Epoch 517/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1319 - val_loss: 211.0957\n",
      "Epoch 518/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1335 - val_loss: 211.0957\n",
      "Epoch 520/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1286 - val_loss: 211.0951\n",
      "Epoch 521/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1340 - val_loss: 211.0939\n",
      "Epoch 522/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0952\n",
      "Epoch 523/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1309 - val_loss: 211.0952\n",
      "Epoch 524/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0948\n",
      "Epoch 525/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1301 - val_loss: 211.0946\n",
      "Epoch 526/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0952\n",
      "Epoch 527/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1308 - val_loss: 211.0949\n",
      "Epoch 528/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1283 - val_loss: 211.0948\n",
      "Epoch 529/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0955\n",
      "Epoch 530/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1297 - val_loss: 211.0958\n",
      "Epoch 531/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0943\n",
      "Epoch 532/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0955\n",
      "Epoch 533/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0953\n",
      "Epoch 534/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1372 - val_loss: 211.0949\n",
      "Epoch 535/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0964\n",
      "Epoch 536/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0950\n",
      "Epoch 537/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0944\n",
      "Epoch 538/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0952\n",
      "Epoch 539/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1322 - val_loss: 211.0946\n",
      "Epoch 540/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1338 - val_loss: 211.0948\n",
      "Epoch 541/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1313 - val_loss: 211.0953\n",
      "Epoch 542/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1270 - val_loss: 211.0949\n",
      "Epoch 543/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1301 - val_loss: 211.0948\n",
      "Epoch 544/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0941\n",
      "Epoch 545/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1316 - val_loss: 211.0933\n",
      "Epoch 546/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0926\n",
      "Epoch 547/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1357 - val_loss: 211.0917\n",
      "Epoch 548/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0931\n",
      "Epoch 549/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0930\n",
      "Epoch 550/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0917\n",
      "Epoch 551/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0942\n",
      "Epoch 552/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1309 - val_loss: 211.0934\n",
      "Epoch 553/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0937\n",
      "Epoch 554/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0938\n",
      "Epoch 555/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0937\n",
      "Epoch 556/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1301 - val_loss: 211.0932\n",
      "Epoch 557/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0955\n",
      "Epoch 558/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1297 - val_loss: 211.0956\n",
      "Epoch 559/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1275 - val_loss: 211.0944\n",
      "Epoch 560/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0943\n",
      "Epoch 561/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0938\n",
      "Epoch 562/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0946\n",
      "Epoch 563/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1330 - val_loss: 211.0946\n",
      "Epoch 564/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0946\n",
      "Epoch 565/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1286 - val_loss: 211.0948\n",
      "Epoch 566/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1325 - val_loss: 211.0958\n",
      "Epoch 567/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0952\n",
      "Epoch 568/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0947\n",
      "Epoch 569/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1323 - val_loss: 211.0964\n",
      "Epoch 570/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1271 - val_loss: 211.0946\n",
      "Epoch 571/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1328 - val_loss: 211.0936\n",
      "Epoch 572/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1334 - val_loss: 211.0949\n",
      "Epoch 573/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1344 - val_loss: 211.0933\n",
      "Epoch 574/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1272 - val_loss: 211.0955\n",
      "Epoch 575/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1342 - val_loss: 211.0955\n",
      "Epoch 576/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1275 - val_loss: 211.0957\n",
      "Epoch 577/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0960\n",
      "Epoch 578/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0952\n",
      "Epoch 579/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0951\n",
      "Epoch 580/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0953\n",
      "Epoch 581/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1331 - val_loss: 211.0971\n",
      "Epoch 582/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1274 - val_loss: 211.0966\n",
      "Epoch 583/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0951\n",
      "Epoch 584/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1323 - val_loss: 211.0951\n",
      "Epoch 585/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0959\n",
      "Epoch 586/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1322 - val_loss: 211.0966\n",
      "Epoch 587/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1271 - val_loss: 211.0960\n",
      "Epoch 588/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0954\n",
      "Epoch 589/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0943\n",
      "Epoch 590/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0935\n",
      "Epoch 591/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1329 - val_loss: 211.0948\n",
      "Epoch 592/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1358 - val_loss: 211.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0954\n",
      "Epoch 594/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0944\n",
      "Epoch 595/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1378 - val_loss: 211.0968\n",
      "Epoch 596/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1357 - val_loss: 211.0945\n",
      "Epoch 597/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0953\n",
      "Epoch 598/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0959\n",
      "Epoch 599/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0954\n",
      "Epoch 600/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1278 - val_loss: 211.0979\n",
      "Epoch 601/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0980\n",
      "Epoch 602/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0975\n",
      "Epoch 603/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0966\n",
      "Epoch 604/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0965\n",
      "Epoch 605/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0965\n",
      "Epoch 606/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0958\n",
      "Epoch 607/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0952\n",
      "Epoch 608/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1312 - val_loss: 211.0964\n",
      "Epoch 609/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0958\n",
      "Epoch 610/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1325 - val_loss: 211.0953\n",
      "Epoch 611/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1290 - val_loss: 211.0973\n",
      "Epoch 612/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1355 - val_loss: 211.0968\n",
      "Epoch 613/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1298 - val_loss: 211.0979\n",
      "Epoch 614/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1676 - val_loss: 211.0971\n",
      "Epoch 615/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2079 - val_loss: 211.0995\n",
      "Epoch 616/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1614 - val_loss: 211.0994\n",
      "Epoch 617/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0985\n",
      "Epoch 618/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0976\n",
      "Epoch 619/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0980\n",
      "Epoch 620/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1334 - val_loss: 211.0989\n",
      "Epoch 621/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1324 - val_loss: 211.0974\n",
      "Epoch 622/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0970\n",
      "Epoch 623/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1341 - val_loss: 211.0950\n",
      "Epoch 624/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1327 - val_loss: 211.0972\n",
      "Epoch 625/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1277 - val_loss: 211.0963\n",
      "Epoch 626/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1327 - val_loss: 211.0960\n",
      "Epoch 627/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0953\n",
      "Epoch 628/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1286 - val_loss: 211.0946\n",
      "Epoch 629/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0966\n",
      "Epoch 630/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1272 - val_loss: 211.0971\n",
      "Epoch 631/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0981\n",
      "Epoch 632/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0983\n",
      "Epoch 633/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1298 - val_loss: 211.0981\n",
      "Epoch 634/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0993\n",
      "Epoch 635/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1320 - val_loss: 211.0970\n",
      "Epoch 636/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0972\n",
      "Epoch 637/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0970\n",
      "Epoch 638/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0973\n",
      "Epoch 639/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1370 - val_loss: 211.0979\n",
      "Epoch 640/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1331 - val_loss: 211.0990\n",
      "Epoch 641/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 196.1310 - val_loss: 211.0971\n",
      "Epoch 642/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0969\n",
      "Epoch 643/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0969\n",
      "Epoch 644/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1319 - val_loss: 211.0961\n",
      "Epoch 645/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1283 - val_loss: 211.0964\n",
      "Epoch 646/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1276 - val_loss: 211.0962\n",
      "Epoch 647/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1276 - val_loss: 211.0956\n",
      "Epoch 648/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0955\n",
      "Epoch 649/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1359 - val_loss: 211.0959\n",
      "Epoch 650/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0959\n",
      "Epoch 651/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 196.1302 - val_loss: 211.0952\n",
      "Epoch 652/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0955\n",
      "Epoch 653/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0943\n",
      "Epoch 654/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1326 - val_loss: 211.0961\n",
      "Epoch 655/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0953\n",
      "Epoch 656/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0956\n",
      "Epoch 657/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1275 - val_loss: 211.0957\n",
      "Epoch 658/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1353 - val_loss: 211.0956\n",
      "Epoch 659/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1312 - val_loss: 211.0944\n",
      "Epoch 660/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0951\n",
      "Epoch 661/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0946\n",
      "Epoch 662/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1319 - val_loss: 211.0966\n",
      "Epoch 663/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1298 - val_loss: 211.0955\n",
      "Epoch 664/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0953\n",
      "Epoch 665/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1301 - val_loss: 211.0953\n",
      "Epoch 666/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1283 - val_loss: 211.0947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0942\n",
      "Epoch 668/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0955\n",
      "Epoch 669/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0944\n",
      "Epoch 670/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0944\n",
      "Epoch 671/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1319 - val_loss: 211.0960\n",
      "Epoch 672/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0960\n",
      "Epoch 673/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0962\n",
      "Epoch 674/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0943\n",
      "Epoch 675/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1341 - val_loss: 211.0954\n",
      "Epoch 676/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1365 - val_loss: 211.0941\n",
      "Epoch 677/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1315 - val_loss: 211.0954\n",
      "Epoch 678/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1304 - val_loss: 211.0945\n",
      "Epoch 679/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0954\n",
      "Epoch 680/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0954\n",
      "Epoch 681/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1290 - val_loss: 211.0954\n",
      "Epoch 682/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1322 - val_loss: 211.0969\n",
      "Epoch 683/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1316 - val_loss: 211.0947\n",
      "Epoch 684/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1218 - val_loss: 211.0934\n",
      "Epoch 685/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1397 - val_loss: 211.0946\n",
      "Epoch 686/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0936\n",
      "Epoch 687/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1298 - val_loss: 211.0948\n",
      "Epoch 688/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1278 - val_loss: 211.0951\n",
      "Epoch 689/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1316 - val_loss: 211.0943\n",
      "Epoch 690/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1273 - val_loss: 211.0941\n",
      "Epoch 691/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1354 - val_loss: 211.0959\n",
      "Epoch 692/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0948\n",
      "Epoch 693/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0936\n",
      "Epoch 694/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0953\n",
      "Epoch 695/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0935\n",
      "Epoch 696/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0952\n",
      "Epoch 697/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0950\n",
      "Epoch 698/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1298 - val_loss: 211.0949\n",
      "Epoch 699/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0949\n",
      "Epoch 700/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0948\n",
      "Epoch 701/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0956\n",
      "Epoch 702/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0957\n",
      "Epoch 703/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1328 - val_loss: 211.0957\n",
      "Epoch 704/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0951\n",
      "Epoch 705/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0949\n",
      "Epoch 706/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1274 - val_loss: 211.0954\n",
      "Epoch 707/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0960\n",
      "Epoch 708/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1320 - val_loss: 211.0955\n",
      "Epoch 709/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1270 - val_loss: 211.0958\n",
      "Epoch 710/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0959\n",
      "Epoch 711/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0959\n",
      "Epoch 712/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0975\n",
      "Epoch 713/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0963\n",
      "Epoch 714/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1289 - val_loss: 211.0958\n",
      "Epoch 715/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0954\n",
      "Epoch 716/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0959\n",
      "Epoch 717/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0958\n",
      "Epoch 718/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1301 - val_loss: 211.0948\n",
      "Epoch 719/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1332 - val_loss: 211.0968\n",
      "Epoch 720/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0949\n",
      "Epoch 721/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1275 - val_loss: 211.0955\n",
      "Epoch 722/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0958\n",
      "Epoch 723/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0950\n",
      "Epoch 724/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1277 - val_loss: 211.0967\n",
      "Epoch 725/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0955\n",
      "Epoch 726/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0951\n",
      "Epoch 727/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0958\n",
      "Epoch 728/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1276 - val_loss: 211.0968\n",
      "Epoch 729/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1322 - val_loss: 211.0957\n",
      "Epoch 730/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1279 - val_loss: 211.0975\n",
      "Epoch 731/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0965\n",
      "Epoch 732/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0958\n",
      "Epoch 733/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0957\n",
      "Epoch 734/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0967\n",
      "Epoch 735/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0972\n",
      "Epoch 736/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0967\n",
      "Epoch 737/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1269 - val_loss: 211.0965\n",
      "Epoch 738/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0970\n",
      "Epoch 739/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0971\n",
      "Epoch 740/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1333 - val_loss: 211.0957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1293 - val_loss: 211.0961\n",
      "Epoch 742/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1321 - val_loss: 211.0962\n",
      "Epoch 743/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0962\n",
      "Epoch 744/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0955\n",
      "Epoch 745/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1329 - val_loss: 211.0976\n",
      "Epoch 746/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0982\n",
      "Epoch 747/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1358 - val_loss: 211.0969\n",
      "Epoch 748/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1340 - val_loss: 211.0944\n",
      "Epoch 749/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1338 - val_loss: 211.0976\n",
      "Epoch 750/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0960\n",
      "Epoch 751/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0965\n",
      "Epoch 752/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1276 - val_loss: 211.0961\n",
      "Epoch 753/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1269 - val_loss: 211.0957\n",
      "Epoch 754/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0963\n",
      "Epoch 755/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1308 - val_loss: 211.0949\n",
      "Epoch 756/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1353 - val_loss: 211.0959\n",
      "Epoch 757/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1304 - val_loss: 211.0954\n",
      "Epoch 758/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1315 - val_loss: 211.0951\n",
      "Epoch 759/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0966\n",
      "Epoch 760/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1322 - val_loss: 211.0967\n",
      "Epoch 761/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1276 - val_loss: 211.0970\n",
      "Epoch 762/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1334 - val_loss: 211.0973\n",
      "Epoch 763/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0963\n",
      "Epoch 764/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0973\n",
      "Epoch 765/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1281 - val_loss: 211.0962\n",
      "Epoch 766/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1283 - val_loss: 211.0961\n",
      "Epoch 767/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0968\n",
      "Epoch 768/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0975\n",
      "Epoch 769/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0964\n",
      "Epoch 770/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0956\n",
      "Epoch 771/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1326 - val_loss: 211.0960\n",
      "Epoch 772/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0947\n",
      "Epoch 773/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0951\n",
      "Epoch 774/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1286 - val_loss: 211.0939\n",
      "Epoch 775/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1330 - val_loss: 211.0947\n",
      "Epoch 776/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1276 - val_loss: 211.0942\n",
      "Epoch 777/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1297 - val_loss: 211.0953\n",
      "Epoch 778/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0952\n",
      "Epoch 779/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0958\n",
      "Epoch 780/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1323 - val_loss: 211.0938\n",
      "Epoch 781/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1335 - val_loss: 211.0940\n",
      "Epoch 782/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0942\n",
      "Epoch 783/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0957\n",
      "Epoch 784/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0943\n",
      "Epoch 785/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0954\n",
      "Epoch 786/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0962\n",
      "Epoch 787/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1326 - val_loss: 211.0955\n",
      "Epoch 788/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0946\n",
      "Epoch 789/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0954\n",
      "Epoch 790/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0946\n",
      "Epoch 791/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0932\n",
      "Epoch 792/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0929\n",
      "Epoch 793/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0956\n",
      "Epoch 794/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0945\n",
      "Epoch 795/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1275 - val_loss: 211.0952\n",
      "Epoch 796/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0957\n",
      "Epoch 797/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1371 - val_loss: 211.0941\n",
      "Epoch 798/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0952\n",
      "Epoch 799/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1349 - val_loss: 211.0964\n",
      "Epoch 800/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0947\n",
      "Epoch 801/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1283 - val_loss: 211.0962\n",
      "Epoch 802/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0959\n",
      "Epoch 803/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1297 - val_loss: 211.0953\n",
      "Epoch 804/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1372 - val_loss: 211.0968\n",
      "Epoch 805/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1294 - val_loss: 211.0966\n",
      "Epoch 806/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1322 - val_loss: 211.0978\n",
      "Epoch 807/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0964\n",
      "Epoch 808/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1290 - val_loss: 211.0959\n",
      "Epoch 809/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0969\n",
      "Epoch 810/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0957\n",
      "Epoch 811/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1348 - val_loss: 211.0945\n",
      "Epoch 812/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0947\n",
      "Epoch 813/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1277 - val_loss: 211.0953\n",
      "Epoch 814/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 815/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0958\n",
      "Epoch 816/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0952\n",
      "Epoch 817/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1295 - val_loss: 211.0961\n",
      "Epoch 818/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1297 - val_loss: 211.0944\n",
      "Epoch 819/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0962\n",
      "Epoch 820/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1310 - val_loss: 211.0948\n",
      "Epoch 821/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1291 - val_loss: 211.0958\n",
      "Epoch 822/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1299 - val_loss: 211.0966\n",
      "Epoch 823/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1320 - val_loss: 211.0961\n",
      "Epoch 824/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1305 - val_loss: 211.0956\n",
      "Epoch 825/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1298 - val_loss: 211.0951\n",
      "Epoch 826/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0947\n",
      "Epoch 827/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1380 - val_loss: 211.0962\n",
      "Epoch 828/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1287 - val_loss: 211.0957\n",
      "Epoch 829/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1303 - val_loss: 211.0953\n",
      "Epoch 830/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0951\n",
      "Epoch 831/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1349 - val_loss: 211.0955\n",
      "Epoch 832/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0947\n",
      "Epoch 833/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1306 - val_loss: 211.0933\n",
      "Epoch 834/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1335 - val_loss: 211.0951\n",
      "Epoch 835/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0949\n",
      "Epoch 836/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1292 - val_loss: 211.0942\n",
      "Epoch 837/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1285 - val_loss: 211.0939\n",
      "Epoch 838/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0943\n",
      "Epoch 839/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0947\n",
      "Epoch 840/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1339 - val_loss: 211.0937\n",
      "Epoch 841/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0940\n",
      "Epoch 842/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1278 - val_loss: 211.0942\n",
      "Epoch 843/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1274 - val_loss: 211.0944\n",
      "Epoch 844/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1311 - val_loss: 211.0939\n",
      "Epoch 845/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1483 - val_loss: 211.1772\n",
      "Epoch 846/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 201.1471 - val_loss: 211.0922\n",
      "Epoch 847/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.9509 - val_loss: 211.0928\n",
      "Epoch 848/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3777 - val_loss: 211.2502\n",
      "Epoch 849/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.2948 - val_loss: 211.0953\n",
      "Epoch 850/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.3001 - val_loss: 211.0970\n",
      "Epoch 851/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.0696 - val_loss: 211.0979\n",
      "Epoch 852/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1658 - val_loss: 211.0962\n",
      "Epoch 853/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1325 - val_loss: 211.0970\n",
      "Epoch 854/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1139 - val_loss: 211.0980\n",
      "Epoch 855/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1123 - val_loss: 211.0991\n",
      "Epoch 856/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1336 - val_loss: 211.0974\n",
      "Epoch 857/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1130 - val_loss: 211.0970\n",
      "Epoch 858/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1277 - val_loss: 211.0966\n",
      "Epoch 859/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1222 - val_loss: 211.0977\n",
      "Epoch 860/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1408 - val_loss: 211.0971\n",
      "Epoch 861/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1388 - val_loss: 211.0979\n",
      "Epoch 862/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1132 - val_loss: 211.0962\n",
      "Epoch 863/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1459 - val_loss: 211.0956\n",
      "Epoch 864/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1584 - val_loss: 211.0961\n",
      "Epoch 865/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1131 - val_loss: 211.0946\n",
      "Epoch 866/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1088 - val_loss: 211.0974\n",
      "Epoch 867/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1175 - val_loss: 211.0947\n",
      "Epoch 868/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1196 - val_loss: 211.0939\n",
      "Epoch 869/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1356 - val_loss: 211.0920\n",
      "Epoch 870/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1454 - val_loss: 211.0931\n",
      "Epoch 871/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1391 - val_loss: 211.0948\n",
      "Epoch 872/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1328 - val_loss: 211.0943\n",
      "Epoch 873/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1254 - val_loss: 211.0952\n",
      "Epoch 874/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1487 - val_loss: 211.0957\n",
      "Epoch 875/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1194 - val_loss: 211.0945\n",
      "Epoch 876/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1058 - val_loss: 211.0954\n",
      "Epoch 877/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1276 - val_loss: 211.0944\n",
      "Epoch 878/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1280 - val_loss: 211.0962\n",
      "Epoch 879/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1136 - val_loss: 211.0961\n",
      "Epoch 880/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1230 - val_loss: 211.0967\n",
      "Epoch 881/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1202 - val_loss: 211.0955\n",
      "Epoch 882/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1374 - val_loss: 211.0953\n",
      "Epoch 883/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1233 - val_loss: 211.0945\n",
      "Epoch 884/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1208 - val_loss: 211.0946\n",
      "Epoch 885/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1448 - val_loss: 211.0954\n",
      "Epoch 886/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1348 - val_loss: 211.0933\n",
      "Epoch 887/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1505 - val_loss: 211.0930\n",
      "Epoch 888/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1308 - val_loss: 211.0912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1044 - val_loss: 211.0931\n",
      "Epoch 890/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1114 - val_loss: 211.0932\n",
      "Epoch 891/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1146 - val_loss: 211.0947\n",
      "Epoch 892/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1378 - val_loss: 211.0937\n",
      "Epoch 893/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1160 - val_loss: 211.0937\n",
      "Epoch 894/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1152 - val_loss: 211.0929\n",
      "Epoch 895/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1334 - val_loss: 211.0940\n",
      "Epoch 896/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1273 - val_loss: 211.0941\n",
      "Epoch 897/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1288 - val_loss: 211.0959\n",
      "Epoch 898/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1086 - val_loss: 211.0944\n",
      "Epoch 899/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1187 - val_loss: 211.0947\n",
      "Epoch 900/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1317 - val_loss: 211.0950\n",
      "Epoch 901/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0941\n",
      "Epoch 902/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1329 - val_loss: 211.0944\n",
      "Epoch 903/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1198 - val_loss: 211.0941\n",
      "Epoch 904/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1465 - val_loss: 211.0962\n",
      "Epoch 905/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1102 - val_loss: 211.0947\n",
      "Epoch 906/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1235 - val_loss: 211.0943\n",
      "Epoch 907/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1493 - val_loss: 211.0935\n",
      "Epoch 908/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1255 - val_loss: 211.0946\n",
      "Epoch 909/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0928\n",
      "Epoch 910/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1121 - val_loss: 211.0942\n",
      "Epoch 911/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1180 - val_loss: 211.0943\n",
      "Epoch 912/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1076 - val_loss: 211.0944\n",
      "Epoch 913/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1222 - val_loss: 211.0947\n",
      "Epoch 914/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1236 - val_loss: 211.0947\n",
      "Epoch 915/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1145 - val_loss: 211.0941\n",
      "Epoch 916/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1150 - val_loss: 211.0953\n",
      "Epoch 917/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1357 - val_loss: 211.0974\n",
      "Epoch 918/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1373 - val_loss: 211.0963\n",
      "Epoch 919/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1186 - val_loss: 211.0979\n",
      "Epoch 920/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1302 - val_loss: 211.0962\n",
      "Epoch 921/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1164 - val_loss: 211.0947\n",
      "Epoch 922/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1147 - val_loss: 211.0947\n",
      "Epoch 923/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1114 - val_loss: 211.0959\n",
      "Epoch 924/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1284 - val_loss: 211.0957\n",
      "Epoch 925/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1235 - val_loss: 211.0973\n",
      "Epoch 926/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1157 - val_loss: 211.0959\n",
      "Epoch 927/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1341 - val_loss: 211.0944\n",
      "Epoch 928/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1314 - val_loss: 211.0965\n",
      "Epoch 929/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1207 - val_loss: 211.0955\n",
      "Epoch 930/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1413 - val_loss: 211.0946\n",
      "Epoch 931/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1224 - val_loss: 211.0945\n",
      "Epoch 932/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1382 - val_loss: 211.0964\n",
      "Epoch 933/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1178 - val_loss: 211.0972\n",
      "Epoch 934/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1375 - val_loss: 211.0951\n",
      "Epoch 935/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1037 - val_loss: 211.0965\n",
      "Epoch 936/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1300 - val_loss: 211.0963\n",
      "Epoch 937/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1282 - val_loss: 211.0963\n",
      "Epoch 938/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1498 - val_loss: 211.0963\n",
      "Epoch 939/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1203 - val_loss: 211.0971\n",
      "Epoch 940/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1149 - val_loss: 211.0982\n",
      "Epoch 941/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1095 - val_loss: 211.0965\n",
      "Epoch 942/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1307 - val_loss: 211.0977\n",
      "Epoch 943/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1250 - val_loss: 211.0967\n",
      "Epoch 944/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1296 - val_loss: 211.0955\n",
      "Epoch 945/1000\n",
      "3800/3800 [==============================] - 13s 3ms/step - loss: 196.1149 - val_loss: 211.0966\n",
      "Epoch 946/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1254 - val_loss: 211.0965\n",
      "Epoch 947/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1054 - val_loss: 211.0952\n",
      "Epoch 948/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1218 - val_loss: 211.0957\n",
      "Epoch 949/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1313 - val_loss: 211.0946\n",
      "Epoch 950/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1527 - val_loss: 211.0946\n",
      "Epoch 951/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1260 - val_loss: 211.0956\n",
      "Epoch 952/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1318 - val_loss: 211.0967\n",
      "Epoch 953/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1125 - val_loss: 211.0971\n",
      "Epoch 954/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1367 - val_loss: 211.0966\n",
      "Epoch 955/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1341 - val_loss: 211.0971\n",
      "Epoch 956/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1155 - val_loss: 211.0965\n",
      "Epoch 957/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1359 - val_loss: 211.0980\n",
      "Epoch 958/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1389 - val_loss: 211.0963\n",
      "Epoch 959/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1383 - val_loss: 211.0973\n",
      "Epoch 960/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1021 - val_loss: 211.0976\n",
      "Epoch 961/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1498 - val_loss: 211.0991\n",
      "Epoch 962/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1205 - val_loss: 211.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1134 - val_loss: 211.0985\n",
      "Epoch 964/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1404 - val_loss: 211.0977\n",
      "Epoch 965/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1427 - val_loss: 211.0979\n",
      "Epoch 966/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1257 - val_loss: 211.0967\n",
      "Epoch 967/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1255 - val_loss: 211.0972\n",
      "Epoch 968/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1146 - val_loss: 211.0955\n",
      "Epoch 969/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.0970 - val_loss: 211.0964\n",
      "Epoch 970/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1438 - val_loss: 211.0966\n",
      "Epoch 971/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1304 - val_loss: 211.0967\n",
      "Epoch 972/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1315 - val_loss: 211.0981\n",
      "Epoch 973/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1422 - val_loss: 211.0976\n",
      "Epoch 974/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1131 - val_loss: 211.0957\n",
      "Epoch 975/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1191 - val_loss: 211.0967\n",
      "Epoch 976/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1060 - val_loss: 211.0964\n",
      "Epoch 977/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1330 - val_loss: 211.0971\n",
      "Epoch 978/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1045 - val_loss: 211.1654\n",
      "Epoch 979/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1542 - val_loss: 211.1653\n",
      "Epoch 980/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1531 - val_loss: 211.1639\n",
      "Epoch 981/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1482 - val_loss: 211.1607\n",
      "Epoch 982/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1259 - val_loss: 211.1588\n",
      "Epoch 983/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1274 - val_loss: 211.1531\n",
      "Epoch 984/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1198 - val_loss: 211.1331\n",
      "Epoch 985/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1142 - val_loss: 211.1317\n",
      "Epoch 986/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1098 - val_loss: 211.1537\n",
      "Epoch 987/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1204 - val_loss: 211.1521\n",
      "Epoch 988/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1368 - val_loss: 211.1120\n",
      "Epoch 989/1000\n",
      "3800/3800 [==============================] - 12s 3ms/step - loss: 196.1375 - val_loss: 211.1384\n",
      "Epoch 990/1000\n",
      "3800/3800 [==============================] - 1814s 477ms/step - loss: 196.1309 - val_loss: 211.1416\n",
      "Epoch 991/1000\n",
      "3800/3800 [==============================] - 17s 4ms/step - loss: 196.1303 - val_loss: 211.1610\n",
      "Epoch 992/1000\n",
      "3800/3800 [==============================] - 17s 4ms/step - loss: 196.1534 - val_loss: 211.1612\n",
      "Epoch 993/1000\n",
      "3800/3800 [==============================] - 3384s 890ms/step - loss: 196.1468 - val_loss: 211.1541\n",
      "Epoch 994/1000\n",
      "3800/3800 [==============================] - 15s 4ms/step - loss: 196.0979 - val_loss: 211.1587\n",
      "Epoch 995/1000\n",
      "3800/3800 [==============================] - 17s 4ms/step - loss: 196.1421 - val_loss: 211.1554\n",
      "Epoch 996/1000\n",
      "3800/3800 [==============================] - 3616s 951ms/step - loss: 196.1010 - val_loss: 211.1562\n",
      "Epoch 997/1000\n",
      "3800/3800 [==============================] - 14s 4ms/step - loss: 196.1302 - val_loss: 211.1562\n",
      "Epoch 998/1000\n",
      "3800/3800 [==============================] - 17s 4ms/step - loss: 196.1408 - val_loss: 211.1429\n",
      "Epoch 999/1000\n",
      "3800/3800 [==============================] - 3616s 952ms/step - loss: 196.1342 - val_loss: 211.1454\n",
      "Epoch 1000/1000\n",
      "3800/3800 [==============================] - 14s 4ms/step - loss: 196.1391 - val_loss: 211.1413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235c5c128>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trimmed_train = X_trimmed[:3800]\n",
    "X_trimmed_test = X_trimmed[3800:]\n",
    "Y_trimmed_train = Y_trimmed[:3800]\n",
    "Y_trimmed_test = Y_trimmed[3800:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=150, dropout = 0.5, return_sequences= True, input_shape=(30, 8)))\n",
    "model.add(LSTM(units=100, dropout = 0.5))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "\n",
    "model.fit(X_trimmed_train, Y_trimmed_train, epochs=1000, batch_size=64, validation_data=(X_trimmed_test, Y_trimmed_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
